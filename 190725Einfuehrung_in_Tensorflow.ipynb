{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmenets/neuralnetwork/blob/master/190725Einfuehrung_in_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8llTbsXJHd6N",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEc-ybFoYoka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCDYM21uY7iH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "2d02defc-ce9c-4976-d51b-619c211d020c"
      },
      "source": [
        "!tar -xvf /content/cifar-10-python.tar.gz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUJZcf8GVUpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '/tmp/data'\n",
        "NUM_STEPS = 10000\n",
        "MINIBATCH_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqWhJ1ZERTmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_variable(shape):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "\n",
        "def conv_layer(input, shape):\n",
        "  W = weight_variable(shape)\n",
        "  b = bias_variable([shape[3]])\n",
        "  return tf.nn.relu(conv2d(input, W) +b)\n",
        "\n",
        "def full_layer(input, size):\n",
        "  in_size = int(input.get_shape()[1])\n",
        "  W = weight_variable([in_size, size])\n",
        "  b = bias_variable([size])\n",
        "  return tf.matmul(input, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM-URTpBNsFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "conv1 = conv_layer(x_image, shape=[5, 5, 1, 32])\n",
        "conv1_pool = max_pool_2x2(conv1)\n",
        "\n",
        "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
        "conv2_pool = max_pool_2x2(conv2)\n",
        "\n",
        "conv2_flat = tf. reshape(conv2_pool, [-1, 7*7*64])\n",
        "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
        "\n",
        "y_conv = full_layer(full1_drop, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAB9x1jHViRU",
        "colab_type": "code",
        "outputId": "4ac17c07-5df1-478e-d261-f71deeae670d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  for i in range(NUM_STEPS):  \n",
        "    batch = mnist.train.next_batch(50)  \n",
        "    \n",
        "    if i % 100 == 0:\n",
        "      train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
        "      print(\"Schritt {}, Genauigkeit Anlernen {}\".format(i, train_accuracy))\n",
        "      \n",
        "    sess.run(train_step, feed_dict={x: batch[0], y_:batch[1], keep_prob: 0.5})\n",
        "    \n",
        "  X = mnist.test.images.reshape(10, 1000, 784)\n",
        "  Y = mnist.test.labels.reshape(10, 1000, 10)\n",
        "  test_accuracy = np.mean([sess.run(accuracy, feed_dict={x:X[i], y_:Y[i], keep_prob:1.0})for i in range(10)])\n",
        "  \n",
        "  print(\"Genauigkeit Test: {}\".format(test_accuracy))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "Schritt 0, Genauigkeit Anlernen 0.07999999821186066\n",
            "Schritt 100, Genauigkeit Anlernen 0.8199999928474426\n",
            "Schritt 200, Genauigkeit Anlernen 0.8999999761581421\n",
            "Schritt 300, Genauigkeit Anlernen 0.8799999952316284\n",
            "Schritt 400, Genauigkeit Anlernen 0.9399999976158142\n",
            "Schritt 500, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 600, Genauigkeit Anlernen 0.9399999976158142\n",
            "Schritt 700, Genauigkeit Anlernen 0.8799999952316284\n",
            "Schritt 800, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 900, Genauigkeit Anlernen 0.9399999976158142\n",
            "Schritt 1000, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 1100, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 1200, Genauigkeit Anlernen 0.8999999761581421\n",
            "Schritt 1300, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 1400, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 1500, Genauigkeit Anlernen 1.0\n",
            "Schritt 1600, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 1700, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 1800, Genauigkeit Anlernen 1.0\n",
            "Schritt 1900, Genauigkeit Anlernen 0.9200000166893005\n",
            "Schritt 2000, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 2100, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 2200, Genauigkeit Anlernen 1.0\n",
            "Schritt 2300, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 2400, Genauigkeit Anlernen 1.0\n",
            "Schritt 2500, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 2600, Genauigkeit Anlernen 1.0\n",
            "Schritt 2700, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 2800, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 2900, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 3000, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 3100, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 3200, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 3300, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 3400, Genauigkeit Anlernen 1.0\n",
            "Schritt 3500, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 3600, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 3700, Genauigkeit Anlernen 1.0\n",
            "Schritt 3800, Genauigkeit Anlernen 1.0\n",
            "Schritt 3900, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 4000, Genauigkeit Anlernen 1.0\n",
            "Schritt 4100, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 4200, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 4300, Genauigkeit Anlernen 1.0\n",
            "Schritt 4400, Genauigkeit Anlernen 1.0\n",
            "Schritt 4500, Genauigkeit Anlernen 1.0\n",
            "Schritt 4600, Genauigkeit Anlernen 1.0\n",
            "Schritt 4700, Genauigkeit Anlernen 1.0\n",
            "Schritt 4800, Genauigkeit Anlernen 0.9200000166893005\n",
            "Schritt 4900, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 5000, Genauigkeit Anlernen 1.0\n",
            "Schritt 5100, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 5200, Genauigkeit Anlernen 1.0\n",
            "Schritt 5300, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 5400, Genauigkeit Anlernen 1.0\n",
            "Schritt 5500, Genauigkeit Anlernen 1.0\n",
            "Schritt 5600, Genauigkeit Anlernen 1.0\n",
            "Schritt 5700, Genauigkeit Anlernen 1.0\n",
            "Schritt 5800, Genauigkeit Anlernen 1.0\n",
            "Schritt 5900, Genauigkeit Anlernen 1.0\n",
            "Schritt 6000, Genauigkeit Anlernen 1.0\n",
            "Schritt 6100, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 6200, Genauigkeit Anlernen 1.0\n",
            "Schritt 6300, Genauigkeit Anlernen 1.0\n",
            "Schritt 6400, Genauigkeit Anlernen 1.0\n",
            "Schritt 6500, Genauigkeit Anlernen 1.0\n",
            "Schritt 6600, Genauigkeit Anlernen 1.0\n",
            "Schritt 6700, Genauigkeit Anlernen 1.0\n",
            "Schritt 6800, Genauigkeit Anlernen 1.0\n",
            "Schritt 6900, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 7000, Genauigkeit Anlernen 1.0\n",
            "Schritt 7100, Genauigkeit Anlernen 1.0\n",
            "Schritt 7200, Genauigkeit Anlernen 1.0\n",
            "Schritt 7300, Genauigkeit Anlernen 1.0\n",
            "Schritt 7400, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 7500, Genauigkeit Anlernen 0.9599999785423279\n",
            "Schritt 7600, Genauigkeit Anlernen 1.0\n",
            "Schritt 7700, Genauigkeit Anlernen 1.0\n",
            "Schritt 7800, Genauigkeit Anlernen 1.0\n",
            "Schritt 7900, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 8000, Genauigkeit Anlernen 1.0\n",
            "Schritt 8100, Genauigkeit Anlernen 0.9800000190734863\n",
            "Schritt 8200, Genauigkeit Anlernen 1.0\n",
            "Schritt 8300, Genauigkeit Anlernen 1.0\n",
            "Schritt 8400, Genauigkeit Anlernen 1.0\n",
            "Schritt 8500, Genauigkeit Anlernen 1.0\n",
            "Schritt 8600, Genauigkeit Anlernen 1.0\n",
            "Schritt 8700, Genauigkeit Anlernen 0.9399999976158142\n",
            "Schritt 8800, Genauigkeit Anlernen 1.0\n",
            "Schritt 8900, Genauigkeit Anlernen 1.0\n",
            "Schritt 9000, Genauigkeit Anlernen 1.0\n",
            "Schritt 9100, Genauigkeit Anlernen 1.0\n",
            "Schritt 9200, Genauigkeit Anlernen 1.0\n",
            "Schritt 9300, Genauigkeit Anlernen 1.0\n",
            "Schritt 9400, Genauigkeit Anlernen 1.0\n",
            "Schritt 9500, Genauigkeit Anlernen 1.0\n",
            "Schritt 9600, Genauigkeit Anlernen 1.0\n",
            "Schritt 9700, Genauigkeit Anlernen 1.0\n",
            "Schritt 9800, Genauigkeit Anlernen 1.0\n",
            "Schritt 9900, Genauigkeit Anlernen 1.0\n",
            "Genauigkeit Test: 0.9902999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}