{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmenets/neuralnetwork/blob/master/chinook190715.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXT3U_hX49xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lt0De55L-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtUXvjZr7tSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3556b592-38e1-47b2-ecce-9e5c6f14d864"
      },
      "source": [
        "cd /content/models/research/object_detection"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnJcNmcI8ALN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGihW7NO8Cvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkjBVHu28HdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGe7nAW9BSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "f2cdef35-808d-452a-b468-e21878f37feb"
      },
      "source": [
        "ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34manchor_generators\u001b[0m/                   inputs_test.py\n",
            "\u001b[01;34mbox_coders\u001b[0m/                          \u001b[01;34mlegacy\u001b[0m/\n",
            "\u001b[01;34mbuilders\u001b[0m/                            \u001b[01;34mmatchers\u001b[0m/\n",
            "CONTRIBUTING.md                      \u001b[01;34mmeta_architectures\u001b[0m/\n",
            "\u001b[01;34mcore\u001b[0m/                                \u001b[01;34mmetrics\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/                                model_hparams.py\n",
            "\u001b[01;34mdata_decoders\u001b[0m/                       model_lib.py\n",
            "\u001b[01;34mdataset_tools\u001b[0m/                       model_lib_test.py\n",
            "\u001b[01;34mdockerfiles\u001b[0m/                         model_main.py\n",
            "eval_util.py                         \u001b[01;34mmodels\u001b[0m/\n",
            "eval_util_test.py                    model_tpu_main.py\n",
            "exporter.py                          object_detection_tutorial.ipynb\n",
            "exporter_test.py                     \u001b[01;34mpredictors\u001b[0m/\n",
            "export_inference_graph.py            \u001b[01;34mprotos\u001b[0m/\n",
            "export_tflite_ssd_graph_lib.py       README.md\n",
            "export_tflite_ssd_graph_lib_test.py  \u001b[01;34msamples\u001b[0m/\n",
            "export_tflite_ssd_graph.py           \u001b[01;34mtest_ckpt\u001b[0m/\n",
            "\u001b[01;34mg3doc\u001b[0m/                               \u001b[01;34mtest_data\u001b[0m/\n",
            "\u001b[01;34mimages\u001b[0m/                              \u001b[01;34mtest_images\u001b[0m/\n",
            "\u001b[01;34minference\u001b[0m/                           \u001b[01;34mtpu_exporters\u001b[0m/\n",
            "\u001b[01;34minference_graph\u001b[0m/                     \u001b[01;34mtraining\u001b[0m/\n",
            "__init__.py                          \u001b[01;34mutils\u001b[0m/\n",
            "inputs.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuCWOoFt-N5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2e66d5-e7a6-4f38-9043-47514d260480"
      },
      "source": [
        "cd /content/models/research/object_detection"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvKNQUWBHMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp  /content/models/research/object_detection/Train-Object-Detection-Classifier/xml_to_csv.py /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLGxacwFARW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1f3dd667-ed47-4bea-91f7-5812c4854e7c"
      },
      "source": [
        "!python3 xml_to_csv.py"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VfI6dZGHeFp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1b7ec58-ded8-4162-ea61-dae280fd0723"
      },
      "source": [
        "!cat /content/models/research/object_detection/generate_tfrecord.py"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"\"\"\n",
            "Usage:\n",
            "  # From tensorflow/models/\n",
            "  # Create train data:\n",
            "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
            "\n",
            "  # Create test data:\n",
            "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
            "\"\"\"\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "from __future__ import absolute_import\n",
            "\n",
            "import os\n",
            "import io\n",
            "import pandas as pd\n",
            "import tensorflow as tf\n",
            "\n",
            "from PIL import Image\n",
            "from object_detection.utils import dataset_util\n",
            "from collections import namedtuple, OrderedDict\n",
            "\n",
            "flags = tf.app.flags\n",
            "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
            "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
            "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
            "FLAGS = flags.FLAGS\n",
            "\n",
            "\n",
            "# TO-DO replace this with label map\n",
            "def class_text_to_int(row_label):\n",
            "    if row_label == 'chinook':\n",
            "        return 1\n",
            "    else:\n",
            "        return 0\n",
            "\n",
            "\n",
            "def split(df, group):\n",
            "    data = namedtuple('data', ['filename', 'object'])\n",
            "    gb = df.groupby(group)\n",
            "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
            "\n",
            "\n",
            "def create_tf_example(group, path):\n",
            "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
            "        encoded_jpg = fid.read()\n",
            "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
            "    image = Image.open(encoded_jpg_io)\n",
            "    width, height = image.size\n",
            "\n",
            "    filename = group.filename.encode('utf8')\n",
            "    image_format = b'jpg'\n",
            "    xmins = []\n",
            "    xmaxs = []\n",
            "    ymins = []\n",
            "    ymaxs = []\n",
            "    classes_text = []\n",
            "    classes = []\n",
            "\n",
            "    for index, row in group.object.iterrows():\n",
            "        xmins.append(row['xmin'] / width)\n",
            "        xmaxs.append(row['xmax'] / width)\n",
            "        ymins.append(row['ymin'] / height)\n",
            "        ymaxs.append(row['ymax'] / height)\n",
            "        classes_text.append(row['class'].encode('utf8'))\n",
            "        classes.append(class_text_to_int(row['class']))\n",
            "\n",
            "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
            "        'image/height': dataset_util.int64_feature(height),\n",
            "        'image/width': dataset_util.int64_feature(width),\n",
            "        'image/filename': dataset_util.bytes_feature(filename),\n",
            "        'image/source_id': dataset_util.bytes_feature(filename),\n",
            "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
            "        'image/format': dataset_util.bytes_feature(image_format),\n",
            "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
            "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
            "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
            "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
            "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
            "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
            "    }))\n",
            "    return tf_example\n",
            "\n",
            "\n",
            "def main(_):\n",
            "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
            "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
            "    examples = pd.read_csv(FLAGS.csv_input)\n",
            "    grouped = split(examples, 'filename')\n",
            "    for group in grouped:\n",
            "        tf_example = create_tf_example(group, path)\n",
            "        writer.write(tf_example.SerializeToString())\n",
            "\n",
            "    writer.close()\n",
            "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
            "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
            "\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    tf.app.run()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m15k-cscH6mL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfd470aa-c1c5-440f-cb29-89d16bc7b063"
      },
      "source": [
        "%%writefile generate_tfrecord_01.py\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'chinook':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing generate_tfrecord_01.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsxFKOByIQcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python generate_tfrecord_01.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-_6ZGWPJTZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0e0b0818-8804-4853-bd72-345184e72240"
      },
      "source": [
        "!python generate_tfrecord_01.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 10:20:28.904641 140045158999936 deprecation_wrapper.py:119] From generate_tfrecord_01.py:101: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0715 10:20:28.905257 140045158999936 deprecation_wrapper.py:119] From generate_tfrecord_01.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0715 10:20:28.944823 140045158999936 deprecation_wrapper.py:119] From generate_tfrecord_01.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/models/research/object_detection/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wERFO7GZKSwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp /content/models/research/object_detection/data/pet_label_map.pbtxt /content/models/research/object_detection/training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU4vyP2TKi16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a20dbd0-b243-445f-fae9-06cace26fabb"
      },
      "source": [
        "!cat /content/models/research/object_detection/training/pet_label_map.pbtxt"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "  id: 1\n",
            "  name: 'Abyssinian'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 2\n",
            "  name: 'american_bulldog'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 3\n",
            "  name: 'american_pit_bull_terrier'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 4\n",
            "  name: 'basset_hound'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 5\n",
            "  name: 'beagle'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 6\n",
            "  name: 'Bengal'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 7\n",
            "  name: 'Birman'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 8\n",
            "  name: 'Bombay'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 9\n",
            "  name: 'boxer'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 10\n",
            "  name: 'British_Shorthair'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 11\n",
            "  name: 'chihuahua'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 12\n",
            "  name: 'Egyptian_Mau'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 13\n",
            "  name: 'english_cocker_spaniel'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 14\n",
            "  name: 'english_setter'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 15\n",
            "  name: 'german_shorthaired'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 16\n",
            "  name: 'great_pyrenees'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 17\n",
            "  name: 'havanese'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 18\n",
            "  name: 'japanese_chin'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 19\n",
            "  name: 'keeshond'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 20\n",
            "  name: 'leonberger'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 21\n",
            "  name: 'Maine_Coon'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 22\n",
            "  name: 'miniature_pinscher'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 23\n",
            "  name: 'newfoundland'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 24\n",
            "  name: 'Persian'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 25\n",
            "  name: 'pomeranian'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 26\n",
            "  name: 'pug'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 27\n",
            "  name: 'Ragdoll'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 28\n",
            "  name: 'Russian_Blue'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 29\n",
            "  name: 'saint_bernard'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 30\n",
            "  name: 'samoyed'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 31\n",
            "  name: 'scottish_terrier'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 32\n",
            "  name: 'shiba_inu'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 33\n",
            "  name: 'Siamese'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 34\n",
            "  name: 'Sphynx'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 35\n",
            "  name: 'staffordshire_bull_terrier'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 36\n",
            "  name: 'wheaten_terrier'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 37\n",
            "  name: 'yorkshire_terrier'\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}