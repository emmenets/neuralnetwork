{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmenets/neuralnetwork/blob/master/191211_objectdetectionclassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD7Dc-iLJzbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXT3U_hX49xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtUXvjZr7tSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYbBtNJnYqZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVw6V940Y5Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf ssd_mobilenet_v1_coco_2018_01_28.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GawmnNo8lsSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvKNQUWBHMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/doc /content/models/research/object_detection\n",
        "#!cp -R /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/images /content/models/research/object_detection\n",
        "#!cp -R /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/inference_graph /content/models/research/object_detection\n",
        "!cp -R /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/training /content/models/research/object_detection\n",
        "!cp -R /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/translate /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/generate_tfrecord.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/Object_detection_image.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/Object_detection_video.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/Object_detection_webcam.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/resizer.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/test.mov /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/test1.JPG /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/xml_to_csv.py /content/models/research/object_detection\n",
        "!cp  /content/models/research/object_detection/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/README.md /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNvAfoLAzM4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/models/research/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdPn1OSJnXWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OanL9KzkDpYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ2muKeD2BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQsHlyfvM11K",
        "colab_type": "code",
        "outputId": "3f1f51b5-4876-44bf-bcef-fbf85b73d423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/models/research/object_detection"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8c43cQ2UVyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images\n",
        "!mkdir inference_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6n8GqZS-xG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /gdrive/My\\ Drive/colabfiles/lektion31/images/test /content/models/research/object_detection/images\n",
        "!cp -r /gdrive/My\\ Drive/colabfiles/lektion31/images/train /content/models/research/object_detection/images\n",
        "!cp /gdrive/My\\ Drive/colabfiles/lektion31/test_labels.csv /content/models/research/object_detection/images\n",
        "!cp /gdrive/My\\ Drive/colabfiles/lektion31/train_labels.csv /content/models/research/object_detection/images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98GmqrIhe3z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm /content/models/research/object_detection/images/test_labels.csv\n",
        "#!rm /content/models/research/object_detection/images/train_labels.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLGxacwFARW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python3 xml_to_csv.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv99g_MdfhZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /content/models/research/object_detection/generate_tfrecord.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhEgw5L1C3Xw",
        "colab_type": "code",
        "outputId": "2bc43021-5b9d-4f3f-fd0a-28ee53db1ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile generate_tfrecord.py\n",
        "\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=images/test_labels.csv  --image_dir=images/test --output_path=test.record\n",
        "\"\"\"\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "flags.DEFINE_string('image_dir', '', 'Path to the image directory')\n",
        "flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'rasti':\n",
        "        return 1\n",
        "\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n",
        "    path = os.path.join(os.getcwd(), FLAGS.image_dir)\n",
        "    examples = pd.read_csv(FLAGS.csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tf.app.run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting generate_tfrecord.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsxFKOByIQcz",
        "colab_type": "code",
        "outputId": "6af25149-cfe3-43cd-bad4-03c1a2b9eebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From generate_tfrecord.py:102: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1211 18:42:15.359420 139789773412224 module_wrapper.py:139] From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1211 18:42:15.419789 139789773412224 module_wrapper.py:139] From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/models/research/object_detection/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-_6ZGWPJTZ3",
        "colab_type": "code",
        "outputId": "90bc9069-fe30-484b-986c-0bc039e30a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From generate_tfrecord.py:102: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1211 18:42:23.486805 140455139710848 module_wrapper.py:139] From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1211 18:42:23.525811 140455139710848 module_wrapper.py:139] From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/models/research/object_detection/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z82tXS2NDgQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /content/models/research/object_detection/training/faster_rcnn_inception_v2_pets.config\n",
        "!rm /content/models/research/object_detection/training/labelmap.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jictvdm5SqHU",
        "colab_type": "code",
        "outputId": "6534d37a-7c00-4ec7-fa31-7977cd2acdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile training/label_map.pbtxt\n",
        "\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'rasti'\n",
        "}\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training/label_map.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiYCKlkF2eOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cat /content/models/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjZVlxOO3Cyi",
        "colab_type": "code",
        "outputId": "27ec2af0-7d4c-4891-800b-02ac323dd4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile training/ssd_mobilenet_v1_coco.config\n",
        "\n",
        "# SSD with Mobilenet v1 configuration for MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 1\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v1'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 0\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 24\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  fine_tune_checkpoint: \"/content/models/research/object_detection/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/models/research/object_detection/train.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/models/research/object_detection/training/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 8000\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/models/research/object_detection/test.record\"\n",
        "  }\n",
        "  label_map_path: \"/content/models/research/object_detection/training/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing training/ssd_mobilenet_v1_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v90gM0m8xfDB",
        "colab_type": "code",
        "outputId": "cb52c67f-cc2b-464a-f59d-35becdb2da69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile train.py\n",
        "\n",
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Training executable for detection models.\n",
        "\n",
        "This executable is used to train DetectionModels. There are two ways of\n",
        "configuring the training job:\n",
        "\n",
        "1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file\n",
        "can be specified by --pipeline_config_path.\n",
        "\n",
        "Example usage:\n",
        "    ./train \\\n",
        "        --logtostderr \\\n",
        "        --train_dir=path/to/train_dir \\\n",
        "        --pipeline_config_path=pipeline_config.pbtxt\n",
        "\n",
        "2) Three configuration files can be provided: a model_pb2.DetectionModel\n",
        "configuration file to define what type of DetectionModel is being trained, an\n",
        "input_reader_pb2.InputReader file to specify what training data will be used and\n",
        "a train_pb2.TrainConfig file to configure training parameters.\n",
        "\n",
        "Example usage:\n",
        "    ./train \\\n",
        "        --logtostderr \\\n",
        "        --train_dir=path/to/train_dir \\\n",
        "        --model_config_path=model_config.pbtxt \\\n",
        "        --train_config_path=train_config.pbtxt \\\n",
        "        --input_config_path=train_input_config.pbtxt\n",
        "\"\"\"\n",
        "\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.builders import dataset_builder\n",
        "from object_detection.builders import graph_rewriter_builder\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.legacy import trainer\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
        "flags.DEFINE_integer('task', 0, 'task id')\n",
        "flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
        "flags.DEFINE_boolean('clone_on_cpu', False,\n",
        "                     'Force clones to be deployed on CPU.  Note that even if '\n",
        "                     'set to False (allowing ops to run on gpu), some ops may '\n",
        "                     'still be run on the CPU if they have no GPU kernel.')\n",
        "flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
        "                     'replicas.')\n",
        "flags.DEFINE_integer('ps_tasks', 0,\n",
        "                     'Number of parameter server tasks. If None, does not use '\n",
        "                     'a parameter server.')\n",
        "flags.DEFINE_string('train_dir', '',\n",
        "                    'Directory to save the checkpoints and training summaries.')\n",
        "\n",
        "flags.DEFINE_string('pipeline_config_path', '',\n",
        "                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "                    'file. If provided, other configs are ignored')\n",
        "\n",
        "flags.DEFINE_string('train_config_path', '',\n",
        "                    'Path to a train_pb2.TrainConfig config file.')\n",
        "flags.DEFINE_string('input_config_path', '',\n",
        "                    'Path to an input_reader_pb2.InputReader config file.')\n",
        "flags.DEFINE_string('model_config_path', '',\n",
        "                    'Path to a model_pb2.DetectionModel config file.')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "@tf.contrib.framework.deprecated(None, 'Use object_detection/model_main.py.')\n",
        "def main(_):\n",
        "  assert FLAGS.train_dir, '`train_dir` is missing.'\n",
        "  if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)\n",
        "  if FLAGS.pipeline_config_path:\n",
        "    configs = config_util.get_configs_from_pipeline_file(\n",
        "        FLAGS.pipeline_config_path)\n",
        "    if FLAGS.task == 0:\n",
        "      tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
        "                    os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
        "                    overwrite=True)\n",
        "  else:\n",
        "    configs = config_util.get_configs_from_multiple_files(\n",
        "        model_config_path=FLAGS.model_config_path,\n",
        "        train_config_path=FLAGS.train_config_path,\n",
        "        train_input_config_path=FLAGS.input_config_path)\n",
        "    if FLAGS.task == 0:\n",
        "      for name, config in [('model.config', FLAGS.model_config_path),\n",
        "                           ('train.config', FLAGS.train_config_path),\n",
        "                           ('input.config', FLAGS.input_config_path)]:\n",
        "        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n",
        "                      overwrite=True)\n",
        "\n",
        "  model_config = configs['model']\n",
        "  train_config = configs['train_config']\n",
        "  input_config = configs['train_input_config']\n",
        "\n",
        "  model_fn = functools.partial(\n",
        "      model_builder.build,\n",
        "      model_config=model_config,\n",
        "      is_training=True)\n",
        "\n",
        "  def get_next(config):\n",
        "    return dataset_builder.make_initializable_iterator(\n",
        "        dataset_builder.build(config)).get_next()\n",
        "\n",
        "  create_input_dict_fn = functools.partial(get_next, input_config)\n",
        "\n",
        "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
        "  cluster_data = env.get('cluster', None)\n",
        "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
        "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
        "  task_info = type('TaskSpec', (object,), task_data)\n",
        "\n",
        "  # Parameters for a single worker.\n",
        "  ps_tasks = 0\n",
        "  worker_replicas = 1\n",
        "  worker_job_name = 'lonely_worker'\n",
        "  task = 0\n",
        "  is_chief = True\n",
        "  master = ''\n",
        "\n",
        "  if cluster_data and 'worker' in cluster_data:\n",
        "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
        "    worker_replicas = len(cluster_data['worker']) + 1\n",
        "  if cluster_data and 'ps' in cluster_data:\n",
        "    ps_tasks = len(cluster_data['ps'])\n",
        "\n",
        "  if worker_replicas > 1 and ps_tasks < 1:\n",
        "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
        "\n",
        "  if worker_replicas >= 1 and ps_tasks > 0:\n",
        "    # Set up distributed training.\n",
        "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
        "                             job_name=task_info.type,\n",
        "                             task_index=task_info.index)\n",
        "    if task_info.type == 'ps':\n",
        "      server.join()\n",
        "      return\n",
        "\n",
        "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
        "    task = task_info.index\n",
        "    is_chief = (task_info.type == 'master')\n",
        "    master = server.target\n",
        "\n",
        "  graph_rewriter_fn = None\n",
        "  if 'graph_rewriter_config' in configs:\n",
        "    graph_rewriter_fn = graph_rewriter_builder.build(\n",
        "        configs['graph_rewriter_config'], is_training=True)\n",
        "\n",
        "  trainer.train(\n",
        "      create_input_dict_fn,\n",
        "      model_fn,\n",
        "      train_config,\n",
        "      master,\n",
        "      task,\n",
        "      FLAGS.num_clones,\n",
        "      worker_replicas,\n",
        "      FLAGS.clone_on_cpu,\n",
        "      ps_tasks,\n",
        "      worker_job_name,\n",
        "      is_chief,\n",
        "      FLAGS.train_dir,\n",
        "      graph_hook_fn=graph_rewriter_fn)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQQIfvm7y7Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R /content/models/research/slim/nets /content/models/research/object_detection\n",
        "!cp -R /content/models/research/slim/deployment /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifu4A4zayA8Z",
        "colab_type": "code",
        "outputId": "832f5681-71d9-4141-f332-6d285843981f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W1211 18:43:37.250712 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1211 18:43:37.250887 140545020077952 module_wrapper.py:139] From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1211 18:43:37.251092 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "W1211 18:43:37.253966 140545020077952 module_wrapper.py:139] From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W1211 18:43:37.266245 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1211 18:43:37.270117 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W1211 18:43:37.270321 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1211 18:43:37.281095 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W1211 18:43:37.282260 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1211 18:43:37.282381 140545020077952 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W1211 18:43:37.289370 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1211 18:43:37.289510 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1211 18:43:37.316002 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W1211 18:43:37.833848 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W1211 18:43:37.839512 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1211 18:43:37.845915 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1211 18:43:37.894306 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:197: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1211 18:43:37.904047 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W1211 18:43:38.473985 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1211 18:43:38.477409 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1211 18:43:38.478489 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W1211 18:43:38.483394 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W1211 18:43:38.486530 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W1211 18:43:38.488991 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1211 18:43:38.489331 140545020077952 module_wrapper.py:139] From /content/models/research/object_detection/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W1211 18:43:38.489480 140545020077952 module_wrapper.py:139] From /content/models/research/object_detection/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1211 18:43:39.218750 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1211 18:43:39.465504 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W1211 18:43:41.092135 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1211 18:43:41.101516 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.101703 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.129508 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.155737 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.182352 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.208849 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:43:41.235317 140545020077952 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W1211 18:43:41.383446 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W1211 18:43:44.735863 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W1211 18:43:44.737105 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W1211 18:43:44.738330 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W1211 18:43:45.239820 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1211 18:43:45.240450 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W1211 18:43:45.240698 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W1211 18:43:45.248119 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "W1211 18:43:46.885654 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1211 18:43:46.887034 140545020077952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1211 18:43:47.864459 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W1211 18:43:49.940018 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "W1211 18:43:50.094119 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "W1211 18:43:50.095885 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W1211 18:43:50.099613 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1211 18:43:50.106182 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1211 18:43:50.106389 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W1211 18:43:50.644458 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W1211 18:43:50.645911 140545020077952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W1211 18:43:50.647705 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.647814 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.647873 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.647930 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.647979 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648029 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648097 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648149 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648227 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648280 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648328 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648374 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648424 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648470 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648516 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648572 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648623 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648671 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648722 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648770 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648815 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.648864 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.648910 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.648955 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649011 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649061 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649116 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649180 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649230 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649277 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649326 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649372 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649417 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649471 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649518 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649563 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649615 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649662 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649707 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649758 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649804 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.649854 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.649912 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.649974 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650027 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650090 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650149 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650218 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650270 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650318 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650364 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650421 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650468 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650515 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650565 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650619 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650665 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650716 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650763 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650815 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.650873 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.650921 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.650970 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651024 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651076 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.651123 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651190 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651240 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.651289 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651348 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651396 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.651443 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651493 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651539 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.651585 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651635 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651682 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.651729 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.651787 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.651834 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.710716 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.710828 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.710901 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.710964 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.711030 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.711101 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.711185 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.711267 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.711332 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.711393 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.711460 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.711524 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.711586 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.711652 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.711714 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.711776 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.711852 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.711917 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.711982 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.712051 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.712144 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.712224 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.712292 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.712355 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.712431 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.712508 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.712573 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.712638 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.712707 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.712771 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.712834 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.712903 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.712967 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.713030 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.713115 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.713197 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.713264 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.713334 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.713398 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.713462 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.713530 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.713595 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.713657 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.713735 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.713801 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.713865 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.713935 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.714000 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.714061 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.714143 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.714239 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.714305 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.714383 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.714450 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.714514 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.714582 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.714646 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.714710 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.714778 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.714842 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.714914 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.714988 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.715053 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.715126 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.715211 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.715276 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.715337 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.715412 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.715472 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.715528 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.715596 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.715656 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.715734 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.715803 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.715864 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.715924 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.715990 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.716052 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.716122 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.716209 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.716276 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.716338 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.716405 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.716467 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.716527 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.716593 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.716655 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.716714 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.716805 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.716867 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.716928 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.716996 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.717059 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.717130 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.717218 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.717284 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.717345 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.717420 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.717486 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.717549 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.717622 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.717684 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.717745 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.717813 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.717876 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.717937 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.718011 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.718084 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.718150 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.718236 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.718300 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.718362 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.718431 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.718495 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.718556 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.718631 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.718697 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.718761 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.718829 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.718892 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.718954 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.719021 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.719094 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.719171 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.719251 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.719319 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.719382 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.719448 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.719511 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.719572 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.719639 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.719704 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.719764 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.719838 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.719904 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.719966 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.720032 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.720103 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.720176 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.720249 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.720313 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.720375 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.720449 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.720516 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.720579 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.720647 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.720710 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.720768 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.720836 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.720900 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.720961 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.721035 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.721111 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.721189 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.721260 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.721323 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.721386 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.721454 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.721516 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.721576 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.721652 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.721721 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.721785 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.721868 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.721932 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.721994 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.722069 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.722136 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.722214 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.722291 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.722357 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.722420 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.722487 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.722549 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.722610 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.722677 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.722740 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.722801 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.722877 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.722943 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.723006 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.723082 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.723147 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.723227 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.723297 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.723361 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.723422 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.723497 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.723563 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.723627 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.723693 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.723757 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.723818 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.723886 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.723950 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.724011 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.724096 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.724177 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.724243 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.724312 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.724375 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.724439 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.724508 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.724570 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.724631 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.724707 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.724774 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.724835 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.724902 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.724965 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.725028 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.725105 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.725183 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.725248 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.725326 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.725392 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.725454 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.725520 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.725586 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.725648 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.725715 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.725777 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.725838 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.725912 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.725977 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.726038 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.726119 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.726200 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.726265 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.726334 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.726397 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.726458 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W1211 18:43:50.726534 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W1211 18:43:50.726609 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W1211 18:43:50.726670 140545020077952 variables_helper.py:157] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W1211 18:43:51.198892 140545020077952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2019-12-11 18:43:52.076850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-12-11 18:43:52.078780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14567dc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-11 18:43:52.078817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-11 18:43:52.083464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-11 18:43:52.258974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:52.259640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14567f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-11 18:43:52.259668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-11 18:43:52.261107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:52.261627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-11 18:43:52.282786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:43:52.527820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:43:52.655126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-11 18:43:52.684995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-11 18:43:52.931988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-11 18:43:52.948927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-11 18:43:53.375863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:43:53.376081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:53.376749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:53.377244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-11 18:43:53.381923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:43:53.383234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-11 18:43:53.383260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-11 18:43:53.383271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-11 18:43:53.384232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:53.384836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:43:53.385364: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-11 18:43:53.385407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/object_detection/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\n",
            "I1211 18:43:55.504573 140545020077952 saver.py:1284] Restoring parameters from /content/models/research/object_detection/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1211 18:43:55.943628 140545020077952 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1211 18:43:56.371825 140545020077952 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I1211 18:44:02.774939 140545020077952 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n",
            "I1211 18:44:03.091328 140541315270400 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I1211 18:44:03.094378 140545020077952 learning.py:768] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I1211 18:44:15.433287 140541348841216 supervisor.py:1099] global_step/sec: 0\n",
            "2019-12-11 18:44:16.847564: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 597196800 exceeds 10% of system memory.\n",
            "2019-12-11 18:44:17.571540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:44:18.562950: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 597196800 exceeds 10% of system memory.\n",
            "2019-12-11 18:44:20.405250: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 597196800 exceeds 10% of system memory.\n",
            "2019-12-11 18:44:21.440042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:44:21.677864: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 597196800 exceeds 10% of system memory.\n",
            "2019-12-11 18:44:23.643202: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 597196800 exceeds 10% of system memory.\n",
            "INFO:tensorflow:Recording summary at step 1.\n",
            "I1211 18:44:25.573609 140541340448512 supervisor.py:1050] Recording summary at step 1.\n",
            "INFO:tensorflow:global step 1: loss = 15.5054 (22.300 sec/step)\n",
            "I1211 18:44:26.118877 140545020077952 learning.py:507] global step 1: loss = 15.5054 (22.300 sec/step)\n",
            "INFO:tensorflow:global step 2: loss = 13.4927 (3.015 sec/step)\n",
            "I1211 18:44:30.162670 140545020077952 learning.py:507] global step 2: loss = 13.4927 (3.015 sec/step)\n",
            "INFO:tensorflow:global step 3: loss = 12.0840 (2.913 sec/step)\n",
            "I1211 18:44:33.755572 140545020077952 learning.py:507] global step 3: loss = 12.0840 (2.913 sec/step)\n",
            "INFO:tensorflow:global step 4: loss = 11.2257 (1.370 sec/step)\n",
            "I1211 18:44:35.130965 140545020077952 learning.py:507] global step 4: loss = 11.2257 (1.370 sec/step)\n",
            "INFO:tensorflow:global step 5: loss = 10.5026 (0.694 sec/step)\n",
            "I1211 18:44:35.827712 140545020077952 learning.py:507] global step 5: loss = 10.5026 (0.694 sec/step)\n",
            "INFO:tensorflow:global step 6: loss = 10.2195 (1.842 sec/step)\n",
            "I1211 18:44:37.671837 140545020077952 learning.py:507] global step 6: loss = 10.2195 (1.842 sec/step)\n",
            "INFO:tensorflow:global step 7: loss = 9.3088 (0.573 sec/step)\n",
            "I1211 18:44:38.468859 140545020077952 learning.py:507] global step 7: loss = 9.3088 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 8: loss = 8.7707 (1.136 sec/step)\n",
            "I1211 18:44:39.802391 140545020077952 learning.py:507] global step 8: loss = 8.7707 (1.136 sec/step)\n",
            "INFO:tensorflow:global step 9: loss = 8.4926 (0.630 sec/step)\n",
            "I1211 18:44:40.511135 140545020077952 learning.py:507] global step 9: loss = 8.4926 (0.630 sec/step)\n",
            "INFO:tensorflow:global step 10: loss = 8.4575 (1.157 sec/step)\n",
            "I1211 18:44:41.911956 140545020077952 learning.py:507] global step 10: loss = 8.4575 (1.157 sec/step)\n",
            "INFO:tensorflow:global step 11: loss = 7.9654 (0.615 sec/step)\n",
            "I1211 18:44:42.695646 140545020077952 learning.py:507] global step 11: loss = 7.9654 (0.615 sec/step)\n",
            "INFO:tensorflow:global step 12: loss = 7.9948 (1.307 sec/step)\n",
            "I1211 18:44:44.144268 140545020077952 learning.py:507] global step 12: loss = 7.9948 (1.307 sec/step)\n",
            "INFO:tensorflow:global step 13: loss = 7.5310 (0.612 sec/step)\n",
            "I1211 18:44:44.953373 140545020077952 learning.py:507] global step 13: loss = 7.5310 (0.612 sec/step)\n",
            "INFO:tensorflow:global step 14: loss = 7.3895 (0.524 sec/step)\n",
            "I1211 18:44:45.648284 140545020077952 learning.py:507] global step 14: loss = 7.3895 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 15: loss = 7.0206 (1.593 sec/step)\n",
            "I1211 18:44:47.243578 140545020077952 learning.py:507] global step 15: loss = 7.0206 (1.593 sec/step)\n",
            "INFO:tensorflow:global step 16: loss = 6.8567 (0.603 sec/step)\n",
            "I1211 18:44:48.128733 140545020077952 learning.py:507] global step 16: loss = 6.8567 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 17: loss = 6.8972 (1.604 sec/step)\n",
            "I1211 18:44:49.769081 140545020077952 learning.py:507] global step 17: loss = 6.8972 (1.604 sec/step)\n",
            "INFO:tensorflow:global step 18: loss = 6.3548 (0.493 sec/step)\n",
            "I1211 18:44:50.446908 140545020077952 learning.py:507] global step 18: loss = 6.3548 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 19: loss = 6.3558 (0.494 sec/step)\n",
            "I1211 18:44:51.238792 140545020077952 learning.py:507] global step 19: loss = 6.3558 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 20: loss = 6.4093 (1.524 sec/step)\n",
            "I1211 18:44:52.764614 140545020077952 learning.py:507] global step 20: loss = 6.4093 (1.524 sec/step)\n",
            "INFO:tensorflow:global step 21: loss = 6.4898 (0.623 sec/step)\n",
            "I1211 18:44:53.640762 140545020077952 learning.py:507] global step 21: loss = 6.4898 (0.623 sec/step)\n",
            "INFO:tensorflow:global step 22: loss = 6.9626 (0.585 sec/step)\n",
            "I1211 18:44:54.517025 140545020077952 learning.py:507] global step 22: loss = 6.9626 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 23: loss = 6.5169 (1.194 sec/step)\n",
            "I1211 18:44:55.832770 140545020077952 learning.py:507] global step 23: loss = 6.5169 (1.194 sec/step)\n",
            "INFO:tensorflow:global step 24: loss = 5.8272 (0.514 sec/step)\n",
            "I1211 18:44:56.533860 140545020077952 learning.py:507] global step 24: loss = 5.8272 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 25: loss = 6.1090 (0.625 sec/step)\n",
            "I1211 18:44:57.683498 140545020077952 learning.py:507] global step 25: loss = 6.1090 (0.625 sec/step)\n",
            "INFO:tensorflow:global step 26: loss = 6.1591 (1.147 sec/step)\n",
            "I1211 18:44:58.942150 140545020077952 learning.py:507] global step 26: loss = 6.1591 (1.147 sec/step)\n",
            "INFO:tensorflow:global step 27: loss = 6.5337 (0.652 sec/step)\n",
            "I1211 18:44:59.943123 140545020077952 learning.py:507] global step 27: loss = 6.5337 (0.652 sec/step)\n",
            "INFO:tensorflow:global step 28: loss = 5.6984 (1.088 sec/step)\n",
            "I1211 18:45:01.057570 140545020077952 learning.py:507] global step 28: loss = 5.6984 (1.088 sec/step)\n",
            "INFO:tensorflow:global step 29: loss = 5.4701 (0.567 sec/step)\n",
            "I1211 18:45:01.831591 140545020077952 learning.py:507] global step 29: loss = 5.4701 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 30: loss = 6.4529 (0.605 sec/step)\n",
            "I1211 18:45:02.556454 140545020077952 learning.py:507] global step 30: loss = 6.4529 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 31: loss = 5.5934 (1.712 sec/step)\n",
            "I1211 18:45:04.270458 140545020077952 learning.py:507] global step 31: loss = 5.5934 (1.712 sec/step)\n",
            "INFO:tensorflow:global step 32: loss = 5.4124 (0.671 sec/step)\n",
            "I1211 18:45:05.042548 140545020077952 learning.py:507] global step 32: loss = 5.4124 (0.671 sec/step)\n",
            "INFO:tensorflow:global step 33: loss = 6.2253 (0.498 sec/step)\n",
            "I1211 18:45:06.125770 140545020077952 learning.py:507] global step 33: loss = 6.2253 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 34: loss = 5.6449 (0.522 sec/step)\n",
            "I1211 18:45:06.805261 140545020077952 learning.py:507] global step 34: loss = 5.6449 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 35: loss = 6.1383 (1.587 sec/step)\n",
            "I1211 18:45:08.516515 140545020077952 learning.py:507] global step 35: loss = 6.1383 (1.587 sec/step)\n",
            "INFO:tensorflow:global step 36: loss = 5.4103 (0.673 sec/step)\n",
            "I1211 18:45:09.203893 140545020077952 learning.py:507] global step 36: loss = 5.4103 (0.673 sec/step)\n",
            "INFO:tensorflow:global step 37: loss = 5.1517 (1.466 sec/step)\n",
            "I1211 18:45:10.700152 140545020077952 learning.py:507] global step 37: loss = 5.1517 (1.466 sec/step)\n",
            "INFO:tensorflow:global step 38: loss = 5.0888 (1.004 sec/step)\n",
            "I1211 18:45:11.706123 140545020077952 learning.py:507] global step 38: loss = 5.0888 (1.004 sec/step)\n",
            "INFO:tensorflow:global step 39: loss = 5.9355 (1.042 sec/step)\n",
            "I1211 18:45:12.749538 140545020077952 learning.py:507] global step 39: loss = 5.9355 (1.042 sec/step)\n",
            "INFO:tensorflow:global step 40: loss = 5.9376 (1.030 sec/step)\n",
            "I1211 18:45:13.780986 140545020077952 learning.py:507] global step 40: loss = 5.9376 (1.030 sec/step)\n",
            "INFO:tensorflow:global step 41: loss = 5.2291 (0.495 sec/step)\n",
            "I1211 18:45:14.484811 140545020077952 learning.py:507] global step 41: loss = 5.2291 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 42: loss = 5.3723 (0.698 sec/step)\n",
            "I1211 18:45:15.678889 140545020077952 learning.py:507] global step 42: loss = 5.3723 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 43: loss = 6.0206 (0.661 sec/step)\n",
            "I1211 18:45:16.531874 140545020077952 learning.py:507] global step 43: loss = 6.0206 (0.661 sec/step)\n",
            "INFO:tensorflow:global step 44: loss = 5.2888 (1.768 sec/step)\n",
            "I1211 18:45:18.354327 140545020077952 learning.py:507] global step 44: loss = 5.2888 (1.768 sec/step)\n",
            "INFO:tensorflow:global step 45: loss = 4.7374 (0.611 sec/step)\n",
            "I1211 18:45:19.249838 140545020077952 learning.py:507] global step 45: loss = 4.7374 (0.611 sec/step)\n",
            "INFO:tensorflow:global step 46: loss = 5.0088 (0.634 sec/step)\n",
            "I1211 18:45:19.985227 140545020077952 learning.py:507] global step 46: loss = 5.0088 (0.634 sec/step)\n",
            "INFO:tensorflow:global step 47: loss = 5.0205 (1.574 sec/step)\n",
            "I1211 18:45:21.562446 140545020077952 learning.py:507] global step 47: loss = 5.0205 (1.574 sec/step)\n",
            "INFO:tensorflow:global step 48: loss = 4.5826 (0.730 sec/step)\n",
            "I1211 18:45:22.486928 140545020077952 learning.py:507] global step 48: loss = 4.5826 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 49: loss = 5.2387 (0.710 sec/step)\n",
            "I1211 18:45:23.478288 140545020077952 learning.py:507] global step 49: loss = 5.2387 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 50: loss = 4.9615 (1.123 sec/step)\n",
            "I1211 18:45:24.731437 140545020077952 learning.py:507] global step 50: loss = 4.9615 (1.123 sec/step)\n",
            "INFO:tensorflow:global step 51: loss = 4.0474 (0.494 sec/step)\n",
            "I1211 18:45:25.554939 140545020077952 learning.py:507] global step 51: loss = 4.0474 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 52: loss = 4.3959 (0.492 sec/step)\n",
            "I1211 18:45:26.197156 140545020077952 learning.py:507] global step 52: loss = 4.3959 (0.492 sec/step)\n",
            "INFO:tensorflow:global step 53: loss = 4.1817 (0.508 sec/step)\n",
            "I1211 18:45:26.707706 140545020077952 learning.py:507] global step 53: loss = 4.1817 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 54: loss = 4.6984 (2.299 sec/step)\n",
            "I1211 18:45:29.009274 140545020077952 learning.py:507] global step 54: loss = 4.6984 (2.299 sec/step)\n",
            "INFO:tensorflow:global step 55: loss = 4.8965 (0.667 sec/step)\n",
            "I1211 18:45:29.735430 140545020077952 learning.py:507] global step 55: loss = 4.8965 (0.667 sec/step)\n",
            "INFO:tensorflow:global step 56: loss = 4.1669 (1.514 sec/step)\n",
            "I1211 18:45:31.520795 140545020077952 learning.py:507] global step 56: loss = 4.1669 (1.514 sec/step)\n",
            "INFO:tensorflow:global step 57: loss = 4.5759 (1.021 sec/step)\n",
            "I1211 18:45:32.543452 140545020077952 learning.py:507] global step 57: loss = 4.5759 (1.021 sec/step)\n",
            "INFO:tensorflow:global step 58: loss = 3.9095 (0.538 sec/step)\n",
            "I1211 18:45:33.382219 140545020077952 learning.py:507] global step 58: loss = 3.9095 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 59: loss = 4.3521 (1.153 sec/step)\n",
            "I1211 18:45:34.675363 140545020077952 learning.py:507] global step 59: loss = 4.3521 (1.153 sec/step)\n",
            "INFO:tensorflow:global step 60: loss = 4.3333 (1.015 sec/step)\n",
            "I1211 18:45:35.691964 140545020077952 learning.py:507] global step 60: loss = 4.3333 (1.015 sec/step)\n",
            "INFO:tensorflow:global step 61: loss = 4.6559 (0.498 sec/step)\n",
            "I1211 18:45:36.411560 140545020077952 learning.py:507] global step 61: loss = 4.6559 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 62: loss = 4.0758 (1.198 sec/step)\n",
            "I1211 18:45:37.767538 140545020077952 learning.py:507] global step 62: loss = 4.0758 (1.198 sec/step)\n",
            "INFO:tensorflow:global step 63: loss = 4.6213 (0.582 sec/step)\n",
            "I1211 18:45:38.577224 140545020077952 learning.py:507] global step 63: loss = 4.6213 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 64: loss = 4.0420 (0.565 sec/step)\n",
            "I1211 18:45:39.605332 140545020077952 learning.py:507] global step 64: loss = 4.0420 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 65: loss = 4.6604 (0.589 sec/step)\n",
            "I1211 18:45:40.515974 140545020077952 learning.py:507] global step 65: loss = 4.6604 (0.589 sec/step)\n",
            "INFO:tensorflow:global step 66: loss = 4.7277 (0.968 sec/step)\n",
            "I1211 18:45:41.636185 140545020077952 learning.py:507] global step 66: loss = 4.7277 (0.968 sec/step)\n",
            "INFO:tensorflow:global step 67: loss = 4.0334 (1.059 sec/step)\n",
            "I1211 18:45:42.703567 140545020077952 learning.py:507] global step 67: loss = 4.0334 (1.059 sec/step)\n",
            "INFO:tensorflow:global step 68: loss = 5.0381 (0.573 sec/step)\n",
            "I1211 18:45:43.423687 140545020077952 learning.py:507] global step 68: loss = 5.0381 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 69: loss = 3.9799 (1.098 sec/step)\n",
            "I1211 18:45:44.774043 140545020077952 learning.py:507] global step 69: loss = 3.9799 (1.098 sec/step)\n",
            "INFO:tensorflow:global step 70: loss = 4.7474 (0.567 sec/step)\n",
            "I1211 18:45:45.434410 140545020077952 learning.py:507] global step 70: loss = 4.7474 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 71: loss = 5.2210 (1.266 sec/step)\n",
            "I1211 18:45:46.836221 140545020077952 learning.py:507] global step 71: loss = 5.2210 (1.266 sec/step)\n",
            "INFO:tensorflow:global step 72: loss = 4.4305 (0.527 sec/step)\n",
            "I1211 18:45:47.628959 140545020077952 learning.py:507] global step 72: loss = 4.4305 (0.527 sec/step)\n",
            "INFO:tensorflow:global step 73: loss = 3.9604 (0.617 sec/step)\n",
            "I1211 18:45:48.650917 140545020077952 learning.py:507] global step 73: loss = 3.9604 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 74: loss = 3.9524 (1.142 sec/step)\n",
            "I1211 18:45:49.856308 140545020077952 learning.py:507] global step 74: loss = 3.9524 (1.142 sec/step)\n",
            "INFO:tensorflow:global step 75: loss = 3.8974 (0.500 sec/step)\n",
            "I1211 18:45:50.558912 140545020077952 learning.py:507] global step 75: loss = 3.8974 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 76: loss = 4.4638 (1.266 sec/step)\n",
            "I1211 18:45:51.958381 140545020077952 learning.py:507] global step 76: loss = 4.4638 (1.266 sec/step)\n",
            "INFO:tensorflow:global step 77: loss = 3.8332 (0.482 sec/step)\n",
            "I1211 18:45:52.557535 140545020077952 learning.py:507] global step 77: loss = 3.8332 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 78: loss = 4.4544 (1.243 sec/step)\n",
            "I1211 18:45:54.018705 140545020077952 learning.py:507] global step 78: loss = 4.4544 (1.243 sec/step)\n",
            "INFO:tensorflow:global step 79: loss = 4.0156 (0.573 sec/step)\n",
            "I1211 18:45:54.824856 140545020077952 learning.py:507] global step 79: loss = 4.0156 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 80: loss = 4.5060 (1.177 sec/step)\n",
            "I1211 18:45:56.085112 140545020077952 learning.py:507] global step 80: loss = 4.5060 (1.177 sec/step)\n",
            "INFO:tensorflow:global step 81: loss = 4.5730 (0.542 sec/step)\n",
            "I1211 18:45:56.629419 140545020077952 learning.py:507] global step 81: loss = 4.5730 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 82: loss = 3.4692 (0.650 sec/step)\n",
            "I1211 18:45:57.281985 140545020077952 learning.py:507] global step 82: loss = 3.4692 (0.650 sec/step)\n",
            "INFO:tensorflow:global step 83: loss = 3.9912 (3.148 sec/step)\n",
            "I1211 18:46:00.435917 140545020077952 learning.py:507] global step 83: loss = 3.9912 (3.148 sec/step)\n",
            "INFO:tensorflow:global step 84: loss = 4.5100 (0.783 sec/step)\n",
            "I1211 18:46:01.474195 140545020077952 learning.py:507] global step 84: loss = 4.5100 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 85: loss = 3.9018 (0.658 sec/step)\n",
            "I1211 18:46:02.708773 140545020077952 learning.py:507] global step 85: loss = 3.9018 (0.658 sec/step)\n",
            "INFO:tensorflow:global step 86: loss = 4.2810 (2.340 sec/step)\n",
            "I1211 18:46:05.093049 140545020077952 learning.py:507] global step 86: loss = 4.2810 (2.340 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 86.\n",
            "I1211 18:46:05.115360 140541340448512 supervisor.py:1050] Recording summary at step 86.\n",
            "INFO:tensorflow:global step 87: loss = 3.2854 (0.647 sec/step)\n",
            "I1211 18:46:05.901959 140545020077952 learning.py:507] global step 87: loss = 3.2854 (0.647 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.781625\n",
            "I1211 18:46:06.742471 140541348841216 supervisor.py:1099] global_step/sec: 0.781625\n",
            "INFO:tensorflow:global step 88: loss = 4.2428 (1.309 sec/step)\n",
            "I1211 18:46:07.483586 140545020077952 learning.py:507] global step 88: loss = 4.2428 (1.309 sec/step)\n",
            "INFO:tensorflow:global step 89: loss = 4.1293 (0.596 sec/step)\n",
            "I1211 18:46:08.081452 140545020077952 learning.py:507] global step 89: loss = 4.1293 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 90: loss = 3.8852 (0.556 sec/step)\n",
            "I1211 18:46:09.097330 140545020077952 learning.py:507] global step 90: loss = 3.8852 (0.556 sec/step)\n",
            "INFO:tensorflow:global step 91: loss = 4.2412 (1.939 sec/step)\n",
            "I1211 18:46:11.141212 140545020077952 learning.py:507] global step 91: loss = 4.2412 (1.939 sec/step)\n",
            "INFO:tensorflow:global step 92: loss = 4.2519 (0.651 sec/step)\n",
            "I1211 18:46:12.070249 140545020077952 learning.py:507] global step 92: loss = 4.2519 (0.651 sec/step)\n",
            "INFO:tensorflow:global step 93: loss = 4.0789 (0.674 sec/step)\n",
            "I1211 18:46:12.791782 140545020077952 learning.py:507] global step 93: loss = 4.0789 (0.674 sec/step)\n",
            "INFO:tensorflow:global step 94: loss = 4.4581 (1.674 sec/step)\n",
            "I1211 18:46:14.467215 140545020077952 learning.py:507] global step 94: loss = 4.4581 (1.674 sec/step)\n",
            "INFO:tensorflow:global step 95: loss = 3.6876 (0.657 sec/step)\n",
            "I1211 18:46:15.308382 140545020077952 learning.py:507] global step 95: loss = 3.6876 (0.657 sec/step)\n",
            "INFO:tensorflow:global step 96: loss = 4.0683 (0.702 sec/step)\n",
            "I1211 18:46:16.358054 140545020077952 learning.py:507] global step 96: loss = 4.0683 (0.702 sec/step)\n",
            "INFO:tensorflow:global step 97: loss = 4.7527 (0.600 sec/step)\n",
            "I1211 18:46:17.155358 140545020077952 learning.py:507] global step 97: loss = 4.7527 (0.600 sec/step)\n",
            "INFO:tensorflow:global step 98: loss = 4.2457 (0.593 sec/step)\n",
            "I1211 18:46:18.297345 140545020077952 learning.py:507] global step 98: loss = 4.2457 (0.593 sec/step)\n",
            "INFO:tensorflow:global step 99: loss = 3.8671 (1.311 sec/step)\n",
            "I1211 18:46:19.637629 140545020077952 learning.py:507] global step 99: loss = 3.8671 (1.311 sec/step)\n",
            "INFO:tensorflow:global step 100: loss = 4.1956 (0.803 sec/step)\n",
            "I1211 18:46:20.543511 140545020077952 learning.py:507] global step 100: loss = 4.1956 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 101: loss = 4.6793 (0.667 sec/step)\n",
            "I1211 18:46:21.427332 140545020077952 learning.py:507] global step 101: loss = 4.6793 (0.667 sec/step)\n",
            "INFO:tensorflow:global step 102: loss = 4.2712 (0.610 sec/step)\n",
            "I1211 18:46:22.270280 140545020077952 learning.py:507] global step 102: loss = 4.2712 (0.610 sec/step)\n",
            "INFO:tensorflow:global step 103: loss = 4.1467 (1.063 sec/step)\n",
            "I1211 18:46:23.547331 140545020077952 learning.py:507] global step 103: loss = 4.1467 (1.063 sec/step)\n",
            "INFO:tensorflow:global step 104: loss = 3.9238 (0.563 sec/step)\n",
            "I1211 18:46:24.330798 140545020077952 learning.py:507] global step 104: loss = 3.9238 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 105: loss = 3.8777 (1.119 sec/step)\n",
            "I1211 18:46:25.612998 140545020077952 learning.py:507] global step 105: loss = 3.8777 (1.119 sec/step)\n",
            "INFO:tensorflow:global step 106: loss = 4.1573 (0.606 sec/step)\n",
            "I1211 18:46:26.409814 140545020077952 learning.py:507] global step 106: loss = 4.1573 (0.606 sec/step)\n",
            "INFO:tensorflow:global step 107: loss = 4.3735 (1.136 sec/step)\n",
            "I1211 18:46:27.683497 140545020077952 learning.py:507] global step 107: loss = 4.3735 (1.136 sec/step)\n",
            "INFO:tensorflow:global step 108: loss = 3.4599 (1.046 sec/step)\n",
            "I1211 18:46:28.731290 140545020077952 learning.py:507] global step 108: loss = 3.4599 (1.046 sec/step)\n",
            "INFO:tensorflow:global step 109: loss = 3.6306 (0.570 sec/step)\n",
            "I1211 18:46:29.466918 140545020077952 learning.py:507] global step 109: loss = 3.6306 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 110: loss = 4.2514 (1.134 sec/step)\n",
            "I1211 18:46:30.731589 140545020077952 learning.py:507] global step 110: loss = 4.2514 (1.134 sec/step)\n",
            "INFO:tensorflow:global step 111: loss = 4.0567 (0.730 sec/step)\n",
            "I1211 18:46:31.586434 140545020077952 learning.py:507] global step 111: loss = 4.0567 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 112: loss = 3.5070 (0.535 sec/step)\n",
            "I1211 18:46:32.474506 140545020077952 learning.py:507] global step 112: loss = 3.5070 (0.535 sec/step)\n",
            "INFO:tensorflow:global step 113: loss = 4.0094 (0.619 sec/step)\n",
            "I1211 18:46:33.248087 140545020077952 learning.py:507] global step 113: loss = 4.0094 (0.619 sec/step)\n",
            "INFO:tensorflow:global step 114: loss = 3.6047 (1.156 sec/step)\n",
            "I1211 18:46:34.628520 140545020077952 learning.py:507] global step 114: loss = 3.6047 (1.156 sec/step)\n",
            "INFO:tensorflow:global step 115: loss = 4.0631 (0.486 sec/step)\n",
            "I1211 18:46:35.315350 140545020077952 learning.py:507] global step 115: loss = 4.0631 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 116: loss = 4.6314 (0.558 sec/step)\n",
            "I1211 18:46:36.437273 140545020077952 learning.py:507] global step 116: loss = 4.6314 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 117: loss = 3.8786 (0.985 sec/step)\n",
            "I1211 18:46:37.548707 140545020077952 learning.py:507] global step 117: loss = 3.8786 (0.985 sec/step)\n",
            "INFO:tensorflow:global step 118: loss = 3.7357 (0.956 sec/step)\n",
            "I1211 18:46:38.506193 140545020077952 learning.py:507] global step 118: loss = 3.7357 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 119: loss = 4.3901 (0.553 sec/step)\n",
            "I1211 18:46:39.263633 140545020077952 learning.py:507] global step 119: loss = 4.3901 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 120: loss = 3.5052 (1.235 sec/step)\n",
            "I1211 18:46:40.500910 140545020077952 learning.py:507] global step 120: loss = 3.5052 (1.235 sec/step)\n",
            "INFO:tensorflow:global step 121: loss = 4.5015 (0.645 sec/step)\n",
            "I1211 18:46:41.343675 140545020077952 learning.py:507] global step 121: loss = 4.5015 (0.645 sec/step)\n",
            "INFO:tensorflow:global step 122: loss = 3.9795 (1.140 sec/step)\n",
            "I1211 18:46:42.517328 140545020077952 learning.py:507] global step 122: loss = 3.9795 (1.140 sec/step)\n",
            "INFO:tensorflow:global step 123: loss = 4.4090 (0.568 sec/step)\n",
            "I1211 18:46:43.248362 140545020077952 learning.py:507] global step 123: loss = 4.4090 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 124: loss = 3.7408 (1.282 sec/step)\n",
            "I1211 18:46:44.539397 140545020077952 learning.py:507] global step 124: loss = 3.7408 (1.282 sec/step)\n",
            "INFO:tensorflow:global step 125: loss = 3.9461 (0.559 sec/step)\n",
            "I1211 18:46:45.373576 140545020077952 learning.py:507] global step 125: loss = 3.9461 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 126: loss = 3.9679 (1.156 sec/step)\n",
            "I1211 18:46:46.601346 140545020077952 learning.py:507] global step 126: loss = 3.9679 (1.156 sec/step)\n",
            "INFO:tensorflow:global step 127: loss = 3.6828 (0.507 sec/step)\n",
            "I1211 18:46:47.291174 140545020077952 learning.py:507] global step 127: loss = 3.6828 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 128: loss = 3.1995 (1.083 sec/step)\n",
            "I1211 18:46:48.604860 140545020077952 learning.py:507] global step 128: loss = 3.1995 (1.083 sec/step)\n",
            "INFO:tensorflow:global step 129: loss = 3.6154 (0.691 sec/step)\n",
            "I1211 18:46:49.374852 140545020077952 learning.py:507] global step 129: loss = 3.6154 (0.691 sec/step)\n",
            "INFO:tensorflow:global step 130: loss = 3.1664 (0.640 sec/step)\n",
            "I1211 18:46:50.393967 140545020077952 learning.py:507] global step 130: loss = 3.1664 (0.640 sec/step)\n",
            "INFO:tensorflow:global step 131: loss = 3.8944 (0.594 sec/step)\n",
            "I1211 18:46:51.391579 140545020077952 learning.py:507] global step 131: loss = 3.8944 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 132: loss = 4.7959 (1.171 sec/step)\n",
            "I1211 18:46:52.611247 140545020077952 learning.py:507] global step 132: loss = 4.7959 (1.171 sec/step)\n",
            "INFO:tensorflow:global step 133: loss = 4.4236 (0.663 sec/step)\n",
            "I1211 18:46:53.456204 140545020077952 learning.py:507] global step 133: loss = 4.4236 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 134: loss = 4.1887 (0.563 sec/step)\n",
            "I1211 18:46:54.292581 140545020077952 learning.py:507] global step 134: loss = 4.1887 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 135: loss = 4.4919 (1.121 sec/step)\n",
            "I1211 18:46:55.578975 140545020077952 learning.py:507] global step 135: loss = 4.4919 (1.121 sec/step)\n",
            "INFO:tensorflow:global step 136: loss = 5.0912 (0.573 sec/step)\n",
            "I1211 18:46:56.367738 140545020077952 learning.py:507] global step 136: loss = 5.0912 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 137: loss = 3.5343 (1.237 sec/step)\n",
            "I1211 18:46:57.613529 140545020077952 learning.py:507] global step 137: loss = 3.5343 (1.237 sec/step)\n",
            "INFO:tensorflow:global step 138: loss = 3.3455 (0.577 sec/step)\n",
            "I1211 18:46:58.245662 140545020077952 learning.py:507] global step 138: loss = 3.3455 (0.577 sec/step)\n",
            "INFO:tensorflow:global step 139: loss = 3.1131 (1.183 sec/step)\n",
            "I1211 18:46:59.655584 140545020077952 learning.py:507] global step 139: loss = 3.1131 (1.183 sec/step)\n",
            "INFO:tensorflow:global step 140: loss = 3.3643 (0.684 sec/step)\n",
            "I1211 18:47:00.606296 140545020077952 learning.py:507] global step 140: loss = 3.3643 (0.684 sec/step)\n",
            "INFO:tensorflow:global step 141: loss = 4.0048 (0.624 sec/step)\n",
            "I1211 18:47:01.319258 140545020077952 learning.py:507] global step 141: loss = 4.0048 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 142: loss = 3.4681 (0.666 sec/step)\n",
            "I1211 18:47:02.399719 140545020077952 learning.py:507] global step 142: loss = 3.4681 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 143: loss = 3.0752 (1.163 sec/step)\n",
            "I1211 18:47:03.626263 140545020077952 learning.py:507] global step 143: loss = 3.0752 (1.163 sec/step)\n",
            "INFO:tensorflow:global step 144: loss = 3.3866 (0.567 sec/step)\n",
            "I1211 18:47:04.372848 140545020077952 learning.py:507] global step 144: loss = 3.3866 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 145: loss = 3.2629 (0.585 sec/step)\n",
            "I1211 18:47:05.257272 140545020077952 learning.py:507] global step 145: loss = 3.2629 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 146: loss = 3.2336 (1.152 sec/step)\n",
            "I1211 18:47:06.668251 140545020077952 learning.py:507] global step 146: loss = 3.2336 (1.152 sec/step)\n",
            "INFO:tensorflow:global step 147: loss = 3.5753 (0.495 sec/step)\n",
            "I1211 18:47:07.392505 140545020077952 learning.py:507] global step 147: loss = 3.5753 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 148: loss = 3.9577 (1.063 sec/step)\n",
            "I1211 18:47:08.624899 140545020077952 learning.py:507] global step 148: loss = 3.9577 (1.063 sec/step)\n",
            "INFO:tensorflow:global step 149: loss = 3.8952 (0.572 sec/step)\n",
            "I1211 18:47:09.257124 140545020077952 learning.py:507] global step 149: loss = 3.8952 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 150: loss = 3.4235 (1.342 sec/step)\n",
            "I1211 18:47:10.654968 140545020077952 learning.py:507] global step 150: loss = 3.4235 (1.342 sec/step)\n",
            "INFO:tensorflow:global step 151: loss = 3.2088 (0.605 sec/step)\n",
            "I1211 18:47:11.297989 140545020077952 learning.py:507] global step 151: loss = 3.2088 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 152: loss = 4.1465 (0.541 sec/step)\n",
            "I1211 18:47:12.095554 140545020077952 learning.py:507] global step 152: loss = 4.1465 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 153: loss = 3.3577 (0.797 sec/step)\n",
            "I1211 18:47:12.946659 140545020077952 learning.py:507] global step 153: loss = 3.3577 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 154: loss = 3.5297 (1.526 sec/step)\n",
            "I1211 18:47:14.660715 140545020077952 learning.py:507] global step 154: loss = 3.5297 (1.526 sec/step)\n",
            "INFO:tensorflow:global step 155: loss = 3.0908 (0.575 sec/step)\n",
            "I1211 18:47:15.455130 140545020077952 learning.py:507] global step 155: loss = 3.0908 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 156: loss = 3.0431 (1.162 sec/step)\n",
            "I1211 18:47:16.679103 140545020077952 learning.py:507] global step 156: loss = 3.0431 (1.162 sec/step)\n",
            "INFO:tensorflow:global step 157: loss = 2.8788 (0.604 sec/step)\n",
            "I1211 18:47:17.516733 140545020077952 learning.py:507] global step 157: loss = 2.8788 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 158: loss = 3.2942 (0.666 sec/step)\n",
            "I1211 18:47:18.556677 140545020077952 learning.py:507] global step 158: loss = 3.2942 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 159: loss = 3.7196 (0.572 sec/step)\n",
            "I1211 18:47:19.478305 140545020077952 learning.py:507] global step 159: loss = 3.7196 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 160: loss = 3.0521 (1.120 sec/step)\n",
            "I1211 18:47:20.620907 140545020077952 learning.py:507] global step 160: loss = 3.0521 (1.120 sec/step)\n",
            "INFO:tensorflow:global step 161: loss = 3.6105 (0.538 sec/step)\n",
            "I1211 18:47:21.356502 140545020077952 learning.py:507] global step 161: loss = 3.6105 (0.538 sec/step)\n",
            "INFO:tensorflow:global step 162: loss = 3.3161 (0.525 sec/step)\n",
            "I1211 18:47:22.210813 140545020077952 learning.py:507] global step 162: loss = 3.3161 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 163: loss = 3.1138 (1.273 sec/step)\n",
            "I1211 18:47:23.709431 140545020077952 learning.py:507] global step 163: loss = 3.1138 (1.273 sec/step)\n",
            "INFO:tensorflow:global step 164: loss = 3.3359 (0.699 sec/step)\n",
            "I1211 18:47:24.414635 140545020077952 learning.py:507] global step 164: loss = 3.3359 (0.699 sec/step)\n",
            "INFO:tensorflow:global step 165: loss = 3.4529 (1.243 sec/step)\n",
            "I1211 18:47:25.753530 140545020077952 learning.py:507] global step 165: loss = 3.4529 (1.243 sec/step)\n",
            "INFO:tensorflow:global step 166: loss = 3.3473 (1.003 sec/step)\n",
            "I1211 18:47:26.758171 140545020077952 learning.py:507] global step 166: loss = 3.3473 (1.003 sec/step)\n",
            "INFO:tensorflow:global step 167: loss = 3.9314 (0.808 sec/step)\n",
            "I1211 18:47:27.763189 140545020077952 learning.py:507] global step 167: loss = 3.9314 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 168: loss = 3.3322 (1.136 sec/step)\n",
            "I1211 18:47:28.901333 140545020077952 learning.py:507] global step 168: loss = 3.3322 (1.136 sec/step)\n",
            "INFO:tensorflow:global step 169: loss = 3.0157 (0.572 sec/step)\n",
            "I1211 18:47:29.696845 140545020077952 learning.py:507] global step 169: loss = 3.0157 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 170: loss = 3.2928 (1.040 sec/step)\n",
            "I1211 18:47:30.893853 140545020077952 learning.py:507] global step 170: loss = 3.2928 (1.040 sec/step)\n",
            "INFO:tensorflow:global step 171: loss = 2.8023 (0.612 sec/step)\n",
            "I1211 18:47:31.689534 140545020077952 learning.py:507] global step 171: loss = 2.8023 (0.612 sec/step)\n",
            "INFO:tensorflow:global step 172: loss = 3.3905 (0.573 sec/step)\n",
            "I1211 18:47:32.406962 140545020077952 learning.py:507] global step 172: loss = 3.3905 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 173: loss = 4.3676 (0.814 sec/step)\n",
            "I1211 18:47:33.223157 140545020077952 learning.py:507] global step 173: loss = 4.3676 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 174: loss = 3.6953 (1.982 sec/step)\n",
            "I1211 18:47:35.375380 140545020077952 learning.py:507] global step 174: loss = 3.6953 (1.982 sec/step)\n",
            "INFO:tensorflow:global step 175: loss = 3.6621 (0.477 sec/step)\n",
            "I1211 18:47:36.027228 140545020077952 learning.py:507] global step 175: loss = 3.6621 (0.477 sec/step)\n",
            "INFO:tensorflow:global step 176: loss = 3.0451 (0.537 sec/step)\n",
            "I1211 18:47:36.566533 140545020077952 learning.py:507] global step 176: loss = 3.0451 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 177: loss = 4.5821 (2.857 sec/step)\n",
            "I1211 18:47:39.425107 140545020077952 learning.py:507] global step 177: loss = 4.5821 (2.857 sec/step)\n",
            "INFO:tensorflow:global step 178: loss = 3.0388 (0.567 sec/step)\n",
            "I1211 18:47:40.240375 140545020077952 learning.py:507] global step 178: loss = 3.0388 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 179: loss = 3.0720 (1.794 sec/step)\n",
            "I1211 18:47:42.052457 140545020077952 learning.py:507] global step 179: loss = 3.0720 (1.794 sec/step)\n",
            "INFO:tensorflow:global step 180: loss = 3.5589 (0.648 sec/step)\n",
            "I1211 18:47:42.833726 140545020077952 learning.py:507] global step 180: loss = 3.5589 (0.648 sec/step)\n",
            "INFO:tensorflow:global step 181: loss = 3.0733 (0.670 sec/step)\n",
            "I1211 18:47:43.777751 140545020077952 learning.py:507] global step 181: loss = 3.0733 (0.670 sec/step)\n",
            "INFO:tensorflow:global step 182: loss = 3.3392 (0.571 sec/step)\n",
            "I1211 18:47:44.699325 140545020077952 learning.py:507] global step 182: loss = 3.3392 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 183: loss = 3.5285 (1.369 sec/step)\n",
            "I1211 18:47:46.074342 140545020077952 learning.py:507] global step 183: loss = 3.5285 (1.369 sec/step)\n",
            "INFO:tensorflow:global step 184: loss = 2.5108 (0.581 sec/step)\n",
            "I1211 18:47:46.897246 140545020077952 learning.py:507] global step 184: loss = 2.5108 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 185: loss = 3.0656 (1.149 sec/step)\n",
            "I1211 18:47:48.177448 140545020077952 learning.py:507] global step 185: loss = 3.0656 (1.149 sec/step)\n",
            "INFO:tensorflow:global step 186: loss = 3.0536 (1.032 sec/step)\n",
            "I1211 18:47:49.211193 140545020077952 learning.py:507] global step 186: loss = 3.0536 (1.032 sec/step)\n",
            "INFO:tensorflow:global step 187: loss = 3.7146 (0.973 sec/step)\n",
            "I1211 18:47:50.186028 140545020077952 learning.py:507] global step 187: loss = 3.7146 (0.973 sec/step)\n",
            "INFO:tensorflow:global step 188: loss = 3.2503 (0.537 sec/step)\n",
            "I1211 18:47:50.987210 140545020077952 learning.py:507] global step 188: loss = 3.2503 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 189: loss = 2.7815 (1.037 sec/step)\n",
            "I1211 18:47:52.140643 140545020077952 learning.py:507] global step 189: loss = 2.7815 (1.037 sec/step)\n",
            "INFO:tensorflow:global step 190: loss = 3.9159 (0.542 sec/step)\n",
            "I1211 18:47:52.997638 140545020077952 learning.py:507] global step 190: loss = 3.9159 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 191: loss = 3.3480 (0.495 sec/step)\n",
            "I1211 18:47:53.546046 140545020077952 learning.py:507] global step 191: loss = 3.3480 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 192: loss = 3.6120 (1.344 sec/step)\n",
            "I1211 18:47:54.893870 140545020077952 learning.py:507] global step 192: loss = 3.6120 (1.344 sec/step)\n",
            "INFO:tensorflow:global step 193: loss = 4.5970 (1.118 sec/step)\n",
            "I1211 18:47:56.013185 140545020077952 learning.py:507] global step 193: loss = 4.5970 (1.118 sec/step)\n",
            "INFO:tensorflow:global step 194: loss = 3.6986 (0.607 sec/step)\n",
            "I1211 18:47:56.747195 140545020077952 learning.py:507] global step 194: loss = 3.6986 (0.607 sec/step)\n",
            "INFO:tensorflow:global step 195: loss = 3.4177 (0.624 sec/step)\n",
            "I1211 18:47:57.842743 140545020077952 learning.py:507] global step 195: loss = 3.4177 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 196: loss = 3.7421 (0.605 sec/step)\n",
            "I1211 18:47:58.545581 140545020077952 learning.py:507] global step 196: loss = 3.7421 (0.605 sec/step)\n",
            "INFO:tensorflow:global step 197: loss = 3.3202 (1.071 sec/step)\n",
            "I1211 18:47:59.899541 140545020077952 learning.py:507] global step 197: loss = 3.3202 (1.071 sec/step)\n",
            "INFO:tensorflow:global step 198: loss = 3.4742 (0.649 sec/step)\n",
            "I1211 18:48:00.724684 140545020077952 learning.py:507] global step 198: loss = 3.4742 (0.649 sec/step)\n",
            "INFO:tensorflow:global step 199: loss = 3.4552 (0.553 sec/step)\n",
            "I1211 18:48:01.610143 140545020077952 learning.py:507] global step 199: loss = 3.4552 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 200: loss = 3.7576 (1.221 sec/step)\n",
            "I1211 18:48:02.875929 140545020077952 learning.py:507] global step 200: loss = 3.7576 (1.221 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 200.\n",
            "I1211 18:48:04.808310 140541340448512 supervisor.py:1050] Recording summary at step 200.\n",
            "INFO:tensorflow:global step 201: loss = 3.5219 (2.112 sec/step)\n",
            "I1211 18:48:04.989359 140545020077952 learning.py:507] global step 201: loss = 3.5219 (2.112 sec/step)\n",
            "INFO:tensorflow:global step 202: loss = 3.0997 (1.042 sec/step)\n",
            "I1211 18:48:06.033114 140545020077952 learning.py:507] global step 202: loss = 3.0997 (1.042 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.959858\n",
            "I1211 18:48:06.549279 140541348841216 supervisor.py:1099] global_step/sec: 0.959858\n",
            "INFO:tensorflow:global step 203: loss = 3.1312 (0.559 sec/step)\n",
            "I1211 18:48:06.903404 140545020077952 learning.py:507] global step 203: loss = 3.1312 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 204: loss = 4.1770 (0.579 sec/step)\n",
            "I1211 18:48:07.741607 140545020077952 learning.py:507] global step 204: loss = 4.1770 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 205: loss = 3.2077 (1.094 sec/step)\n",
            "I1211 18:48:09.056814 140545020077952 learning.py:507] global step 205: loss = 3.2077 (1.094 sec/step)\n",
            "INFO:tensorflow:global step 206: loss = 3.8312 (0.566 sec/step)\n",
            "I1211 18:48:09.882507 140545020077952 learning.py:507] global step 206: loss = 3.8312 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 207: loss = 3.3273 (0.652 sec/step)\n",
            "I1211 18:48:10.953396 140545020077952 learning.py:507] global step 207: loss = 3.3273 (0.652 sec/step)\n",
            "INFO:tensorflow:global step 208: loss = 2.9389 (1.073 sec/step)\n",
            "I1211 18:48:12.055013 140545020077952 learning.py:507] global step 208: loss = 2.9389 (1.073 sec/step)\n",
            "INFO:tensorflow:global step 209: loss = 3.7607 (0.545 sec/step)\n",
            "I1211 18:48:12.731271 140545020077952 learning.py:507] global step 209: loss = 3.7607 (0.545 sec/step)\n",
            "INFO:tensorflow:global step 210: loss = 3.8161 (0.576 sec/step)\n",
            "I1211 18:48:13.919706 140545020077952 learning.py:507] global step 210: loss = 3.8161 (0.576 sec/step)\n",
            "INFO:tensorflow:global step 211: loss = 3.7413 (1.017 sec/step)\n",
            "I1211 18:48:14.955802 140545020077952 learning.py:507] global step 211: loss = 3.7413 (1.017 sec/step)\n",
            "INFO:tensorflow:global step 212: loss = 3.3674 (0.568 sec/step)\n",
            "I1211 18:48:15.759390 140545020077952 learning.py:507] global step 212: loss = 3.3674 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 213: loss = 3.7444 (1.119 sec/step)\n",
            "I1211 18:48:17.016116 140545020077952 learning.py:507] global step 213: loss = 3.7444 (1.119 sec/step)\n",
            "INFO:tensorflow:global step 214: loss = 2.9656 (0.663 sec/step)\n",
            "I1211 18:48:17.919694 140545020077952 learning.py:507] global step 214: loss = 2.9656 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 215: loss = 2.6605 (0.474 sec/step)\n",
            "I1211 18:48:18.425015 140545020077952 learning.py:507] global step 215: loss = 2.6605 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 216: loss = 3.0391 (2.159 sec/step)\n",
            "I1211 18:48:20.585550 140545020077952 learning.py:507] global step 216: loss = 3.0391 (2.159 sec/step)\n",
            "INFO:tensorflow:global step 217: loss = 3.1460 (0.669 sec/step)\n",
            "I1211 18:48:21.489436 140545020077952 learning.py:507] global step 217: loss = 3.1460 (0.669 sec/step)\n",
            "INFO:tensorflow:global step 218: loss = 2.4805 (1.761 sec/step)\n",
            "I1211 18:48:23.386344 140545020077952 learning.py:507] global step 218: loss = 2.4805 (1.761 sec/step)\n",
            "INFO:tensorflow:global step 219: loss = 2.9764 (0.628 sec/step)\n",
            "I1211 18:48:24.356242 140545020077952 learning.py:507] global step 219: loss = 2.9764 (0.628 sec/step)\n",
            "INFO:tensorflow:global step 220: loss = 3.1038 (0.810 sec/step)\n",
            "I1211 18:48:25.296112 140545020077952 learning.py:507] global step 220: loss = 3.1038 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 221: loss = 3.0748 (1.407 sec/step)\n",
            "I1211 18:48:26.707786 140545020077952 learning.py:507] global step 221: loss = 3.0748 (1.407 sec/step)\n",
            "INFO:tensorflow:global step 222: loss = 2.9131 (0.601 sec/step)\n",
            "I1211 18:48:27.567489 140545020077952 learning.py:507] global step 222: loss = 2.9131 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 223: loss = 2.8876 (0.645 sec/step)\n",
            "I1211 18:48:28.494194 140545020077952 learning.py:507] global step 223: loss = 2.8876 (0.645 sec/step)\n",
            "INFO:tensorflow:global step 224: loss = 3.7612 (0.624 sec/step)\n",
            "I1211 18:48:29.331412 140545020077952 learning.py:507] global step 224: loss = 3.7612 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 225: loss = 3.2320 (1.930 sec/step)\n",
            "I1211 18:48:31.263405 140545020077952 learning.py:507] global step 225: loss = 3.2320 (1.930 sec/step)\n",
            "INFO:tensorflow:global step 226: loss = 3.3117 (0.485 sec/step)\n",
            "I1211 18:48:32.010339 140545020077952 learning.py:507] global step 226: loss = 3.3117 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 227: loss = 3.6050 (1.838 sec/step)\n",
            "I1211 18:48:33.853201 140545020077952 learning.py:507] global step 227: loss = 3.6050 (1.838 sec/step)\n",
            "INFO:tensorflow:global step 228: loss = 4.1397 (0.653 sec/step)\n",
            "I1211 18:48:34.698102 140545020077952 learning.py:507] global step 228: loss = 4.1397 (0.653 sec/step)\n",
            "INFO:tensorflow:global step 229: loss = 3.6250 (1.222 sec/step)\n",
            "I1211 18:48:36.205802 140545020077952 learning.py:507] global step 229: loss = 3.6250 (1.222 sec/step)\n",
            "INFO:tensorflow:global step 230: loss = 3.4420 (0.666 sec/step)\n",
            "I1211 18:48:37.068440 140545020077952 learning.py:507] global step 230: loss = 3.4420 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 231: loss = 3.2452 (1.362 sec/step)\n",
            "I1211 18:48:38.684003 140545020077952 learning.py:507] global step 231: loss = 3.2452 (1.362 sec/step)\n",
            "INFO:tensorflow:global step 232: loss = 3.6394 (0.592 sec/step)\n",
            "I1211 18:48:39.558393 140545020077952 learning.py:507] global step 232: loss = 3.6394 (0.592 sec/step)\n",
            "INFO:tensorflow:global step 233: loss = 2.8975 (0.460 sec/step)\n",
            "I1211 18:48:40.180181 140545020077952 learning.py:507] global step 233: loss = 2.8975 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 234: loss = 2.6481 (1.835 sec/step)\n",
            "I1211 18:48:42.017416 140545020077952 learning.py:507] global step 234: loss = 2.6481 (1.835 sec/step)\n",
            "INFO:tensorflow:global step 235: loss = 2.8574 (0.564 sec/step)\n",
            "I1211 18:48:42.583585 140545020077952 learning.py:507] global step 235: loss = 2.8574 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 236: loss = 2.8585 (1.668 sec/step)\n",
            "I1211 18:48:44.253190 140545020077952 learning.py:507] global step 236: loss = 2.8585 (1.668 sec/step)\n",
            "INFO:tensorflow:global step 237: loss = 2.9352 (0.622 sec/step)\n",
            "I1211 18:48:44.877290 140545020077952 learning.py:507] global step 237: loss = 2.9352 (0.622 sec/step)\n",
            "INFO:tensorflow:global step 238: loss = 3.2471 (1.068 sec/step)\n",
            "I1211 18:48:45.956504 140545020077952 learning.py:507] global step 238: loss = 3.2471 (1.068 sec/step)\n",
            "INFO:tensorflow:global step 239: loss = 3.3896 (2.304 sec/step)\n",
            "I1211 18:48:48.262624 140545020077952 learning.py:507] global step 239: loss = 3.3896 (2.304 sec/step)\n",
            "INFO:tensorflow:global step 240: loss = 3.3377 (0.621 sec/step)\n",
            "I1211 18:48:48.923284 140545020077952 learning.py:507] global step 240: loss = 3.3377 (0.621 sec/step)\n",
            "INFO:tensorflow:global step 241: loss = 3.2196 (1.457 sec/step)\n",
            "I1211 18:48:50.395462 140545020077952 learning.py:507] global step 241: loss = 3.2196 (1.457 sec/step)\n",
            "INFO:tensorflow:global step 242: loss = 3.1110 (0.633 sec/step)\n",
            "I1211 18:48:51.298218 140545020077952 learning.py:507] global step 242: loss = 3.1110 (0.633 sec/step)\n",
            "INFO:tensorflow:global step 243: loss = 3.0717 (0.574 sec/step)\n",
            "I1211 18:48:52.135189 140545020077952 learning.py:507] global step 243: loss = 3.0717 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 244: loss = 3.2202 (0.625 sec/step)\n",
            "I1211 18:48:53.188876 140545020077952 learning.py:507] global step 244: loss = 3.2202 (0.625 sec/step)\n",
            "INFO:tensorflow:global step 245: loss = 3.4986 (1.224 sec/step)\n",
            "I1211 18:48:54.452764 140545020077952 learning.py:507] global step 245: loss = 3.4986 (1.224 sec/step)\n",
            "INFO:tensorflow:global step 246: loss = 2.9346 (0.667 sec/step)\n",
            "I1211 18:48:55.318152 140545020077952 learning.py:507] global step 246: loss = 2.9346 (0.667 sec/step)\n",
            "INFO:tensorflow:global step 247: loss = 3.4514 (0.739 sec/step)\n",
            "I1211 18:48:56.268952 140545020077952 learning.py:507] global step 247: loss = 3.4514 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 248: loss = 2.9491 (0.523 sec/step)\n",
            "I1211 18:48:57.078635 140545020077952 learning.py:507] global step 248: loss = 2.9491 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 249: loss = 3.1328 (0.598 sec/step)\n",
            "I1211 18:48:57.814375 140545020077952 learning.py:507] global step 249: loss = 3.1328 (0.598 sec/step)\n",
            "INFO:tensorflow:global step 250: loss = 4.0127 (1.530 sec/step)\n",
            "I1211 18:48:59.345910 140545020077952 learning.py:507] global step 250: loss = 4.0127 (1.530 sec/step)\n",
            "INFO:tensorflow:global step 251: loss = 2.6639 (0.546 sec/step)\n",
            "I1211 18:49:00.159658 140545020077952 learning.py:507] global step 251: loss = 2.6639 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 252: loss = 3.7219 (0.990 sec/step)\n",
            "I1211 18:49:01.365873 140545020077952 learning.py:507] global step 252: loss = 3.7219 (0.990 sec/step)\n",
            "INFO:tensorflow:global step 253: loss = 4.1076 (0.559 sec/step)\n",
            "I1211 18:49:02.188623 140545020077952 learning.py:507] global step 253: loss = 4.1076 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 254: loss = 3.2293 (1.039 sec/step)\n",
            "I1211 18:49:03.344325 140545020077952 learning.py:507] global step 254: loss = 3.2293 (1.039 sec/step)\n",
            "INFO:tensorflow:global step 255: loss = 3.6797 (0.686 sec/step)\n",
            "I1211 18:49:04.082432 140545020077952 learning.py:507] global step 255: loss = 3.6797 (0.686 sec/step)\n",
            "INFO:tensorflow:global step 256: loss = 2.7750 (0.571 sec/step)\n",
            "I1211 18:49:05.027186 140545020077952 learning.py:507] global step 256: loss = 2.7750 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 257: loss = 3.6219 (0.604 sec/step)\n",
            "I1211 18:49:06.018822 140545020077952 learning.py:507] global step 257: loss = 3.6219 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 258: loss = 3.5780 (1.315 sec/step)\n",
            "I1211 18:49:07.482313 140545020077952 learning.py:507] global step 258: loss = 3.5780 (1.315 sec/step)\n",
            "INFO:tensorflow:global step 259: loss = 3.4729 (1.070 sec/step)\n",
            "I1211 18:49:08.554188 140545020077952 learning.py:507] global step 259: loss = 3.4729 (1.070 sec/step)\n",
            "INFO:tensorflow:global step 260: loss = 3.4105 (0.621 sec/step)\n",
            "I1211 18:49:09.421944 140545020077952 learning.py:507] global step 260: loss = 3.4105 (0.621 sec/step)\n",
            "INFO:tensorflow:global step 261: loss = 3.6961 (1.131 sec/step)\n",
            "I1211 18:49:10.680129 140545020077952 learning.py:507] global step 261: loss = 3.6961 (1.131 sec/step)\n",
            "INFO:tensorflow:global step 262: loss = 2.7573 (0.637 sec/step)\n",
            "I1211 18:49:11.552818 140545020077952 learning.py:507] global step 262: loss = 2.7573 (0.637 sec/step)\n",
            "INFO:tensorflow:global step 263: loss = 3.1627 (0.539 sec/step)\n",
            "I1211 18:49:12.320971 140545020077952 learning.py:507] global step 263: loss = 3.1627 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 264: loss = 3.2636 (1.202 sec/step)\n",
            "I1211 18:49:13.746837 140545020077952 learning.py:507] global step 264: loss = 3.2636 (1.202 sec/step)\n",
            "INFO:tensorflow:global step 265: loss = 2.9057 (0.584 sec/step)\n",
            "I1211 18:49:14.549425 140545020077952 learning.py:507] global step 265: loss = 2.9057 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 266: loss = 3.4662 (1.262 sec/step)\n",
            "I1211 18:49:15.914521 140545020077952 learning.py:507] global step 266: loss = 3.4662 (1.262 sec/step)\n",
            "INFO:tensorflow:global step 267: loss = 3.6492 (0.696 sec/step)\n",
            "I1211 18:49:16.790366 140545020077952 learning.py:507] global step 267: loss = 3.6492 (0.696 sec/step)\n",
            "INFO:tensorflow:global step 268: loss = 3.6631 (0.638 sec/step)\n",
            "I1211 18:49:17.734821 140545020077952 learning.py:507] global step 268: loss = 3.6631 (0.638 sec/step)\n",
            "INFO:tensorflow:global step 269: loss = 3.4676 (0.524 sec/step)\n",
            "I1211 18:49:18.404831 140545020077952 learning.py:507] global step 269: loss = 3.4676 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 270: loss = 3.1657 (1.439 sec/step)\n",
            "I1211 18:49:19.952070 140545020077952 learning.py:507] global step 270: loss = 3.1657 (1.439 sec/step)\n",
            "INFO:tensorflow:global step 271: loss = 3.0413 (0.518 sec/step)\n",
            "I1211 18:49:20.685229 140545020077952 learning.py:507] global step 271: loss = 3.0413 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 272: loss = 2.8796 (1.202 sec/step)\n",
            "I1211 18:49:22.171745 140545020077952 learning.py:507] global step 272: loss = 2.8796 (1.202 sec/step)\n",
            "INFO:tensorflow:global step 273: loss = 3.4914 (0.644 sec/step)\n",
            "I1211 18:49:23.047934 140545020077952 learning.py:507] global step 273: loss = 3.4914 (0.644 sec/step)\n",
            "INFO:tensorflow:global step 274: loss = 3.2963 (0.599 sec/step)\n",
            "I1211 18:49:24.018503 140545020077952 learning.py:507] global step 274: loss = 3.2963 (0.599 sec/step)\n",
            "INFO:tensorflow:global step 275: loss = 3.2428 (1.144 sec/step)\n",
            "I1211 18:49:25.275290 140545020077952 learning.py:507] global step 275: loss = 3.2428 (1.144 sec/step)\n",
            "INFO:tensorflow:global step 276: loss = 4.0500 (0.608 sec/step)\n",
            "I1211 18:49:26.092146 140545020077952 learning.py:507] global step 276: loss = 4.0500 (0.608 sec/step)\n",
            "INFO:tensorflow:global step 277: loss = 3.5940 (0.572 sec/step)\n",
            "I1211 18:49:27.000123 140545020077952 learning.py:507] global step 277: loss = 3.5940 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 278: loss = 3.5121 (0.665 sec/step)\n",
            "I1211 18:49:28.262609 140545020077952 learning.py:507] global step 278: loss = 3.5121 (0.665 sec/step)\n",
            "INFO:tensorflow:global step 279: loss = 3.2336 (0.814 sec/step)\n",
            "I1211 18:49:29.327628 140545020077952 learning.py:507] global step 279: loss = 3.2336 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 280: loss = 3.0571 (1.073 sec/step)\n",
            "I1211 18:49:30.402261 140545020077952 learning.py:507] global step 280: loss = 3.0571 (1.073 sec/step)\n",
            "INFO:tensorflow:global step 281: loss = 3.7789 (0.630 sec/step)\n",
            "I1211 18:49:31.195102 140545020077952 learning.py:507] global step 281: loss = 3.7789 (0.630 sec/step)\n",
            "INFO:tensorflow:global step 282: loss = 4.1444 (0.639 sec/step)\n",
            "I1211 18:49:32.345552 140545020077952 learning.py:507] global step 282: loss = 4.1444 (0.639 sec/step)\n",
            "INFO:tensorflow:global step 283: loss = 3.4686 (1.115 sec/step)\n",
            "I1211 18:49:33.514212 140545020077952 learning.py:507] global step 283: loss = 3.4686 (1.115 sec/step)\n",
            "INFO:tensorflow:global step 284: loss = 2.6414 (0.603 sec/step)\n",
            "I1211 18:49:34.170392 140545020077952 learning.py:507] global step 284: loss = 2.6414 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 285: loss = 3.1728 (0.540 sec/step)\n",
            "I1211 18:49:35.120801 140545020077952 learning.py:507] global step 285: loss = 3.1728 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 286: loss = 3.1646 (1.258 sec/step)\n",
            "I1211 18:49:36.564299 140545020077952 learning.py:507] global step 286: loss = 3.1646 (1.258 sec/step)\n",
            "INFO:tensorflow:global step 287: loss = 3.2768 (0.566 sec/step)\n",
            "I1211 18:49:37.385466 140545020077952 learning.py:507] global step 287: loss = 3.2768 (0.566 sec/step)\n",
            "INFO:tensorflow:global step 288: loss = 3.8599 (0.617 sec/step)\n",
            "I1211 18:49:38.465519 140545020077952 learning.py:507] global step 288: loss = 3.8599 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 289: loss = 3.0168 (0.658 sec/step)\n",
            "I1211 18:49:39.455920 140545020077952 learning.py:507] global step 289: loss = 3.0168 (0.658 sec/step)\n",
            "INFO:tensorflow:global step 290: loss = 3.0246 (1.159 sec/step)\n",
            "I1211 18:49:40.670825 140545020077952 learning.py:507] global step 290: loss = 3.0246 (1.159 sec/step)\n",
            "INFO:tensorflow:global step 291: loss = 3.2332 (0.574 sec/step)\n",
            "I1211 18:49:41.446856 140545020077952 learning.py:507] global step 291: loss = 3.2332 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 292: loss = 3.4456 (1.145 sec/step)\n",
            "I1211 18:49:42.779124 140545020077952 learning.py:507] global step 292: loss = 3.4456 (1.145 sec/step)\n",
            "INFO:tensorflow:global step 293: loss = 3.4460 (0.630 sec/step)\n",
            "I1211 18:49:43.658698 140545020077952 learning.py:507] global step 293: loss = 3.4460 (0.630 sec/step)\n",
            "INFO:tensorflow:global step 294: loss = 3.0557 (1.111 sec/step)\n",
            "I1211 18:49:44.887509 140545020077952 learning.py:507] global step 294: loss = 3.0557 (1.111 sec/step)\n",
            "INFO:tensorflow:global step 295: loss = 3.4641 (0.508 sec/step)\n",
            "I1211 18:49:45.673901 140545020077952 learning.py:507] global step 295: loss = 3.4641 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 296: loss = 2.5685 (0.897 sec/step)\n",
            "I1211 18:49:46.696904 140545020077952 learning.py:507] global step 296: loss = 2.5685 (0.897 sec/step)\n",
            "INFO:tensorflow:global step 297: loss = 2.8885 (1.244 sec/step)\n",
            "I1211 18:49:47.959437 140545020077952 learning.py:507] global step 297: loss = 2.8885 (1.244 sec/step)\n",
            "INFO:tensorflow:global step 298: loss = 3.1795 (0.568 sec/step)\n",
            "I1211 18:49:48.827630 140545020077952 learning.py:507] global step 298: loss = 3.1795 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 299: loss = 2.1909 (0.491 sec/step)\n",
            "I1211 18:49:49.704669 140545020077952 learning.py:507] global step 299: loss = 2.1909 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 300: loss = 2.7530 (1.160 sec/step)\n",
            "I1211 18:49:51.035816 140545020077952 learning.py:507] global step 300: loss = 2.7530 (1.160 sec/step)\n",
            "INFO:tensorflow:global step 301: loss = 3.6396 (0.624 sec/step)\n",
            "I1211 18:49:51.916879 140545020077952 learning.py:507] global step 301: loss = 3.6396 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 302: loss = 2.8407 (1.102 sec/step)\n",
            "I1211 18:49:53.189429 140545020077952 learning.py:507] global step 302: loss = 2.8407 (1.102 sec/step)\n",
            "INFO:tensorflow:global step 303: loss = 3.5654 (1.048 sec/step)\n",
            "I1211 18:49:54.239189 140545020077952 learning.py:507] global step 303: loss = 3.5654 (1.048 sec/step)\n",
            "INFO:tensorflow:global step 304: loss = 3.1487 (0.665 sec/step)\n",
            "I1211 18:49:55.199175 140545020077952 learning.py:507] global step 304: loss = 3.1487 (0.665 sec/step)\n",
            "INFO:tensorflow:global step 305: loss = 3.0725 (0.641 sec/step)\n",
            "I1211 18:49:56.030681 140545020077952 learning.py:507] global step 305: loss = 3.0725 (0.641 sec/step)\n",
            "INFO:tensorflow:global step 306: loss = 2.6944 (0.620 sec/step)\n",
            "I1211 18:49:56.991624 140545020077952 learning.py:507] global step 306: loss = 2.6944 (0.620 sec/step)\n",
            "INFO:tensorflow:global step 307: loss = 2.9463 (1.022 sec/step)\n",
            "I1211 18:49:58.148967 140545020077952 learning.py:507] global step 307: loss = 2.9463 (1.022 sec/step)\n",
            "INFO:tensorflow:global step 308: loss = 4.2568 (0.490 sec/step)\n",
            "I1211 18:49:58.828812 140545020077952 learning.py:507] global step 308: loss = 4.2568 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 309: loss = 3.5930 (1.146 sec/step)\n",
            "I1211 18:50:00.198086 140545020077952 learning.py:507] global step 309: loss = 3.5930 (1.146 sec/step)\n",
            "INFO:tensorflow:global step 310: loss = 3.4773 (0.487 sec/step)\n",
            "I1211 18:50:00.686877 140545020077952 learning.py:507] global step 310: loss = 3.4773 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 311: loss = 3.4954 (1.434 sec/step)\n",
            "I1211 18:50:02.136418 140545020077952 learning.py:507] global step 311: loss = 3.4954 (1.434 sec/step)\n",
            "INFO:tensorflow:global step 312: loss = 3.2740 (0.609 sec/step)\n",
            "I1211 18:50:02.922145 140545020077952 learning.py:507] global step 312: loss = 3.2740 (0.609 sec/step)\n",
            "INFO:tensorflow:global step 313: loss = 3.5320 (2.160 sec/step)\n",
            "I1211 18:50:05.243098 140545020077952 learning.py:507] global step 313: loss = 3.5320 (2.160 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 313.\n",
            "I1211 18:50:06.208201 140541340448512 supervisor.py:1050] Recording summary at step 313.\n",
            "INFO:tensorflow:global step 314: loss = 3.6036 (1.208 sec/step)\n",
            "I1211 18:50:06.453181 140545020077952 learning.py:507] global step 314: loss = 3.6036 (1.208 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.932855\n",
            "I1211 18:50:06.610772 140541348841216 supervisor.py:1099] global_step/sec: 0.932855\n",
            "INFO:tensorflow:global step 315: loss = 3.0059 (0.701 sec/step)\n",
            "I1211 18:50:07.162996 140545020077952 learning.py:507] global step 315: loss = 3.0059 (0.701 sec/step)\n",
            "INFO:tensorflow:global step 316: loss = 3.5684 (1.418 sec/step)\n",
            "I1211 18:50:08.588194 140545020077952 learning.py:507] global step 316: loss = 3.5684 (1.418 sec/step)\n",
            "INFO:tensorflow:global step 317: loss = 3.3338 (1.045 sec/step)\n",
            "I1211 18:50:09.635342 140545020077952 learning.py:507] global step 317: loss = 3.3338 (1.045 sec/step)\n",
            "INFO:tensorflow:global step 318: loss = 2.8025 (0.627 sec/step)\n",
            "I1211 18:50:10.343458 140545020077952 learning.py:507] global step 318: loss = 2.8025 (0.627 sec/step)\n",
            "INFO:tensorflow:global step 319: loss = 3.2071 (0.736 sec/step)\n",
            "I1211 18:50:11.570704 140545020077952 learning.py:507] global step 319: loss = 3.2071 (0.736 sec/step)\n",
            "INFO:tensorflow:global step 320: loss = 3.7987 (1.187 sec/step)\n",
            "I1211 18:50:12.775240 140545020077952 learning.py:507] global step 320: loss = 3.7987 (1.187 sec/step)\n",
            "INFO:tensorflow:global step 321: loss = 3.0126 (0.701 sec/step)\n",
            "I1211 18:50:13.642441 140545020077952 learning.py:507] global step 321: loss = 3.0126 (0.701 sec/step)\n",
            "INFO:tensorflow:global step 322: loss = 3.1041 (0.567 sec/step)\n",
            "I1211 18:50:14.591836 140545020077952 learning.py:507] global step 322: loss = 3.1041 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 323: loss = 2.7583 (1.201 sec/step)\n",
            "I1211 18:50:15.987668 140545020077952 learning.py:507] global step 323: loss = 2.7583 (1.201 sec/step)\n",
            "INFO:tensorflow:global step 324: loss = 2.6333 (0.653 sec/step)\n",
            "I1211 18:50:16.728541 140545020077952 learning.py:507] global step 324: loss = 2.6333 (0.653 sec/step)\n",
            "INFO:tensorflow:global step 325: loss = 3.5998 (1.921 sec/step)\n",
            "I1211 18:50:18.821238 140545020077952 learning.py:507] global step 325: loss = 3.5998 (1.921 sec/step)\n",
            "INFO:tensorflow:global step 326: loss = 2.8969 (0.463 sec/step)\n",
            "I1211 18:50:19.285803 140545020077952 learning.py:507] global step 326: loss = 2.8969 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 327: loss = 3.8060 (0.575 sec/step)\n",
            "I1211 18:50:20.344292 140545020077952 learning.py:507] global step 327: loss = 3.8060 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 328: loss = 3.0009 (2.472 sec/step)\n",
            "I1211 18:50:22.992411 140545020077952 learning.py:507] global step 328: loss = 3.0009 (2.472 sec/step)\n",
            "INFO:tensorflow:global step 329: loss = 2.6333 (0.688 sec/step)\n",
            "I1211 18:50:23.863319 140545020077952 learning.py:507] global step 329: loss = 2.6333 (0.688 sec/step)\n",
            "INFO:tensorflow:global step 330: loss = 3.0605 (0.675 sec/step)\n",
            "I1211 18:50:24.918219 140545020077952 learning.py:507] global step 330: loss = 3.0605 (0.675 sec/step)\n",
            "INFO:tensorflow:global step 331: loss = 2.9833 (0.627 sec/step)\n",
            "I1211 18:50:25.812429 140545020077952 learning.py:507] global step 331: loss = 2.9833 (0.627 sec/step)\n",
            "INFO:tensorflow:global step 332: loss = 2.7008 (0.586 sec/step)\n",
            "I1211 18:50:26.596780 140545020077952 learning.py:507] global step 332: loss = 2.7008 (0.586 sec/step)\n",
            "INFO:tensorflow:global step 333: loss = 2.6412 (0.716 sec/step)\n",
            "I1211 18:50:27.615568 140545020077952 learning.py:507] global step 333: loss = 2.6412 (0.716 sec/step)\n",
            "INFO:tensorflow:global step 334: loss = 2.7132 (1.482 sec/step)\n",
            "I1211 18:50:29.295640 140545020077952 learning.py:507] global step 334: loss = 2.7132 (1.482 sec/step)\n",
            "INFO:tensorflow:global step 335: loss = 3.0915 (0.600 sec/step)\n",
            "I1211 18:50:30.185370 140545020077952 learning.py:507] global step 335: loss = 3.0915 (0.600 sec/step)\n",
            "INFO:tensorflow:global step 336: loss = 3.0712 (1.016 sec/step)\n",
            "I1211 18:50:31.339486 140545020077952 learning.py:507] global step 336: loss = 3.0712 (1.016 sec/step)\n",
            "INFO:tensorflow:global step 337: loss = 3.0587 (0.520 sec/step)\n",
            "I1211 18:50:32.132334 140545020077952 learning.py:507] global step 337: loss = 3.0587 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 338: loss = 3.7588 (1.059 sec/step)\n",
            "I1211 18:50:33.390525 140545020077952 learning.py:507] global step 338: loss = 3.7588 (1.059 sec/step)\n",
            "INFO:tensorflow:global step 339: loss = 2.8990 (1.001 sec/step)\n",
            "I1211 18:50:34.392704 140545020077952 learning.py:507] global step 339: loss = 2.8990 (1.001 sec/step)\n",
            "INFO:tensorflow:global step 340: loss = 2.8692 (0.559 sec/step)\n",
            "I1211 18:50:35.221916 140545020077952 learning.py:507] global step 340: loss = 2.8692 (0.559 sec/step)\n",
            "INFO:tensorflow:global step 341: loss = 3.2371 (0.584 sec/step)\n",
            "I1211 18:50:36.314955 140545020077952 learning.py:507] global step 341: loss = 3.2371 (0.584 sec/step)\n",
            "INFO:tensorflow:global step 342: loss = 3.9884 (1.180 sec/step)\n",
            "I1211 18:50:37.518981 140545020077952 learning.py:507] global step 342: loss = 3.9884 (1.180 sec/step)\n",
            "INFO:tensorflow:global step 343: loss = 4.1159 (0.550 sec/step)\n",
            "I1211 18:50:38.070942 140545020077952 learning.py:507] global step 343: loss = 4.1159 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 344: loss = 3.9044 (0.701 sec/step)\n",
            "I1211 18:50:39.248804 140545020077952 learning.py:507] global step 344: loss = 3.9044 (0.701 sec/step)\n",
            "INFO:tensorflow:global step 345: loss = 2.9432 (1.707 sec/step)\n",
            "I1211 18:50:41.125428 140545020077952 learning.py:507] global step 345: loss = 2.9432 (1.707 sec/step)\n",
            "INFO:tensorflow:global step 346: loss = 2.7066 (0.701 sec/step)\n",
            "I1211 18:50:41.967536 140545020077952 learning.py:507] global step 346: loss = 2.7066 (0.701 sec/step)\n",
            "INFO:tensorflow:global step 347: loss = 2.8919 (0.734 sec/step)\n",
            "I1211 18:50:43.174345 140545020077952 learning.py:507] global step 347: loss = 2.8919 (0.734 sec/step)\n",
            "INFO:tensorflow:global step 348: loss = 2.7731 (0.629 sec/step)\n",
            "I1211 18:50:43.869133 140545020077952 learning.py:507] global step 348: loss = 2.7731 (0.629 sec/step)\n",
            "INFO:tensorflow:global step 349: loss = 3.0444 (1.188 sec/step)\n",
            "I1211 18:50:45.264794 140545020077952 learning.py:507] global step 349: loss = 3.0444 (1.188 sec/step)\n",
            "INFO:tensorflow:global step 350: loss = 3.0169 (0.653 sec/step)\n",
            "I1211 18:50:46.078197 140545020077952 learning.py:507] global step 350: loss = 3.0169 (0.653 sec/step)\n",
            "INFO:tensorflow:global step 351: loss = 2.7008 (1.406 sec/step)\n",
            "I1211 18:50:47.550366 140545020077952 learning.py:507] global step 351: loss = 2.7008 (1.406 sec/step)\n",
            "INFO:tensorflow:global step 352: loss = 3.2608 (0.537 sec/step)\n",
            "I1211 18:50:48.304244 140545020077952 learning.py:507] global step 352: loss = 3.2608 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 353: loss = 3.0063 (1.266 sec/step)\n",
            "I1211 18:50:49.821651 140545020077952 learning.py:507] global step 353: loss = 3.0063 (1.266 sec/step)\n",
            "INFO:tensorflow:global step 354: loss = 2.6796 (0.643 sec/step)\n",
            "I1211 18:50:50.506280 140545020077952 learning.py:507] global step 354: loss = 2.6796 (0.643 sec/step)\n",
            "INFO:tensorflow:global step 355: loss = 3.4239 (1.538 sec/step)\n",
            "I1211 18:50:52.045796 140545020077952 learning.py:507] global step 355: loss = 3.4239 (1.538 sec/step)\n",
            "INFO:tensorflow:global step 356: loss = 3.3512 (0.642 sec/step)\n",
            "I1211 18:50:52.812299 140545020077952 learning.py:507] global step 356: loss = 3.3512 (0.642 sec/step)\n",
            "INFO:tensorflow:global step 357: loss = 3.0550 (0.609 sec/step)\n",
            "I1211 18:50:53.740986 140545020077952 learning.py:507] global step 357: loss = 3.0550 (0.609 sec/step)\n",
            "INFO:tensorflow:global step 358: loss = 3.0499 (0.633 sec/step)\n",
            "I1211 18:50:54.686313 140545020077952 learning.py:507] global step 358: loss = 3.0499 (0.633 sec/step)\n",
            "INFO:tensorflow:global step 359: loss = 2.8668 (1.520 sec/step)\n",
            "I1211 18:50:56.228376 140545020077952 learning.py:507] global step 359: loss = 2.8668 (1.520 sec/step)\n",
            "INFO:tensorflow:global step 360: loss = 3.6697 (0.498 sec/step)\n",
            "I1211 18:50:56.727838 140545020077952 learning.py:507] global step 360: loss = 3.6697 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 361: loss = 4.2659 (0.754 sec/step)\n",
            "I1211 18:50:57.738690 140545020077952 learning.py:507] global step 361: loss = 4.2659 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 362: loss = 3.4844 (1.490 sec/step)\n",
            "I1211 18:50:59.353467 140545020077952 learning.py:507] global step 362: loss = 3.4844 (1.490 sec/step)\n",
            "INFO:tensorflow:global step 363: loss = 3.6093 (0.644 sec/step)\n",
            "I1211 18:51:00.250334 140545020077952 learning.py:507] global step 363: loss = 3.6093 (0.644 sec/step)\n",
            "INFO:tensorflow:global step 364: loss = 3.7706 (0.610 sec/step)\n",
            "I1211 18:51:01.281344 140545020077952 learning.py:507] global step 364: loss = 3.7706 (0.610 sec/step)\n",
            "INFO:tensorflow:global step 365: loss = 3.0554 (0.590 sec/step)\n",
            "I1211 18:51:02.236377 140545020077952 learning.py:507] global step 365: loss = 3.0554 (0.590 sec/step)\n",
            "INFO:tensorflow:global step 366: loss = 3.3576 (0.539 sec/step)\n",
            "I1211 18:51:02.837911 140545020077952 learning.py:507] global step 366: loss = 3.3576 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 367: loss = 3.4102 (1.448 sec/step)\n",
            "I1211 18:51:04.326565 140545020077952 learning.py:507] global step 367: loss = 3.4102 (1.448 sec/step)\n",
            "INFO:tensorflow:global step 368: loss = 3.0252 (0.486 sec/step)\n",
            "I1211 18:51:04.946308 140545020077952 learning.py:507] global step 368: loss = 3.0252 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 369: loss = 3.2792 (1.513 sec/step)\n",
            "I1211 18:51:06.492116 140545020077952 learning.py:507] global step 369: loss = 3.2792 (1.513 sec/step)\n",
            "INFO:tensorflow:global step 370: loss = 3.0825 (0.549 sec/step)\n",
            "I1211 18:51:07.267137 140545020077952 learning.py:507] global step 370: loss = 3.0825 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 371: loss = 3.1306 (0.588 sec/step)\n",
            "I1211 18:51:08.349811 140545020077952 learning.py:507] global step 371: loss = 3.1306 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 372: loss = 3.4623 (1.074 sec/step)\n",
            "I1211 18:51:09.473783 140545020077952 learning.py:507] global step 372: loss = 3.4623 (1.074 sec/step)\n",
            "INFO:tensorflow:global step 373: loss = 2.2679 (0.625 sec/step)\n",
            "I1211 18:51:10.418856 140545020077952 learning.py:507] global step 373: loss = 2.2679 (0.625 sec/step)\n",
            "INFO:tensorflow:global step 374: loss = 3.2538 (0.574 sec/step)\n",
            "I1211 18:51:11.377100 140545020077952 learning.py:507] global step 374: loss = 3.2538 (0.574 sec/step)\n",
            "INFO:tensorflow:global step 375: loss = 2.4875 (1.085 sec/step)\n",
            "I1211 18:51:12.589423 140545020077952 learning.py:507] global step 375: loss = 2.4875 (1.085 sec/step)\n",
            "INFO:tensorflow:global step 376: loss = 3.0589 (0.616 sec/step)\n",
            "I1211 18:51:13.309823 140545020077952 learning.py:507] global step 376: loss = 3.0589 (0.616 sec/step)\n",
            "INFO:tensorflow:global step 377: loss = 3.7192 (1.341 sec/step)\n",
            "I1211 18:51:14.706057 140545020077952 learning.py:507] global step 377: loss = 3.7192 (1.341 sec/step)\n",
            "INFO:tensorflow:global step 378: loss = 3.5169 (0.709 sec/step)\n",
            "I1211 18:51:15.434799 140545020077952 learning.py:507] global step 378: loss = 3.5169 (0.709 sec/step)\n",
            "INFO:tensorflow:global step 379: loss = 3.1452 (1.327 sec/step)\n",
            "I1211 18:51:16.876460 140545020077952 learning.py:507] global step 379: loss = 3.1452 (1.327 sec/step)\n",
            "INFO:tensorflow:global step 380: loss = 3.1905 (0.572 sec/step)\n",
            "I1211 18:51:17.671836 140545020077952 learning.py:507] global step 380: loss = 3.1905 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 381: loss = 3.2432 (1.042 sec/step)\n",
            "I1211 18:51:18.897613 140545020077952 learning.py:507] global step 381: loss = 3.2432 (1.042 sec/step)\n",
            "INFO:tensorflow:global step 382: loss = 3.2786 (0.558 sec/step)\n",
            "I1211 18:51:19.788012 140545020077952 learning.py:507] global step 382: loss = 3.2786 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 383: loss = 2.9556 (0.513 sec/step)\n",
            "I1211 18:51:20.441278 140545020077952 learning.py:507] global step 383: loss = 2.9556 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 384: loss = 2.5118 (0.518 sec/step)\n",
            "I1211 18:51:20.961200 140545020077952 learning.py:507] global step 384: loss = 2.5118 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 385: loss = 3.4585 (2.268 sec/step)\n",
            "I1211 18:51:23.235922 140545020077952 learning.py:507] global step 385: loss = 3.4585 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 386: loss = 2.9896 (0.758 sec/step)\n",
            "I1211 18:51:24.229019 140545020077952 learning.py:507] global step 386: loss = 2.9896 (0.758 sec/step)\n",
            "INFO:tensorflow:global step 387: loss = 3.0990 (0.650 sec/step)\n",
            "I1211 18:51:24.940310 140545020077952 learning.py:507] global step 387: loss = 3.0990 (0.650 sec/step)\n",
            "INFO:tensorflow:global step 388: loss = 3.2265 (1.702 sec/step)\n",
            "I1211 18:51:26.644254 140545020077952 learning.py:507] global step 388: loss = 3.2265 (1.702 sec/step)\n",
            "INFO:tensorflow:global step 389: loss = 3.0533 (0.752 sec/step)\n",
            "I1211 18:51:27.449074 140545020077952 learning.py:507] global step 389: loss = 3.0533 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 390: loss = 2.9182 (1.207 sec/step)\n",
            "I1211 18:51:28.825646 140545020077952 learning.py:507] global step 390: loss = 2.9182 (1.207 sec/step)\n",
            "INFO:tensorflow:global step 391: loss = 2.9829 (0.637 sec/step)\n",
            "I1211 18:51:29.485619 140545020077952 learning.py:507] global step 391: loss = 2.9829 (0.637 sec/step)\n",
            "INFO:tensorflow:global step 392: loss = 3.2718 (1.240 sec/step)\n",
            "I1211 18:51:31.007095 140545020077952 learning.py:507] global step 392: loss = 3.2718 (1.240 sec/step)\n",
            "INFO:tensorflow:global step 393: loss = 3.1067 (0.594 sec/step)\n",
            "I1211 18:51:31.912676 140545020077952 learning.py:507] global step 393: loss = 3.1067 (0.594 sec/step)\n",
            "INFO:tensorflow:global step 394: loss = 2.7448 (0.618 sec/step)\n",
            "I1211 18:51:32.926604 140545020077952 learning.py:507] global step 394: loss = 2.7448 (0.618 sec/step)\n",
            "INFO:tensorflow:global step 395: loss = 3.0965 (0.754 sec/step)\n",
            "I1211 18:51:33.761058 140545020077952 learning.py:507] global step 395: loss = 3.0965 (0.754 sec/step)\n",
            "INFO:tensorflow:global step 396: loss = 3.0408 (1.567 sec/step)\n",
            "I1211 18:51:35.329677 140545020077952 learning.py:507] global step 396: loss = 3.0408 (1.567 sec/step)\n",
            "INFO:tensorflow:global step 397: loss = 3.2450 (0.635 sec/step)\n",
            "I1211 18:51:36.248214 140545020077952 learning.py:507] global step 397: loss = 3.2450 (0.635 sec/step)\n",
            "INFO:tensorflow:global step 398: loss = 3.2155 (1.042 sec/step)\n",
            "I1211 18:51:37.339618 140545020077952 learning.py:507] global step 398: loss = 3.2155 (1.042 sec/step)\n",
            "INFO:tensorflow:global step 399: loss = 3.0718 (0.497 sec/step)\n",
            "I1211 18:51:38.010392 140545020077952 learning.py:507] global step 399: loss = 3.0718 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 400: loss = 3.5310 (1.187 sec/step)\n",
            "I1211 18:51:39.467149 140545020077952 learning.py:507] global step 400: loss = 3.5310 (1.187 sec/step)\n",
            "INFO:tensorflow:global step 401: loss = 3.3412 (0.570 sec/step)\n",
            "I1211 18:51:40.351648 140545020077952 learning.py:507] global step 401: loss = 3.3412 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 402: loss = 2.5810 (1.245 sec/step)\n",
            "I1211 18:51:41.641855 140545020077952 learning.py:507] global step 402: loss = 2.5810 (1.245 sec/step)\n",
            "INFO:tensorflow:global step 403: loss = 3.0886 (0.660 sec/step)\n",
            "I1211 18:51:42.324713 140545020077952 learning.py:507] global step 403: loss = 3.0886 (0.660 sec/step)\n",
            "INFO:tensorflow:global step 404: loss = 2.4446 (1.268 sec/step)\n",
            "I1211 18:51:43.737540 140545020077952 learning.py:507] global step 404: loss = 2.4446 (1.268 sec/step)\n",
            "INFO:tensorflow:global step 405: loss = 3.3948 (0.771 sec/step)\n",
            "I1211 18:51:44.646813 140545020077952 learning.py:507] global step 405: loss = 3.3948 (0.771 sec/step)\n",
            "INFO:tensorflow:global step 406: loss = 3.7620 (0.690 sec/step)\n",
            "I1211 18:51:45.573040 140545020077952 learning.py:507] global step 406: loss = 3.7620 (0.690 sec/step)\n",
            "INFO:tensorflow:global step 407: loss = 2.9217 (0.713 sec/step)\n",
            "I1211 18:51:46.556974 140545020077952 learning.py:507] global step 407: loss = 2.9217 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 408: loss = 3.2732 (0.777 sec/step)\n",
            "I1211 18:51:47.698350 140545020077952 learning.py:507] global step 408: loss = 3.2732 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 409: loss = 3.2145 (0.627 sec/step)\n",
            "I1211 18:51:48.484345 140545020077952 learning.py:507] global step 409: loss = 3.2145 (0.627 sec/step)\n",
            "INFO:tensorflow:global step 410: loss = 3.0489 (0.618 sec/step)\n",
            "I1211 18:51:49.581361 140545020077952 learning.py:507] global step 410: loss = 3.0489 (0.618 sec/step)\n",
            "INFO:tensorflow:global step 411: loss = 2.9996 (0.567 sec/step)\n",
            "I1211 18:51:50.509113 140545020077952 learning.py:507] global step 411: loss = 2.9996 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 412: loss = 3.0105 (0.570 sec/step)\n",
            "I1211 18:51:51.541002 140545020077952 learning.py:507] global step 412: loss = 3.0105 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 413: loss = 3.2519 (1.059 sec/step)\n",
            "I1211 18:51:52.733708 140545020077952 learning.py:507] global step 413: loss = 3.2519 (1.059 sec/step)\n",
            "INFO:tensorflow:global step 414: loss = 3.0798 (0.550 sec/step)\n",
            "I1211 18:51:53.712484 140545020077952 learning.py:507] global step 414: loss = 3.0798 (0.550 sec/step)\n",
            "INFO:tensorflow:global step 415: loss = 3.2991 (0.588 sec/step)\n",
            "I1211 18:51:54.425419 140545020077952 learning.py:507] global step 415: loss = 3.2991 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 416: loss = 2.8292 (0.650 sec/step)\n",
            "I1211 18:51:55.078231 140545020077952 learning.py:507] global step 416: loss = 2.8292 (0.650 sec/step)\n",
            "INFO:tensorflow:global step 417: loss = 2.6464 (0.951 sec/step)\n",
            "I1211 18:51:56.884363 140545020077952 learning.py:507] global step 417: loss = 2.6464 (0.951 sec/step)\n",
            "INFO:tensorflow:global step 418: loss = 3.7172 (1.926 sec/step)\n",
            "I1211 18:51:59.117030 140545020077952 learning.py:507] global step 418: loss = 3.7172 (1.926 sec/step)\n",
            "INFO:tensorflow:global step 419: loss = 3.3307 (0.679 sec/step)\n",
            "I1211 18:51:59.979313 140545020077952 learning.py:507] global step 419: loss = 3.3307 (0.679 sec/step)\n",
            "INFO:tensorflow:global step 420: loss = 2.7114 (1.368 sec/step)\n",
            "I1211 18:52:01.477072 140545020077952 learning.py:507] global step 420: loss = 2.7114 (1.368 sec/step)\n",
            "INFO:tensorflow:global step 421: loss = 3.2835 (0.657 sec/step)\n",
            "I1211 18:52:02.342359 140545020077952 learning.py:507] global step 421: loss = 3.2835 (0.657 sec/step)\n",
            "INFO:tensorflow:global step 422: loss = 2.8872 (0.560 sec/step)\n",
            "I1211 18:52:03.021437 140545020077952 learning.py:507] global step 422: loss = 2.8872 (0.560 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 422.\n",
            "I1211 18:52:06.499327 140541340448512 supervisor.py:1050] Recording summary at step 422.\n",
            "INFO:tensorflow:global_step/sec: 0.900487\n",
            "I1211 18:52:06.545886 140541348841216 supervisor.py:1099] global_step/sec: 0.900487\n",
            "INFO:tensorflow:global step 423: loss = 3.0982 (3.678 sec/step)\n",
            "I1211 18:52:06.702775 140545020077952 learning.py:507] global step 423: loss = 3.0982 (3.678 sec/step)\n",
            "INFO:tensorflow:global step 424: loss = 3.7425 (0.770 sec/step)\n",
            "I1211 18:52:07.638532 140545020077952 learning.py:507] global step 424: loss = 3.7425 (0.770 sec/step)\n",
            "INFO:tensorflow:global step 425: loss = 3.9729 (1.719 sec/step)\n",
            "I1211 18:52:09.550403 140545020077952 learning.py:507] global step 425: loss = 3.9729 (1.719 sec/step)\n",
            "INFO:tensorflow:global step 426: loss = 3.1210 (0.626 sec/step)\n",
            "I1211 18:52:10.365396 140545020077952 learning.py:507] global step 426: loss = 3.1210 (0.626 sec/step)\n",
            "INFO:tensorflow:global step 427: loss = 2.9254 (0.821 sec/step)\n",
            "I1211 18:52:11.603234 140545020077952 learning.py:507] global step 427: loss = 2.9254 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 428: loss = 3.0578 (1.118 sec/step)\n",
            "I1211 18:52:12.936874 140545020077952 learning.py:507] global step 428: loss = 3.0578 (1.118 sec/step)\n",
            "INFO:tensorflow:global step 429: loss = 2.9964 (0.572 sec/step)\n",
            "I1211 18:52:13.683381 140545020077952 learning.py:507] global step 429: loss = 2.9964 (0.572 sec/step)\n",
            "INFO:tensorflow:global step 430: loss = 3.6795 (0.542 sec/step)\n",
            "I1211 18:52:14.897762 140545020077952 learning.py:507] global step 430: loss = 3.6795 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 431: loss = 3.0718 (0.601 sec/step)\n",
            "I1211 18:52:15.612338 140545020077952 learning.py:507] global step 431: loss = 3.0718 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 432: loss = 3.1395 (0.659 sec/step)\n",
            "I1211 18:52:16.273691 140545020077952 learning.py:507] global step 432: loss = 3.1395 (0.659 sec/step)\n",
            "INFO:tensorflow:global step 433: loss = 3.7876 (2.580 sec/step)\n",
            "I1211 18:52:18.855850 140545020077952 learning.py:507] global step 433: loss = 3.7876 (2.580 sec/step)\n",
            "INFO:tensorflow:global step 434: loss = 2.9149 (0.674 sec/step)\n",
            "I1211 18:52:19.664462 140545020077952 learning.py:507] global step 434: loss = 2.9149 (0.674 sec/step)\n",
            "INFO:tensorflow:global step 435: loss = 2.7895 (1.311 sec/step)\n",
            "I1211 18:52:21.089617 140545020077952 learning.py:507] global step 435: loss = 2.7895 (1.311 sec/step)\n",
            "INFO:tensorflow:global step 436: loss = 2.7458 (0.585 sec/step)\n",
            "I1211 18:52:21.676610 140545020077952 learning.py:507] global step 436: loss = 2.7458 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 437: loss = 3.5516 (0.935 sec/step)\n",
            "I1211 18:52:22.789771 140545020077952 learning.py:507] global step 437: loss = 3.5516 (0.935 sec/step)\n",
            "INFO:tensorflow:global step 438: loss = 2.7563 (1.845 sec/step)\n",
            "I1211 18:52:24.772091 140545020077952 learning.py:507] global step 438: loss = 2.7563 (1.845 sec/step)\n",
            "INFO:tensorflow:global step 439: loss = 3.0841 (0.724 sec/step)\n",
            "I1211 18:52:25.596735 140545020077952 learning.py:507] global step 439: loss = 3.0841 (0.724 sec/step)\n",
            "INFO:tensorflow:global step 440: loss = 3.5752 (1.250 sec/step)\n",
            "I1211 18:52:26.921509 140545020077952 learning.py:507] global step 440: loss = 3.5752 (1.250 sec/step)\n",
            "INFO:tensorflow:global step 441: loss = 2.6027 (0.672 sec/step)\n",
            "I1211 18:52:27.835891 140545020077952 learning.py:507] global step 441: loss = 2.6027 (0.672 sec/step)\n",
            "INFO:tensorflow:global step 442: loss = 2.8167 (0.732 sec/step)\n",
            "I1211 18:52:28.792577 140545020077952 learning.py:507] global step 442: loss = 2.8167 (0.732 sec/step)\n",
            "INFO:tensorflow:global step 443: loss = 2.9199 (0.537 sec/step)\n",
            "I1211 18:52:29.523821 140545020077952 learning.py:507] global step 443: loss = 2.9199 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 444: loss = 2.7833 (1.475 sec/step)\n",
            "I1211 18:52:31.110656 140545020077952 learning.py:507] global step 444: loss = 2.7833 (1.475 sec/step)\n",
            "INFO:tensorflow:global step 445: loss = 3.2116 (1.297 sec/step)\n",
            "I1211 18:52:32.448278 140545020077952 learning.py:507] global step 445: loss = 3.2116 (1.297 sec/step)\n",
            "INFO:tensorflow:global step 446: loss = 3.1726 (0.629 sec/step)\n",
            "I1211 18:52:33.275104 140545020077952 learning.py:507] global step 446: loss = 3.1726 (0.629 sec/step)\n",
            "INFO:tensorflow:global step 447: loss = 2.5535 (1.364 sec/step)\n",
            "I1211 18:52:34.737547 140545020077952 learning.py:507] global step 447: loss = 2.5535 (1.364 sec/step)\n",
            "INFO:tensorflow:global step 448: loss = 2.9909 (0.531 sec/step)\n",
            "I1211 18:52:35.270696 140545020077952 learning.py:507] global step 448: loss = 2.9909 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 449: loss = 2.7375 (1.028 sec/step)\n",
            "I1211 18:52:36.588884 140545020077952 learning.py:507] global step 449: loss = 2.7375 (1.028 sec/step)\n",
            "INFO:tensorflow:global step 450: loss = 2.7025 (0.746 sec/step)\n",
            "I1211 18:52:37.685337 140545020077952 learning.py:507] global step 450: loss = 2.7025 (0.746 sec/step)\n",
            "INFO:tensorflow:global step 451: loss = 3.8016 (0.642 sec/step)\n",
            "I1211 18:52:38.663438 140545020077952 learning.py:507] global step 451: loss = 3.8016 (0.642 sec/step)\n",
            "INFO:tensorflow:global step 452: loss = 2.9999 (1.035 sec/step)\n",
            "I1211 18:52:39.895475 140545020077952 learning.py:507] global step 452: loss = 2.9999 (1.035 sec/step)\n",
            "INFO:tensorflow:global step 453: loss = 2.9580 (0.587 sec/step)\n",
            "I1211 18:52:40.584198 140545020077952 learning.py:507] global step 453: loss = 2.9580 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 454: loss = 2.4845 (1.265 sec/step)\n",
            "I1211 18:52:42.088673 140545020077952 learning.py:507] global step 454: loss = 2.4845 (1.265 sec/step)\n",
            "INFO:tensorflow:global step 455: loss = 2.7361 (0.482 sec/step)\n",
            "I1211 18:52:42.827687 140545020077952 learning.py:507] global step 455: loss = 2.7361 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 456: loss = 2.7140 (0.761 sec/step)\n",
            "I1211 18:52:44.107806 140545020077952 learning.py:507] global step 456: loss = 2.7140 (0.761 sec/step)\n",
            "INFO:tensorflow:global step 457: loss = 3.2202 (0.591 sec/step)\n",
            "I1211 18:52:44.735022 140545020077952 learning.py:507] global step 457: loss = 3.2202 (0.591 sec/step)\n",
            "INFO:tensorflow:global step 458: loss = 2.7931 (1.367 sec/step)\n",
            "I1211 18:52:46.426771 140545020077952 learning.py:507] global step 458: loss = 2.7931 (1.367 sec/step)\n",
            "INFO:tensorflow:global step 459: loss = 3.3810 (0.525 sec/step)\n",
            "I1211 18:52:47.117333 140545020077952 learning.py:507] global step 459: loss = 3.3810 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 460: loss = 3.8473 (0.634 sec/step)\n",
            "I1211 18:52:48.087067 140545020077952 learning.py:507] global step 460: loss = 3.8473 (0.634 sec/step)\n",
            "INFO:tensorflow:global step 461: loss = 2.6124 (1.230 sec/step)\n",
            "I1211 18:52:49.513635 140545020077952 learning.py:507] global step 461: loss = 2.6124 (1.230 sec/step)\n",
            "INFO:tensorflow:global step 462: loss = 2.3488 (2.000 sec/step)\n",
            "I1211 18:52:51.515640 140545020077952 learning.py:507] global step 462: loss = 2.3488 (2.000 sec/step)\n",
            "INFO:tensorflow:global step 463: loss = 2.8829 (0.495 sec/step)\n",
            "I1211 18:52:52.012728 140545020077952 learning.py:507] global step 463: loss = 2.8829 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 464: loss = 2.9495 (1.852 sec/step)\n",
            "I1211 18:52:53.866533 140545020077952 learning.py:507] global step 464: loss = 2.9495 (1.852 sec/step)\n",
            "INFO:tensorflow:global step 465: loss = 2.7873 (0.539 sec/step)\n",
            "I1211 18:52:54.643538 140545020077952 learning.py:507] global step 465: loss = 2.7873 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 466: loss = 2.2113 (0.655 sec/step)\n",
            "I1211 18:52:55.699874 140545020077952 learning.py:507] global step 466: loss = 2.2113 (0.655 sec/step)\n",
            "INFO:tensorflow:global step 467: loss = 2.8731 (0.662 sec/step)\n",
            "I1211 18:52:56.857430 140545020077952 learning.py:507] global step 467: loss = 2.8731 (0.662 sec/step)\n",
            "INFO:tensorflow:global step 468: loss = 3.3917 (0.575 sec/step)\n",
            "I1211 18:52:57.519518 140545020077952 learning.py:507] global step 468: loss = 3.3917 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 469: loss = 3.0191 (0.846 sec/step)\n",
            "I1211 18:52:58.610738 140545020077952 learning.py:507] global step 469: loss = 3.0191 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 470: loss = 2.4231 (1.504 sec/step)\n",
            "I1211 18:53:00.210309 140545020077952 learning.py:507] global step 470: loss = 2.4231 (1.504 sec/step)\n",
            "INFO:tensorflow:global step 471: loss = 2.9146 (0.521 sec/step)\n",
            "I1211 18:53:00.960506 140545020077952 learning.py:507] global step 471: loss = 2.9146 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 472: loss = 3.2806 (1.394 sec/step)\n",
            "I1211 18:53:02.500616 140545020077952 learning.py:507] global step 472: loss = 3.2806 (1.394 sec/step)\n",
            "INFO:tensorflow:global step 473: loss = 2.5721 (0.683 sec/step)\n",
            "I1211 18:53:03.436976 140545020077952 learning.py:507] global step 473: loss = 2.5721 (0.683 sec/step)\n",
            "INFO:tensorflow:global step 474: loss = 3.5871 (0.544 sec/step)\n",
            "I1211 18:53:04.260181 140545020077952 learning.py:507] global step 474: loss = 3.5871 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 475: loss = 3.0182 (1.275 sec/step)\n",
            "I1211 18:53:05.600354 140545020077952 learning.py:507] global step 475: loss = 3.0182 (1.275 sec/step)\n",
            "INFO:tensorflow:global step 476: loss = 2.8707 (0.531 sec/step)\n",
            "I1211 18:53:06.132681 140545020077952 learning.py:507] global step 476: loss = 2.8707 (0.531 sec/step)\n",
            "INFO:tensorflow:global step 477: loss = 3.3601 (1.803 sec/step)\n",
            "I1211 18:53:07.937797 140545020077952 learning.py:507] global step 477: loss = 3.3601 (1.803 sec/step)\n",
            "INFO:tensorflow:global step 478: loss = 3.4135 (0.622 sec/step)\n",
            "I1211 18:53:08.822268 140545020077952 learning.py:507] global step 478: loss = 3.4135 (0.622 sec/step)\n",
            "INFO:tensorflow:global step 479: loss = 3.4323 (0.551 sec/step)\n",
            "I1211 18:53:09.775320 140545020077952 learning.py:507] global step 479: loss = 3.4323 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 480: loss = 2.5347 (1.628 sec/step)\n",
            "I1211 18:53:11.607191 140545020077952 learning.py:507] global step 480: loss = 2.5347 (1.628 sec/step)\n",
            "INFO:tensorflow:global step 481: loss = 3.1987 (0.496 sec/step)\n",
            "I1211 18:53:12.365013 140545020077952 learning.py:507] global step 481: loss = 3.1987 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 482: loss = 2.8786 (0.644 sec/step)\n",
            "I1211 18:53:13.566880 140545020077952 learning.py:507] global step 482: loss = 2.8786 (0.644 sec/step)\n",
            "INFO:tensorflow:global step 483: loss = 2.6371 (0.570 sec/step)\n",
            "I1211 18:53:14.198338 140545020077952 learning.py:507] global step 483: loss = 2.6371 (0.570 sec/step)\n",
            "INFO:tensorflow:global step 484: loss = 3.6324 (1.529 sec/step)\n",
            "I1211 18:53:15.841152 140545020077952 learning.py:507] global step 484: loss = 3.6324 (1.529 sec/step)\n",
            "INFO:tensorflow:global step 485: loss = 3.1225 (0.698 sec/step)\n",
            "I1211 18:53:16.790784 140545020077952 learning.py:507] global step 485: loss = 3.1225 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 486: loss = 2.9299 (1.192 sec/step)\n",
            "I1211 18:53:18.003312 140545020077952 learning.py:507] global step 486: loss = 2.9299 (1.192 sec/step)\n",
            "INFO:tensorflow:global step 487: loss = 3.1177 (0.645 sec/step)\n",
            "I1211 18:53:18.661617 140545020077952 learning.py:507] global step 487: loss = 3.1177 (0.645 sec/step)\n",
            "INFO:tensorflow:global step 488: loss = 2.6208 (1.374 sec/step)\n",
            "I1211 18:53:20.164291 140545020077952 learning.py:507] global step 488: loss = 2.6208 (1.374 sec/step)\n",
            "INFO:tensorflow:global step 489: loss = 3.3998 (0.602 sec/step)\n",
            "I1211 18:53:21.067358 140545020077952 learning.py:507] global step 489: loss = 3.3998 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 490: loss = 2.9241 (0.565 sec/step)\n",
            "I1211 18:53:22.087788 140545020077952 learning.py:507] global step 490: loss = 2.9241 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 491: loss = 2.7839 (0.458 sec/step)\n",
            "I1211 18:53:22.660402 140545020077952 learning.py:507] global step 491: loss = 2.7839 (0.458 sec/step)\n",
            "INFO:tensorflow:global step 492: loss = 3.0779 (1.587 sec/step)\n",
            "I1211 18:53:24.249495 140545020077952 learning.py:507] global step 492: loss = 3.0779 (1.587 sec/step)\n",
            "INFO:tensorflow:global step 493: loss = 3.1401 (0.485 sec/step)\n",
            "I1211 18:53:24.736172 140545020077952 learning.py:507] global step 493: loss = 3.1401 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 494: loss = 3.1760 (1.482 sec/step)\n",
            "I1211 18:53:26.362943 140545020077952 learning.py:507] global step 494: loss = 3.1760 (1.482 sec/step)\n",
            "INFO:tensorflow:global step 495: loss = 2.7575 (0.683 sec/step)\n",
            "I1211 18:53:27.157330 140545020077952 learning.py:507] global step 495: loss = 2.7575 (0.683 sec/step)\n",
            "INFO:tensorflow:global step 496: loss = 3.1302 (1.238 sec/step)\n",
            "I1211 18:53:28.644327 140545020077952 learning.py:507] global step 496: loss = 3.1302 (1.238 sec/step)\n",
            "INFO:tensorflow:global step 497: loss = 2.2094 (0.652 sec/step)\n",
            "I1211 18:53:29.585282 140545020077952 learning.py:507] global step 497: loss = 2.2094 (0.652 sec/step)\n",
            "INFO:tensorflow:global step 498: loss = 2.6847 (0.552 sec/step)\n",
            "I1211 18:53:30.406180 140545020077952 learning.py:507] global step 498: loss = 2.6847 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 499: loss = 2.7489 (0.509 sec/step)\n",
            "I1211 18:53:31.352697 140545020077952 learning.py:507] global step 499: loss = 2.7489 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 500: loss = 2.1466 (1.359 sec/step)\n",
            "I1211 18:53:32.824633 140545020077952 learning.py:507] global step 500: loss = 2.1466 (1.359 sec/step)\n",
            "INFO:tensorflow:global step 501: loss = 2.6876 (0.710 sec/step)\n",
            "I1211 18:53:33.804881 140545020077952 learning.py:507] global step 501: loss = 2.6876 (0.710 sec/step)\n",
            "INFO:tensorflow:global step 502: loss = 3.3374 (0.520 sec/step)\n",
            "I1211 18:53:34.374110 140545020077952 learning.py:507] global step 502: loss = 3.3374 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 503: loss = 3.0721 (1.738 sec/step)\n",
            "I1211 18:53:36.129861 140545020077952 learning.py:507] global step 503: loss = 3.0721 (1.738 sec/step)\n",
            "INFO:tensorflow:global step 504: loss = 2.8103 (1.373 sec/step)\n",
            "I1211 18:53:37.603015 140545020077952 learning.py:507] global step 504: loss = 2.8103 (1.373 sec/step)\n",
            "INFO:tensorflow:global step 505: loss = 3.2760 (0.536 sec/step)\n",
            "I1211 18:53:38.445266 140545020077952 learning.py:507] global step 505: loss = 3.2760 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 506: loss = 3.8231 (0.601 sec/step)\n",
            "I1211 18:53:39.295789 140545020077952 learning.py:507] global step 506: loss = 3.8231 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 507: loss = 3.2037 (1.637 sec/step)\n",
            "I1211 18:53:40.934876 140545020077952 learning.py:507] global step 507: loss = 3.2037 (1.637 sec/step)\n",
            "INFO:tensorflow:global step 508: loss = 3.3748 (0.573 sec/step)\n",
            "I1211 18:53:41.902889 140545020077952 learning.py:507] global step 508: loss = 3.3748 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 509: loss = 3.4046 (0.552 sec/step)\n",
            "I1211 18:53:42.828795 140545020077952 learning.py:507] global step 509: loss = 3.4046 (0.552 sec/step)\n",
            "INFO:tensorflow:global step 510: loss = 3.2728 (0.739 sec/step)\n",
            "I1211 18:53:43.785044 140545020077952 learning.py:507] global step 510: loss = 3.2728 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 511: loss = 3.0333 (1.250 sec/step)\n",
            "I1211 18:53:45.266440 140545020077952 learning.py:507] global step 511: loss = 3.0333 (1.250 sec/step)\n",
            "INFO:tensorflow:global step 512: loss = 3.1287 (0.517 sec/step)\n",
            "I1211 18:53:46.023214 140545020077952 learning.py:507] global step 512: loss = 3.1287 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 513: loss = 2.9607 (1.217 sec/step)\n",
            "I1211 18:53:47.396869 140545020077952 learning.py:507] global step 513: loss = 2.9607 (1.217 sec/step)\n",
            "INFO:tensorflow:global step 514: loss = 2.7325 (0.752 sec/step)\n",
            "I1211 18:53:48.416361 140545020077952 learning.py:507] global step 514: loss = 2.7325 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 515: loss = 3.1742 (0.521 sec/step)\n",
            "I1211 18:53:49.291826 140545020077952 learning.py:507] global step 515: loss = 3.1742 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 516: loss = 3.2434 (0.573 sec/step)\n",
            "I1211 18:53:50.094535 140545020077952 learning.py:507] global step 516: loss = 3.2434 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 517: loss = 2.6995 (1.498 sec/step)\n",
            "I1211 18:53:51.594772 140545020077952 learning.py:507] global step 517: loss = 2.6995 (1.498 sec/step)\n",
            "INFO:tensorflow:global step 518: loss = 2.7131 (0.638 sec/step)\n",
            "I1211 18:53:52.542752 140545020077952 learning.py:507] global step 518: loss = 2.7131 (0.638 sec/step)\n",
            "INFO:tensorflow:global step 519: loss = 3.5314 (1.021 sec/step)\n",
            "I1211 18:53:53.648692 140545020077952 learning.py:507] global step 519: loss = 3.5314 (1.021 sec/step)\n",
            "INFO:tensorflow:global step 520: loss = 3.0609 (0.663 sec/step)\n",
            "I1211 18:53:54.456764 140545020077952 learning.py:507] global step 520: loss = 3.0609 (0.663 sec/step)\n",
            "INFO:tensorflow:global step 521: loss = 3.4792 (0.575 sec/step)\n",
            "I1211 18:53:55.282982 140545020077952 learning.py:507] global step 521: loss = 3.4792 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 522: loss = 2.6468 (1.510 sec/step)\n",
            "I1211 18:53:56.873086 140545020077952 learning.py:507] global step 522: loss = 2.6468 (1.510 sec/step)\n",
            "INFO:tensorflow:global step 523: loss = 3.0662 (0.713 sec/step)\n",
            "I1211 18:53:57.873545 140545020077952 learning.py:507] global step 523: loss = 3.0662 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 524: loss = 2.3927 (0.622 sec/step)\n",
            "I1211 18:53:58.898557 140545020077952 learning.py:507] global step 524: loss = 2.3927 (0.622 sec/step)\n",
            "INFO:tensorflow:global step 525: loss = 2.9814 (1.042 sec/step)\n",
            "I1211 18:54:00.013328 140545020077952 learning.py:507] global step 525: loss = 2.9814 (1.042 sec/step)\n",
            "INFO:tensorflow:global step 526: loss = 3.0769 (0.571 sec/step)\n",
            "I1211 18:54:00.801055 140545020077952 learning.py:507] global step 526: loss = 3.0769 (0.571 sec/step)\n",
            "INFO:tensorflow:global step 527: loss = 3.0842 (0.596 sec/step)\n",
            "I1211 18:54:01.728490 140545020077952 learning.py:507] global step 527: loss = 3.0842 (0.596 sec/step)\n",
            "INFO:tensorflow:global step 528: loss = 2.8843 (1.085 sec/step)\n",
            "I1211 18:54:02.991648 140545020077952 learning.py:507] global step 528: loss = 2.8843 (1.085 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n",
            "I1211 18:54:03.093110 140541315270400 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "INFO:tensorflow:global step 529: loss = 2.6888 (2.381 sec/step)\n",
            "I1211 18:54:05.623528 140545020077952 learning.py:507] global step 529: loss = 2.6888 (2.381 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 529.\n",
            "I1211 18:54:05.623861 140541340448512 supervisor.py:1050] Recording summary at step 529.\n",
            "INFO:tensorflow:global_step/sec: 0.899551\n",
            "I1211 18:54:06.605938 140541348841216 supervisor.py:1099] global_step/sec: 0.899551\n",
            "INFO:tensorflow:global step 530: loss = 2.7620 (0.773 sec/step)\n",
            "I1211 18:54:06.619564 140545020077952 learning.py:507] global step 530: loss = 2.7620 (0.773 sec/step)\n",
            "INFO:tensorflow:global step 531: loss = 3.1116 (1.536 sec/step)\n",
            "I1211 18:54:08.653658 140545020077952 learning.py:507] global step 531: loss = 3.1116 (1.536 sec/step)\n",
            "INFO:tensorflow:global step 532: loss = 4.0115 (0.724 sec/step)\n",
            "I1211 18:54:09.476008 140545020077952 learning.py:507] global step 532: loss = 4.0115 (0.724 sec/step)\n",
            "INFO:tensorflow:global step 533: loss = 2.5270 (1.480 sec/step)\n",
            "I1211 18:54:11.222519 140545020077952 learning.py:507] global step 533: loss = 2.5270 (1.480 sec/step)\n",
            "INFO:tensorflow:global step 534: loss = 2.7073 (0.567 sec/step)\n",
            "I1211 18:54:11.946314 140545020077952 learning.py:507] global step 534: loss = 2.7073 (0.567 sec/step)\n",
            "INFO:tensorflow:global step 535: loss = 2.4649 (1.777 sec/step)\n",
            "I1211 18:54:13.744904 140545020077952 learning.py:507] global step 535: loss = 2.4649 (1.777 sec/step)\n",
            "INFO:tensorflow:global step 536: loss = 3.3359 (0.544 sec/step)\n",
            "I1211 18:54:14.291408 140545020077952 learning.py:507] global step 536: loss = 3.3359 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 537: loss = 2.7440 (1.731 sec/step)\n",
            "I1211 18:54:16.024580 140545020077952 learning.py:507] global step 537: loss = 2.7440 (1.731 sec/step)\n",
            "INFO:tensorflow:global step 538: loss = 3.6795 (0.503 sec/step)\n",
            "I1211 18:54:16.784414 140545020077952 learning.py:507] global step 538: loss = 3.6795 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 539: loss = 3.1068 (1.351 sec/step)\n",
            "I1211 18:54:18.344578 140545020077952 learning.py:507] global step 539: loss = 3.1068 (1.351 sec/step)\n",
            "INFO:tensorflow:global step 540: loss = 4.0681 (0.658 sec/step)\n",
            "I1211 18:54:19.136347 140545020077952 learning.py:507] global step 540: loss = 4.0681 (0.658 sec/step)\n",
            "INFO:tensorflow:global step 541: loss = 3.1959 (1.326 sec/step)\n",
            "I1211 18:54:20.675807 140545020077952 learning.py:507] global step 541: loss = 3.1959 (1.326 sec/step)\n",
            "INFO:tensorflow:global step 542: loss = 2.5951 (0.592 sec/step)\n",
            "I1211 18:54:21.573567 140545020077952 learning.py:507] global step 542: loss = 2.5951 (0.592 sec/step)\n",
            "INFO:tensorflow:global step 543: loss = 2.6783 (0.549 sec/step)\n",
            "I1211 18:54:22.226306 140545020077952 learning.py:507] global step 543: loss = 2.6783 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 544: loss = 2.7860 (1.470 sec/step)\n",
            "I1211 18:54:23.711287 140545020077952 learning.py:507] global step 544: loss = 2.7860 (1.470 sec/step)\n",
            "INFO:tensorflow:global step 545: loss = 2.9354 (0.537 sec/step)\n",
            "I1211 18:54:24.435720 140545020077952 learning.py:507] global step 545: loss = 2.9354 (0.537 sec/step)\n",
            "INFO:tensorflow:global step 546: loss = 2.7986 (1.640 sec/step)\n",
            "I1211 18:54:26.314616 140545020077952 learning.py:507] global step 546: loss = 2.7986 (1.640 sec/step)\n",
            "INFO:tensorflow:global step 547: loss = 3.5884 (0.585 sec/step)\n",
            "I1211 18:54:27.059779 140545020077952 learning.py:507] global step 547: loss = 3.5884 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 548: loss = 3.5312 (1.276 sec/step)\n",
            "I1211 18:54:28.692021 140545020077952 learning.py:507] global step 548: loss = 3.5312 (1.276 sec/step)\n",
            "INFO:tensorflow:global step 549: loss = 2.5923 (0.652 sec/step)\n",
            "I1211 18:54:29.572386 140545020077952 learning.py:507] global step 549: loss = 2.5923 (0.652 sec/step)\n",
            "INFO:tensorflow:global step 550: loss = 2.1132 (1.477 sec/step)\n",
            "I1211 18:54:31.222203 140545020077952 learning.py:507] global step 550: loss = 2.1132 (1.477 sec/step)\n",
            "INFO:tensorflow:global step 551: loss = 3.0522 (1.078 sec/step)\n",
            "I1211 18:54:32.302191 140545020077952 learning.py:507] global step 551: loss = 3.0522 (1.078 sec/step)\n",
            "INFO:tensorflow:global step 552: loss = 3.2065 (0.575 sec/step)\n",
            "I1211 18:54:33.084726 140545020077952 learning.py:507] global step 552: loss = 3.2065 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 553: loss = 3.3864 (0.524 sec/step)\n",
            "I1211 18:54:34.239430 140545020077952 learning.py:507] global step 553: loss = 3.3864 (0.524 sec/step)\n",
            "INFO:tensorflow:global step 554: loss = 3.1671 (0.655 sec/step)\n",
            "I1211 18:54:35.334995 140545020077952 learning.py:507] global step 554: loss = 3.1671 (0.655 sec/step)\n",
            "INFO:tensorflow:global step 555: loss = 2.7119 (1.528 sec/step)\n",
            "I1211 18:54:36.894507 140545020077952 learning.py:507] global step 555: loss = 2.7119 (1.528 sec/step)\n",
            "INFO:tensorflow:global step 556: loss = 3.3500 (0.500 sec/step)\n",
            "I1211 18:54:37.765361 140545020077952 learning.py:507] global step 556: loss = 3.3500 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 557: loss = 2.7997 (1.271 sec/step)\n",
            "I1211 18:54:39.160873 140545020077952 learning.py:507] global step 557: loss = 2.7997 (1.271 sec/step)\n",
            "INFO:tensorflow:global step 558: loss = 2.6920 (0.505 sec/step)\n",
            "I1211 18:54:39.667675 140545020077952 learning.py:507] global step 558: loss = 2.6920 (0.505 sec/step)\n",
            "INFO:tensorflow:global step 559: loss = 3.0505 (1.684 sec/step)\n",
            "I1211 18:54:41.353405 140545020077952 learning.py:507] global step 559: loss = 3.0505 (1.684 sec/step)\n",
            "INFO:tensorflow:global step 560: loss = 2.9025 (0.664 sec/step)\n",
            "I1211 18:54:42.129789 140545020077952 learning.py:507] global step 560: loss = 2.9025 (0.664 sec/step)\n",
            "INFO:tensorflow:global step 561: loss = 2.4289 (1.659 sec/step)\n",
            "I1211 18:54:43.841081 140545020077952 learning.py:507] global step 561: loss = 2.4289 (1.659 sec/step)\n",
            "INFO:tensorflow:global step 562: loss = 2.7966 (0.749 sec/step)\n",
            "I1211 18:54:44.659817 140545020077952 learning.py:507] global step 562: loss = 2.7966 (0.749 sec/step)\n",
            "INFO:tensorflow:global step 563: loss = 3.5299 (1.104 sec/step)\n",
            "I1211 18:54:46.037398 140545020077952 learning.py:507] global step 563: loss = 3.5299 (1.104 sec/step)\n",
            "INFO:tensorflow:global step 564: loss = 2.6490 (0.694 sec/step)\n",
            "I1211 18:54:46.895256 140545020077952 learning.py:507] global step 564: loss = 2.6490 (0.694 sec/step)\n",
            "INFO:tensorflow:global step 565: loss = 3.0878 (0.628 sec/step)\n",
            "I1211 18:54:47.998636 140545020077952 learning.py:507] global step 565: loss = 3.0878 (0.628 sec/step)\n",
            "INFO:tensorflow:global step 566: loss = 2.9339 (0.667 sec/step)\n",
            "I1211 18:54:49.014645 140545020077952 learning.py:507] global step 566: loss = 2.9339 (0.667 sec/step)\n",
            "INFO:tensorflow:global step 567: loss = 3.1121 (0.769 sec/step)\n",
            "I1211 18:54:50.199250 140545020077952 learning.py:507] global step 567: loss = 3.1121 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 568: loss = 2.8942 (0.694 sec/step)\n",
            "I1211 18:54:51.092895 140545020077952 learning.py:507] global step 568: loss = 2.8942 (0.694 sec/step)\n",
            "INFO:tensorflow:global step 569: loss = 2.6952 (2.348 sec/step)\n",
            "I1211 18:54:53.607447 140545020077952 learning.py:507] global step 569: loss = 2.6952 (2.348 sec/step)\n",
            "INFO:tensorflow:global step 570: loss = 3.1085 (0.752 sec/step)\n",
            "I1211 18:54:54.678558 140545020077952 learning.py:507] global step 570: loss = 3.1085 (0.752 sec/step)\n",
            "INFO:tensorflow:global step 571: loss = 3.9210 (0.704 sec/step)\n",
            "I1211 18:54:55.514126 140545020077952 learning.py:507] global step 571: loss = 3.9210 (0.704 sec/step)\n",
            "INFO:tensorflow:global step 572: loss = 3.2705 (1.577 sec/step)\n",
            "I1211 18:54:57.095382 140545020077952 learning.py:507] global step 572: loss = 3.2705 (1.577 sec/step)\n",
            "INFO:tensorflow:global step 573: loss = 2.7228 (0.680 sec/step)\n",
            "I1211 18:54:57.777843 140545020077952 learning.py:507] global step 573: loss = 2.7228 (0.680 sec/step)\n",
            "INFO:tensorflow:global step 574: loss = 2.9705 (1.762 sec/step)\n",
            "I1211 18:54:59.541911 140545020077952 learning.py:507] global step 574: loss = 2.9705 (1.762 sec/step)\n",
            "INFO:tensorflow:global step 575: loss = 2.5051 (0.541 sec/step)\n",
            "I1211 18:55:00.084532 140545020077952 learning.py:507] global step 575: loss = 2.5051 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 576: loss = 2.9311 (1.582 sec/step)\n",
            "I1211 18:55:01.969259 140545020077952 learning.py:507] global step 576: loss = 2.9311 (1.582 sec/step)\n",
            "INFO:tensorflow:global step 577: loss = 2.5261 (1.083 sec/step)\n",
            "I1211 18:55:03.245741 140545020077952 learning.py:507] global step 577: loss = 2.5261 (1.083 sec/step)\n",
            "INFO:tensorflow:global step 578: loss = 2.7657 (1.028 sec/step)\n",
            "I1211 18:55:04.292110 140545020077952 learning.py:507] global step 578: loss = 2.7657 (1.028 sec/step)\n",
            "INFO:tensorflow:global step 579: loss = 2.5371 (1.245 sec/step)\n",
            "I1211 18:55:05.545070 140545020077952 learning.py:507] global step 579: loss = 2.5371 (1.245 sec/step)\n",
            "INFO:tensorflow:global step 580: loss = 2.0523 (0.711 sec/step)\n",
            "I1211 18:55:06.361422 140545020077952 learning.py:507] global step 580: loss = 2.0523 (0.711 sec/step)\n",
            "INFO:tensorflow:global step 581: loss = 2.4097 (1.354 sec/step)\n",
            "I1211 18:55:07.913192 140545020077952 learning.py:507] global step 581: loss = 2.4097 (1.354 sec/step)\n",
            "INFO:tensorflow:global step 582: loss = 3.7602 (0.483 sec/step)\n",
            "I1211 18:55:08.398704 140545020077952 learning.py:507] global step 582: loss = 3.7602 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 583: loss = 3.1579 (1.891 sec/step)\n",
            "I1211 18:55:10.292143 140545020077952 learning.py:507] global step 583: loss = 3.1579 (1.891 sec/step)\n",
            "INFO:tensorflow:global step 584: loss = 2.7509 (0.634 sec/step)\n",
            "I1211 18:55:11.006823 140545020077952 learning.py:507] global step 584: loss = 2.7509 (0.634 sec/step)\n",
            "INFO:tensorflow:global step 585: loss = 3.0074 (1.281 sec/step)\n",
            "I1211 18:55:12.707694 140545020077952 learning.py:507] global step 585: loss = 3.0074 (1.281 sec/step)\n",
            "INFO:tensorflow:global step 586: loss = 2.9115 (0.604 sec/step)\n",
            "I1211 18:55:13.510507 140545020077952 learning.py:507] global step 586: loss = 2.9115 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 587: loss = 2.3133 (0.560 sec/step)\n",
            "I1211 18:55:14.285681 140545020077952 learning.py:507] global step 587: loss = 2.3133 (0.560 sec/step)\n",
            "INFO:tensorflow:global step 588: loss = 2.9843 (0.581 sec/step)\n",
            "I1211 18:55:14.867894 140545020077952 learning.py:507] global step 588: loss = 2.9843 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 589: loss = 2.8314 (2.650 sec/step)\n",
            "I1211 18:55:17.594640 140545020077952 learning.py:507] global step 589: loss = 2.8314 (2.650 sec/step)\n",
            "INFO:tensorflow:global step 590: loss = 2.5900 (2.684 sec/step)\n",
            "I1211 18:55:20.280635 140545020077952 learning.py:507] global step 590: loss = 2.5900 (2.684 sec/step)\n",
            "INFO:tensorflow:global step 591: loss = 2.4643 (0.624 sec/step)\n",
            "I1211 18:55:21.224736 140545020077952 learning.py:507] global step 591: loss = 2.4643 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 592: loss = 2.3535 (1.433 sec/step)\n",
            "I1211 18:55:22.673468 140545020077952 learning.py:507] global step 592: loss = 2.3535 (1.433 sec/step)\n",
            "INFO:tensorflow:global step 593: loss = 3.1637 (0.507 sec/step)\n",
            "I1211 18:55:23.182586 140545020077952 learning.py:507] global step 593: loss = 3.1637 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 594: loss = 3.1241 (1.250 sec/step)\n",
            "I1211 18:55:24.546538 140545020077952 learning.py:507] global step 594: loss = 3.1241 (1.250 sec/step)\n",
            "INFO:tensorflow:global step 595: loss = 2.7940 (1.551 sec/step)\n",
            "I1211 18:55:26.102294 140545020077952 learning.py:507] global step 595: loss = 2.7940 (1.551 sec/step)\n",
            "INFO:tensorflow:global step 596: loss = 3.7783 (0.539 sec/step)\n",
            "I1211 18:55:26.643796 140545020077952 learning.py:507] global step 596: loss = 3.7783 (0.539 sec/step)\n",
            "INFO:tensorflow:global step 597: loss = 3.0872 (2.338 sec/step)\n",
            "I1211 18:55:28.984505 140545020077952 learning.py:507] global step 597: loss = 3.0872 (2.338 sec/step)\n",
            "INFO:tensorflow:global step 598: loss = 3.0925 (0.579 sec/step)\n",
            "I1211 18:55:29.566072 140545020077952 learning.py:507] global step 598: loss = 3.0925 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 599: loss = 2.8530 (2.169 sec/step)\n",
            "I1211 18:55:31.737186 140545020077952 learning.py:507] global step 599: loss = 2.8530 (2.169 sec/step)\n",
            "INFO:tensorflow:global step 600: loss = 3.6088 (0.717 sec/step)\n",
            "I1211 18:55:32.527199 140545020077952 learning.py:507] global step 600: loss = 3.6088 (0.717 sec/step)\n",
            "INFO:tensorflow:global step 601: loss = 3.5018 (1.405 sec/step)\n",
            "I1211 18:55:34.008805 140545020077952 learning.py:507] global step 601: loss = 3.5018 (1.405 sec/step)\n",
            "INFO:tensorflow:global step 602: loss = 2.7320 (0.549 sec/step)\n",
            "I1211 18:55:34.559066 140545020077952 learning.py:507] global step 602: loss = 2.7320 (0.549 sec/step)\n",
            "INFO:tensorflow:global step 603: loss = 2.5630 (0.994 sec/step)\n",
            "I1211 18:55:35.751941 140545020077952 learning.py:507] global step 603: loss = 2.5630 (0.994 sec/step)\n",
            "INFO:tensorflow:global step 604: loss = 2.6444 (2.049 sec/step)\n",
            "I1211 18:55:37.929858 140545020077952 learning.py:507] global step 604: loss = 2.6444 (2.049 sec/step)\n",
            "INFO:tensorflow:global step 605: loss = 2.6919 (0.713 sec/step)\n",
            "I1211 18:55:38.954084 140545020077952 learning.py:507] global step 605: loss = 2.6919 (0.713 sec/step)\n",
            "INFO:tensorflow:global step 606: loss = 3.2725 (0.568 sec/step)\n",
            "I1211 18:55:39.525412 140545020077952 learning.py:507] global step 606: loss = 3.2725 (0.568 sec/step)\n",
            "INFO:tensorflow:global step 607: loss = 2.9132 (1.022 sec/step)\n",
            "I1211 18:55:40.788390 140545020077952 learning.py:507] global step 607: loss = 2.9132 (1.022 sec/step)\n",
            "INFO:tensorflow:global step 608: loss = 3.0684 (1.702 sec/step)\n",
            "I1211 18:55:42.822909 140545020077952 learning.py:507] global step 608: loss = 3.0684 (1.702 sec/step)\n",
            "INFO:tensorflow:global step 609: loss = 2.6390 (0.573 sec/step)\n",
            "I1211 18:55:43.532332 140545020077952 learning.py:507] global step 609: loss = 2.6390 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 610: loss = 2.4728 (1.380 sec/step)\n",
            "I1211 18:55:45.243656 140545020077952 learning.py:507] global step 610: loss = 2.4728 (1.380 sec/step)\n",
            "INFO:tensorflow:global step 611: loss = 2.9644 (0.611 sec/step)\n",
            "I1211 18:55:45.856749 140545020077952 learning.py:507] global step 611: loss = 2.9644 (0.611 sec/step)\n",
            "INFO:tensorflow:global step 612: loss = 2.7977 (1.715 sec/step)\n",
            "I1211 18:55:47.599205 140545020077952 learning.py:507] global step 612: loss = 2.7977 (1.715 sec/step)\n",
            "INFO:tensorflow:global step 613: loss = 2.9651 (1.376 sec/step)\n",
            "I1211 18:55:48.980665 140545020077952 learning.py:507] global step 613: loss = 2.9651 (1.376 sec/step)\n",
            "INFO:tensorflow:global step 614: loss = 2.6993 (0.633 sec/step)\n",
            "I1211 18:55:49.955296 140545020077952 learning.py:507] global step 614: loss = 2.6993 (0.633 sec/step)\n",
            "INFO:tensorflow:global step 615: loss = 3.5962 (0.581 sec/step)\n",
            "I1211 18:55:51.103292 140545020077952 learning.py:507] global step 615: loss = 3.5962 (0.581 sec/step)\n",
            "INFO:tensorflow:global step 616: loss = 2.5873 (1.481 sec/step)\n",
            "I1211 18:55:52.592336 140545020077952 learning.py:507] global step 616: loss = 2.5873 (1.481 sec/step)\n",
            "INFO:tensorflow:global step 617: loss = 3.3587 (0.730 sec/step)\n",
            "I1211 18:55:53.506141 140545020077952 learning.py:507] global step 617: loss = 3.3587 (0.730 sec/step)\n",
            "INFO:tensorflow:global step 618: loss = 2.8658 (0.637 sec/step)\n",
            "I1211 18:55:54.675353 140545020077952 learning.py:507] global step 618: loss = 2.8658 (0.637 sec/step)\n",
            "INFO:tensorflow:global step 619: loss = 2.4797 (1.385 sec/step)\n",
            "I1211 18:55:56.137829 140545020077952 learning.py:507] global step 619: loss = 2.4797 (1.385 sec/step)\n",
            "INFO:tensorflow:global step 620: loss = 2.4386 (0.509 sec/step)\n",
            "I1211 18:55:56.938450 140545020077952 learning.py:507] global step 620: loss = 2.4386 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 621: loss = 3.4767 (1.678 sec/step)\n",
            "I1211 18:55:58.846471 140545020077952 learning.py:507] global step 621: loss = 3.4767 (1.678 sec/step)\n",
            "INFO:tensorflow:global step 622: loss = 2.7488 (0.563 sec/step)\n",
            "I1211 18:55:59.670597 140545020077952 learning.py:507] global step 622: loss = 2.7488 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 623: loss = 2.8233 (1.330 sec/step)\n",
            "I1211 18:56:01.264060 140545020077952 learning.py:507] global step 623: loss = 2.8233 (1.330 sec/step)\n",
            "INFO:tensorflow:global step 624: loss = 2.5091 (0.603 sec/step)\n",
            "I1211 18:56:01.869217 140545020077952 learning.py:507] global step 624: loss = 2.5091 (0.603 sec/step)\n",
            "INFO:tensorflow:global step 625: loss = 3.1667 (2.145 sec/step)\n",
            "I1211 18:56:04.024883 140545020077952 learning.py:507] global step 625: loss = 3.1667 (2.145 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 625.\n",
            "I1211 18:56:05.954869 140541340448512 supervisor.py:1050] Recording summary at step 625.\n",
            "INFO:tensorflow:global step 626: loss = 2.8805 (1.875 sec/step)\n",
            "I1211 18:56:06.145282 140545020077952 learning.py:507] global step 626: loss = 2.8805 (1.875 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.799423\n",
            "I1211 18:56:06.692532 140541348841216 supervisor.py:1099] global_step/sec: 0.799423\n",
            "INFO:tensorflow:global step 627: loss = 2.9486 (0.614 sec/step)\n",
            "I1211 18:56:07.012699 140545020077952 learning.py:507] global step 627: loss = 2.9486 (0.614 sec/step)\n",
            "INFO:tensorflow:global step 628: loss = 2.9812 (1.459 sec/step)\n",
            "I1211 18:56:08.607888 140545020077952 learning.py:507] global step 628: loss = 2.9812 (1.459 sec/step)\n",
            "INFO:tensorflow:global step 629: loss = 3.5147 (0.642 sec/step)\n",
            "I1211 18:56:09.404082 140545020077952 learning.py:507] global step 629: loss = 3.5147 (0.642 sec/step)\n",
            "INFO:tensorflow:global step 630: loss = 2.6780 (0.906 sec/step)\n",
            "I1211 18:56:10.656010 140545020077952 learning.py:507] global step 630: loss = 2.6780 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 631: loss = 2.7950 (1.246 sec/step)\n",
            "I1211 18:56:12.029108 140545020077952 learning.py:507] global step 631: loss = 2.7950 (1.246 sec/step)\n",
            "INFO:tensorflow:global step 632: loss = 3.0103 (0.573 sec/step)\n",
            "I1211 18:56:12.810350 140545020077952 learning.py:507] global step 632: loss = 3.0103 (0.573 sec/step)\n",
            "INFO:tensorflow:global step 633: loss = 2.8237 (1.297 sec/step)\n",
            "I1211 18:56:14.423157 140545020077952 learning.py:507] global step 633: loss = 2.8237 (1.297 sec/step)\n",
            "INFO:tensorflow:global step 634: loss = 2.6542 (0.757 sec/step)\n",
            "I1211 18:56:15.434245 140545020077952 learning.py:507] global step 634: loss = 2.6542 (0.757 sec/step)\n",
            "INFO:tensorflow:global step 635: loss = 2.5560 (0.739 sec/step)\n",
            "I1211 18:56:16.270359 140545020077952 learning.py:507] global step 635: loss = 2.5560 (0.739 sec/step)\n",
            "INFO:tensorflow:global step 636: loss = 2.5479 (1.878 sec/step)\n",
            "I1211 18:56:18.397508 140545020077952 learning.py:507] global step 636: loss = 2.5479 (1.878 sec/step)\n",
            "INFO:tensorflow:global step 637: loss = 2.9117 (0.808 sec/step)\n",
            "I1211 18:56:19.480566 140545020077952 learning.py:507] global step 637: loss = 2.9117 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 638: loss = 3.4266 (1.754 sec/step)\n",
            "I1211 18:56:21.267633 140545020077952 learning.py:507] global step 638: loss = 3.4266 (1.754 sec/step)\n",
            "INFO:tensorflow:global step 639: loss = 2.7062 (0.489 sec/step)\n",
            "I1211 18:56:21.759116 140545020077952 learning.py:507] global step 639: loss = 2.7062 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 640: loss = 2.1855 (1.875 sec/step)\n",
            "I1211 18:56:23.636520 140545020077952 learning.py:507] global step 640: loss = 2.1855 (1.875 sec/step)\n",
            "INFO:tensorflow:global step 641: loss = 2.7838 (0.627 sec/step)\n",
            "I1211 18:56:24.540211 140545020077952 learning.py:507] global step 641: loss = 2.7838 (0.627 sec/step)\n",
            "INFO:tensorflow:global step 642: loss = 3.2184 (0.601 sec/step)\n",
            "I1211 18:56:25.579337 140545020077952 learning.py:507] global step 642: loss = 3.2184 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 643: loss = 2.9877 (0.747 sec/step)\n",
            "I1211 18:56:26.871447 140545020077952 learning.py:507] global step 643: loss = 2.9877 (0.747 sec/step)\n",
            "INFO:tensorflow:global step 644: loss = 3.6181 (0.638 sec/step)\n",
            "I1211 18:56:27.915194 140545020077952 learning.py:507] global step 644: loss = 3.6181 (0.638 sec/step)\n",
            "INFO:tensorflow:global step 645: loss = 3.3094 (0.583 sec/step)\n",
            "I1211 18:56:28.605772 140545020077952 learning.py:507] global step 645: loss = 3.3094 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 646: loss = 2.9071 (0.934 sec/step)\n",
            "I1211 18:56:29.712215 140545020077952 learning.py:507] global step 646: loss = 2.9071 (0.934 sec/step)\n",
            "INFO:tensorflow:global step 647: loss = 2.7114 (1.979 sec/step)\n",
            "I1211 18:56:31.904876 140545020077952 learning.py:507] global step 647: loss = 2.7114 (1.979 sec/step)\n",
            "INFO:tensorflow:global step 648: loss = 3.3973 (0.618 sec/step)\n",
            "I1211 18:56:32.524791 140545020077952 learning.py:507] global step 648: loss = 3.3973 (0.618 sec/step)\n",
            "INFO:tensorflow:global step 649: loss = 2.5935 (1.704 sec/step)\n",
            "I1211 18:56:34.237133 140545020077952 learning.py:507] global step 649: loss = 2.5935 (1.704 sec/step)\n",
            "INFO:tensorflow:global step 650: loss = 2.6810 (0.546 sec/step)\n",
            "I1211 18:56:34.790511 140545020077952 learning.py:507] global step 650: loss = 2.6810 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 651: loss = 3.0629 (2.130 sec/step)\n",
            "I1211 18:56:36.923062 140545020077952 learning.py:507] global step 651: loss = 3.0629 (2.130 sec/step)\n",
            "INFO:tensorflow:global step 652: loss = 2.8824 (0.490 sec/step)\n",
            "I1211 18:56:37.414571 140545020077952 learning.py:507] global step 652: loss = 2.8824 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 653: loss = 3.0962 (1.736 sec/step)\n",
            "I1211 18:56:39.152349 140545020077952 learning.py:507] global step 653: loss = 3.0962 (1.736 sec/step)\n",
            "INFO:tensorflow:global step 654: loss = 3.0241 (0.693 sec/step)\n",
            "I1211 18:56:39.847643 140545020077952 learning.py:507] global step 654: loss = 3.0241 (0.693 sec/step)\n",
            "INFO:tensorflow:global step 655: loss = 2.9088 (1.807 sec/step)\n",
            "I1211 18:56:41.656613 140545020077952 learning.py:507] global step 655: loss = 2.9088 (1.807 sec/step)\n",
            "INFO:tensorflow:global step 656: loss = 3.0402 (0.547 sec/step)\n",
            "I1211 18:56:42.205930 140545020077952 learning.py:507] global step 656: loss = 3.0402 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 657: loss = 2.3135 (1.637 sec/step)\n",
            "I1211 18:56:43.844948 140545020077952 learning.py:507] global step 657: loss = 2.3135 (1.637 sec/step)\n",
            "INFO:tensorflow:global step 658: loss = 2.7932 (0.620 sec/step)\n",
            "I1211 18:56:44.735049 140545020077952 learning.py:507] global step 658: loss = 2.7932 (0.620 sec/step)\n",
            "INFO:tensorflow:global step 659: loss = 2.7097 (0.654 sec/step)\n",
            "I1211 18:56:45.778588 140545020077952 learning.py:507] global step 659: loss = 2.7097 (0.654 sec/step)\n",
            "INFO:tensorflow:global step 660: loss = 2.8073 (1.871 sec/step)\n",
            "I1211 18:56:47.663102 140545020077952 learning.py:507] global step 660: loss = 2.8073 (1.871 sec/step)\n",
            "INFO:tensorflow:global step 661: loss = 2.4943 (0.797 sec/step)\n",
            "I1211 18:56:48.721740 140545020077952 learning.py:507] global step 661: loss = 2.4943 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 662: loss = 2.5811 (0.680 sec/step)\n",
            "I1211 18:56:49.762105 140545020077952 learning.py:507] global step 662: loss = 2.5811 (0.680 sec/step)\n",
            "INFO:tensorflow:global step 663: loss = 3.2690 (0.601 sec/step)\n",
            "I1211 18:56:50.452218 140545020077952 learning.py:507] global step 663: loss = 3.2690 (0.601 sec/step)\n",
            "INFO:tensorflow:global step 664: loss = 2.9241 (1.028 sec/step)\n",
            "I1211 18:56:51.694415 140545020077952 learning.py:507] global step 664: loss = 2.9241 (1.028 sec/step)\n",
            "INFO:tensorflow:global step 665: loss = 2.9293 (1.581 sec/step)\n",
            "I1211 18:56:53.592258 140545020077952 learning.py:507] global step 665: loss = 2.9293 (1.581 sec/step)\n",
            "INFO:tensorflow:global step 666: loss = 2.6661 (0.536 sec/step)\n",
            "I1211 18:56:54.257584 140545020077952 learning.py:507] global step 666: loss = 2.6661 (0.536 sec/step)\n",
            "INFO:tensorflow:global step 667: loss = 3.4013 (1.684 sec/step)\n",
            "I1211 18:56:55.981029 140545020077952 learning.py:507] global step 667: loss = 3.4013 (1.684 sec/step)\n",
            "INFO:tensorflow:global step 668: loss = 2.7355 (0.707 sec/step)\n",
            "I1211 18:56:56.913917 140545020077952 learning.py:507] global step 668: loss = 2.7355 (0.707 sec/step)\n",
            "INFO:tensorflow:global step 669: loss = 3.4148 (0.512 sec/step)\n",
            "I1211 18:56:57.611389 140545020077952 learning.py:507] global step 669: loss = 3.4148 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 670: loss = 2.6188 (1.619 sec/step)\n",
            "I1211 18:56:59.291289 140545020077952 learning.py:507] global step 670: loss = 2.6188 (1.619 sec/step)\n",
            "INFO:tensorflow:global step 671: loss = 2.6198 (0.528 sec/step)\n",
            "I1211 18:56:59.825111 140545020077952 learning.py:507] global step 671: loss = 2.6198 (0.528 sec/step)\n",
            "INFO:tensorflow:global step 672: loss = 2.7865 (1.821 sec/step)\n",
            "I1211 18:57:01.648001 140545020077952 learning.py:507] global step 672: loss = 2.7865 (1.821 sec/step)\n",
            "INFO:tensorflow:global step 673: loss = 3.7310 (0.648 sec/step)\n",
            "I1211 18:57:02.522538 140545020077952 learning.py:507] global step 673: loss = 3.7310 (0.648 sec/step)\n",
            "INFO:tensorflow:global step 674: loss = 3.1340 (1.570 sec/step)\n",
            "I1211 18:57:04.161957 140545020077952 learning.py:507] global step 674: loss = 3.1340 (1.570 sec/step)\n",
            "INFO:tensorflow:global step 675: loss = 2.7445 (0.563 sec/step)\n",
            "I1211 18:57:04.835434 140545020077952 learning.py:507] global step 675: loss = 2.7445 (0.563 sec/step)\n",
            "INFO:tensorflow:global step 676: loss = 3.3992 (0.631 sec/step)\n",
            "I1211 18:57:05.654048 140545020077952 learning.py:507] global step 676: loss = 3.3992 (0.631 sec/step)\n",
            "INFO:tensorflow:global step 677: loss = 2.5783 (1.698 sec/step)\n",
            "I1211 18:57:07.372482 140545020077952 learning.py:507] global step 677: loss = 2.5783 (1.698 sec/step)\n",
            "INFO:tensorflow:global step 678: loss = 3.1532 (0.504 sec/step)\n",
            "I1211 18:57:07.878805 140545020077952 learning.py:507] global step 678: loss = 3.1532 (0.504 sec/step)\n",
            "INFO:tensorflow:global step 679: loss = 2.9709 (1.794 sec/step)\n",
            "I1211 18:57:09.674644 140545020077952 learning.py:507] global step 679: loss = 2.9709 (1.794 sec/step)\n",
            "INFO:tensorflow:global step 680: loss = 3.4349 (0.662 sec/step)\n",
            "I1211 18:57:10.338807 140545020077952 learning.py:507] global step 680: loss = 3.4349 (0.662 sec/step)\n",
            "INFO:tensorflow:global step 681: loss = 2.7219 (1.723 sec/step)\n",
            "I1211 18:57:12.109447 140545020077952 learning.py:507] global step 681: loss = 2.7219 (1.723 sec/step)\n",
            "INFO:tensorflow:global step 682: loss = 3.3334 (0.491 sec/step)\n",
            "I1211 18:57:12.602275 140545020077952 learning.py:507] global step 682: loss = 3.3334 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 683: loss = 2.9494 (0.769 sec/step)\n",
            "I1211 18:57:13.678458 140545020077952 learning.py:507] global step 683: loss = 2.9494 (0.769 sec/step)\n",
            "INFO:tensorflow:global step 684: loss = 2.7509 (1.842 sec/step)\n",
            "I1211 18:57:15.902523 140545020077952 learning.py:507] global step 684: loss = 2.7509 (1.842 sec/step)\n",
            "INFO:tensorflow:global step 685: loss = 2.8353 (0.698 sec/step)\n",
            "I1211 18:57:16.872422 140545020077952 learning.py:507] global step 685: loss = 2.8353 (0.698 sec/step)\n",
            "INFO:tensorflow:global step 686: loss = 2.5889 (0.554 sec/step)\n",
            "I1211 18:57:17.546730 140545020077952 learning.py:507] global step 686: loss = 2.5889 (0.554 sec/step)\n",
            "INFO:tensorflow:global step 687: loss = 2.4785 (1.611 sec/step)\n",
            "I1211 18:57:19.331239 140545020077952 learning.py:507] global step 687: loss = 2.4785 (1.611 sec/step)\n",
            "INFO:tensorflow:global step 688: loss = 2.5503 (0.620 sec/step)\n",
            "I1211 18:57:19.988870 140545020077952 learning.py:507] global step 688: loss = 2.5503 (0.620 sec/step)\n",
            "INFO:tensorflow:global step 689: loss = 2.5959 (1.527 sec/step)\n",
            "I1211 18:57:21.517835 140545020077952 learning.py:507] global step 689: loss = 2.5959 (1.527 sec/step)\n",
            "INFO:tensorflow:global step 690: loss = 2.8019 (0.615 sec/step)\n",
            "I1211 18:57:22.476242 140545020077952 learning.py:507] global step 690: loss = 2.8019 (0.615 sec/step)\n",
            "INFO:tensorflow:global step 691: loss = 2.6879 (0.491 sec/step)\n",
            "I1211 18:57:23.042537 140545020077952 learning.py:507] global step 691: loss = 2.6879 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 692: loss = 3.7404 (1.330 sec/step)\n",
            "I1211 18:57:24.618262 140545020077952 learning.py:507] global step 692: loss = 3.7404 (1.330 sec/step)\n",
            "INFO:tensorflow:global step 693: loss = 2.9335 (0.670 sec/step)\n",
            "I1211 18:57:25.577859 140545020077952 learning.py:507] global step 693: loss = 2.9335 (0.670 sec/step)\n",
            "INFO:tensorflow:global step 694: loss = 2.7064 (1.730 sec/step)\n",
            "I1211 18:57:27.362526 140545020077952 learning.py:507] global step 694: loss = 2.7064 (1.730 sec/step)\n",
            "INFO:tensorflow:global step 695: loss = 2.6674 (0.497 sec/step)\n",
            "I1211 18:57:27.861998 140545020077952 learning.py:507] global step 695: loss = 2.6674 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 696: loss = 2.6038 (1.843 sec/step)\n",
            "I1211 18:57:29.706906 140545020077952 learning.py:507] global step 696: loss = 2.6038 (1.843 sec/step)\n",
            "INFO:tensorflow:global step 697: loss = 2.6408 (0.578 sec/step)\n",
            "I1211 18:57:30.679638 140545020077952 learning.py:507] global step 697: loss = 2.6408 (0.578 sec/step)\n",
            "INFO:tensorflow:global step 698: loss = 2.6859 (0.695 sec/step)\n",
            "I1211 18:57:31.718480 140545020077952 learning.py:507] global step 698: loss = 2.6859 (0.695 sec/step)\n",
            "INFO:tensorflow:global step 699: loss = 3.5413 (1.769 sec/step)\n",
            "I1211 18:57:33.559441 140545020077952 learning.py:507] global step 699: loss = 3.5413 (1.769 sec/step)\n",
            "INFO:tensorflow:global step 700: loss = 3.0700 (1.089 sec/step)\n",
            "I1211 18:57:34.650201 140545020077952 learning.py:507] global step 700: loss = 3.0700 (1.089 sec/step)\n",
            "INFO:tensorflow:global step 701: loss = 3.7469 (0.551 sec/step)\n",
            "I1211 18:57:35.500686 140545020077952 learning.py:507] global step 701: loss = 3.7469 (0.551 sec/step)\n",
            "INFO:tensorflow:global step 702: loss = 2.5482 (0.703 sec/step)\n",
            "I1211 18:57:36.640192 140545020077952 learning.py:507] global step 702: loss = 2.5482 (0.703 sec/step)\n",
            "INFO:tensorflow:global step 703: loss = 2.5821 (0.658 sec/step)\n",
            "I1211 18:57:37.696590 140545020077952 learning.py:507] global step 703: loss = 2.5821 (0.658 sec/step)\n",
            "INFO:tensorflow:global step 704: loss = 2.4606 (0.585 sec/step)\n",
            "I1211 18:57:38.646611 140545020077952 learning.py:507] global step 704: loss = 2.4606 (0.585 sec/step)\n",
            "INFO:tensorflow:global step 705: loss = 3.0271 (1.381 sec/step)\n",
            "I1211 18:57:40.382090 140545020077952 learning.py:507] global step 705: loss = 3.0271 (1.381 sec/step)\n",
            "INFO:tensorflow:global step 706: loss = 2.5675 (0.542 sec/step)\n",
            "I1211 18:57:40.925713 140545020077952 learning.py:507] global step 706: loss = 2.5675 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 707: loss = 2.2650 (1.871 sec/step)\n",
            "I1211 18:57:42.798717 140545020077952 learning.py:507] global step 707: loss = 2.2650 (1.871 sec/step)\n",
            "INFO:tensorflow:global step 708: loss = 3.1590 (0.587 sec/step)\n",
            "I1211 18:57:43.599528 140545020077952 learning.py:507] global step 708: loss = 3.1590 (0.587 sec/step)\n",
            "INFO:tensorflow:global step 709: loss = 2.8454 (0.689 sec/step)\n",
            "I1211 18:57:44.691685 140545020077952 learning.py:507] global step 709: loss = 2.8454 (0.689 sec/step)\n",
            "INFO:tensorflow:global step 710: loss = 2.8075 (1.963 sec/step)\n",
            "I1211 18:57:46.782823 140545020077952 learning.py:507] global step 710: loss = 2.8075 (1.963 sec/step)\n",
            "INFO:tensorflow:global step 711: loss = 3.2005 (0.498 sec/step)\n",
            "I1211 18:57:47.282061 140545020077952 learning.py:507] global step 711: loss = 3.2005 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 712: loss = 2.6314 (1.782 sec/step)\n",
            "I1211 18:57:49.065518 140545020077952 learning.py:507] global step 712: loss = 2.6314 (1.782 sec/step)\n",
            "INFO:tensorflow:global step 713: loss = 2.3516 (0.624 sec/step)\n",
            "I1211 18:57:49.942881 140545020077952 learning.py:507] global step 713: loss = 2.3516 (0.624 sec/step)\n",
            "INFO:tensorflow:global step 714: loss = 2.2587 (0.629 sec/step)\n",
            "I1211 18:57:51.032385 140545020077952 learning.py:507] global step 714: loss = 2.2587 (0.629 sec/step)\n",
            "INFO:tensorflow:global step 715: loss = 2.6114 (0.606 sec/step)\n",
            "I1211 18:57:51.862876 140545020077952 learning.py:507] global step 715: loss = 2.6114 (0.606 sec/step)\n",
            "INFO:tensorflow:global step 716: loss = 3.6753 (1.839 sec/step)\n",
            "I1211 18:57:53.704083 140545020077952 learning.py:507] global step 716: loss = 3.6753 (1.839 sec/step)\n",
            "INFO:tensorflow:global step 717: loss = 2.7051 (0.695 sec/step)\n",
            "I1211 18:57:54.417662 140545020077952 learning.py:507] global step 717: loss = 2.7051 (0.695 sec/step)\n",
            "INFO:tensorflow:global step 718: loss = 3.2829 (1.586 sec/step)\n",
            "I1211 18:57:56.068691 140545020077952 learning.py:507] global step 718: loss = 3.2829 (1.586 sec/step)\n",
            "INFO:tensorflow:global step 719: loss = 3.0185 (0.543 sec/step)\n",
            "I1211 18:57:56.613544 140545020077952 learning.py:507] global step 719: loss = 3.0185 (0.543 sec/step)\n",
            "INFO:tensorflow:global step 720: loss = 3.1535 (0.837 sec/step)\n",
            "I1211 18:57:57.580353 140545020077952 learning.py:507] global step 720: loss = 3.1535 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 721: loss = 2.7697 (1.902 sec/step)\n",
            "I1211 18:57:59.785206 140545020077952 learning.py:507] global step 721: loss = 2.7697 (1.902 sec/step)\n",
            "INFO:tensorflow:global step 722: loss = 2.9732 (0.569 sec/step)\n",
            "I1211 18:58:00.394197 140545020077952 learning.py:507] global step 722: loss = 2.9732 (0.569 sec/step)\n",
            "INFO:tensorflow:global step 723: loss = 2.9007 (1.342 sec/step)\n",
            "I1211 18:58:02.028668 140545020077952 learning.py:507] global step 723: loss = 2.9007 (1.342 sec/step)\n",
            "INFO:tensorflow:global step 724: loss = 2.0397 (0.743 sec/step)\n",
            "I1211 18:58:02.825567 140545020077952 learning.py:507] global step 724: loss = 2.0397 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 725: loss = 2.2092 (2.340 sec/step)\n",
            "I1211 18:58:05.175883 140545020077952 learning.py:507] global step 725: loss = 2.2092 (2.340 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.825858\n",
            "I1211 18:58:06.567859 140541348841216 supervisor.py:1099] global_step/sec: 0.825858\n",
            "INFO:tensorflow:Recording summary at step 725.\n",
            "I1211 18:58:07.181176 140541340448512 supervisor.py:1050] Recording summary at step 725.\n",
            "INFO:tensorflow:global step 726: loss = 2.6990 (1.945 sec/step)\n",
            "I1211 18:58:07.416863 140545020077952 learning.py:507] global step 726: loss = 2.6990 (1.945 sec/step)\n",
            "INFO:tensorflow:global step 727: loss = 2.9387 (0.629 sec/step)\n",
            "I1211 18:58:08.047695 140545020077952 learning.py:507] global step 727: loss = 2.9387 (0.629 sec/step)\n",
            "INFO:tensorflow:global step 728: loss = 2.9927 (2.002 sec/step)\n",
            "I1211 18:58:10.052065 140545020077952 learning.py:507] global step 728: loss = 2.9927 (2.002 sec/step)\n",
            "INFO:tensorflow:global step 729: loss = 2.4999 (0.530 sec/step)\n",
            "I1211 18:58:10.584428 140545020077952 learning.py:507] global step 729: loss = 2.4999 (0.530 sec/step)\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 185, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"train.py\", line 181, in main\n",
            "    graph_hook_fn=graph_rewriter_fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/legacy/trainer.py\", line 417, in train\n",
            "    saver=saver)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 775, in train\n",
            "    train_step_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 490, in train_step\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoYXafYtY5Uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tensorboard --logdir=training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-WzWDHjZQ-5",
        "colab_type": "code",
        "outputId": "28a8c721-a925-42d5-a3d5-24557d325672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix training/model.ckpt-528 --output_directory inference_graph"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1211 18:58:29.092622 140539026188160 module_wrapper.py:139] From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1211 18:58:29.099873 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1211 18:58:29.100154 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1211 18:58:29.134520 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W1211 18:58:29.161194 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1211 18:58:29.162832 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W1211 18:58:30.534593 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1211 18:58:30.544616 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.544812 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.580721 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.616057 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.650605 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.685010 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1211 18:58:30.719774 140539026188160 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1211 18:58:30.966509 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W1211 18:58:31.380842 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1211 18:58:31.381108 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1211 18:58:31.384022 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W1211 18:58:31.384200 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W1211 18:58:31.385001 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "108 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/5.49m params)\n",
            "  BoxPredictor_0 (--/9.23k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x512x6, 3.07k/3.07k params)\n",
            "  BoxPredictor_1 (--/36.90k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/12.30k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x12, 12.29k/12.29k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/5.41m params)\n",
            "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "108 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1211 18:58:32.075141 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1211 18:58:32.580220 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-12-11 18:58:32.599685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-11 18:58:32.659144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:32.659748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-11 18:58:32.663409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:58:32.685274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:58:32.774765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-11 18:58:32.784890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-11 18:58:32.820945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-11 18:58:32.837046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-11 18:58:32.912024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:58:32.912214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:32.912853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:32.913462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-11 18:58:32.925339: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-12-11 18:58:32.927242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a019c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-11 18:58:32.927303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-11 18:58:33.058963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.059655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a01800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-11 18:58:33.059684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2019-12-11 18:58:33.059908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.060434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-11 18:58:33.060518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:58:33.060537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:58:33.060550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-11 18:58:33.060563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-11 18:58:33.060575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-11 18:58:33.060588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-11 18:58:33.060602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:58:33.060684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.061252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.061733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-11 18:58:33.065853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:58:33.068124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-11 18:58:33.068155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-11 18:58:33.068192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-11 18:58:33.068421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.068994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:33.069564: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-11 18:58:33.069605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-528\n",
            "I1211 18:58:33.071330 140539026188160 saver.py:1284] Restoring parameters from training/model.ckpt-528\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1211 18:58:33.941909 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-12-11 18:58:34.447844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:34.448441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-11 18:58:34.448527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:58:34.448552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:58:34.448573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-11 18:58:34.448592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-11 18:58:34.448611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-11 18:58:34.448630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-11 18:58:34.448650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:58:34.448753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:34.449314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:34.449802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-11 18:58:34.449844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-11 18:58:34.449856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-11 18:58:34.449869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-11 18:58:34.449985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:34.450593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:34.451107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-528\n",
            "I1211 18:58:34.452339 140539026188160 saver.py:1284] Restoring parameters from training/model.ckpt-528\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1211 18:58:37.254920 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1211 18:58:37.255226 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 199 variables.\n",
            "I1211 18:58:37.487569 140539026188160 graph_util_impl.py:334] Froze 199 variables.\n",
            "INFO:tensorflow:Converted 199 variables to const ops.\n",
            "I1211 18:58:37.550348 140539026188160 graph_util_impl.py:394] Converted 199 variables to const ops.\n",
            "2019-12-11 18:58:37.666373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:37.666949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-11 18:58:37.667037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-11 18:58:37.667063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-11 18:58:37.667084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-11 18:58:37.667107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-11 18:58:37.667128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-11 18:58:37.667147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-11 18:58:37.667186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-11 18:58:37.667297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:37.667861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:37.668346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-11 18:58:37.668388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-11 18:58:37.668402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-11 18:58:37.668411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-11 18:58:37.668531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:37.669074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-11 18:58:37.669578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W1211 18:58:37.952485 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1211 18:58:37.955018 140539026188160 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W1211 18:58:37.955524 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W1211 18:58:37.955703 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W1211 18:58:37.955910 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W1211 18:58:37.956050 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I1211 18:58:37.956329 140539026188160 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1211 18:58:37.956431 140539026188160 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: inference_graph/saved_model/saved_model.pb\n",
            "I1211 18:58:38.160198 140539026188160 builder_impl.py:425] SavedModel written to: inference_graph/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1211 18:58:38.182934 140539026188160 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\n",
            "I1211 18:58:38.183154 140539026188160 config_util.py:190] Writing pipeline config file to inference_graph/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxGhSchrjUg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -r /content/models/research/object_detection/inference_graph /gdrive/My\\ Drive/colabfiles/lektion31"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0owJO0_cqhSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp /gdrive/My\\ Drive/colabfiles/lektion31/rasenbilder190726_01/bild101.jpg /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8-djxitLZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp /gdrive/My\\ Drive/colabfiles/lektion31/rasen.mov /content/models/research/object_detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcwxa8EfjeBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## Image Object Detection Using Tensorflow-trained Classifier #########\n",
        "#\n",
        "# Author: Evan Juras\n",
        "# Date: 1/15/18\n",
        "# Description: \n",
        "# This program uses a TensorFlow-trained classifier to perform object detection.\n",
        "# It loads the classifier uses it to perform object detection on an image.\n",
        "# It draws boxes and scores around the objects of interest in the image.\n",
        "\n",
        "## Some of the code is copied from Google's example at\n",
        "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "\n",
        "## and some is copied from Dat Tran's example at\n",
        "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n",
        "\n",
        "## but I changed it to make it more understandable to me.\n",
        "\n",
        "# Import packages\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'inference_graph'\n",
        "#IMAGE_NAME = 'bild101.jpg'\n",
        "#IMAGE_NAME = 'ch (8).jpg'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','label_map.pbtxt')\n",
        "\n",
        "# Path to image\n",
        "PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "# Load image using OpenCV and\n",
        "# expand image dimensions to have shape: [1, None, None, 3]\n",
        "# i.e. a single-column array, where each item in the column has the pixel RGB value\n",
        "image = cv2.imread('/gdrive/My Drive/colabfiles/lektion20/DSC01019.JPG')\n",
        "image_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Perform the actual detection by running the model with the image as input\n",
        "(boxes, scores, classes, num) = sess.run(\n",
        "    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "    feed_dict={image_tensor: image_expanded})\n",
        "\n",
        "# Draw the results of the detection (aka 'visulaize the results')\n",
        "\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image,\n",
        "    np.squeeze(boxes),\n",
        "    np.squeeze(classes).astype(np.int32),\n",
        "    np.squeeze(scores),\n",
        "    category_index,\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=2,\n",
        "    min_score_thresh=0.80)\n",
        "\n",
        "# All the results have been drawn on image. Now display the image.\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Press any key to close the image\n",
        "#cv2.waitKey(0)\n",
        "\n",
        "# Clean up\n",
        "#cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjs2cfgcr1AZ",
        "colab_type": "code",
        "outputId": "757c75eb-cedf-4587-9f75-3ab672dcb831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "######## Video Object Detection Using Tensorflow-trained Classifier #########\n",
        "#\n",
        "# Author: Evan Juras\n",
        "# Date: 1/16/18\n",
        "# Description: \n",
        "# This program uses a TensorFlow-trained classifier to perform object detection.\n",
        "# It loads the classifier uses it to perform object detection on a video.\n",
        "# It draws boxes and scores around the objects of interest in each frame\n",
        "# of the video.\n",
        "\n",
        "## Some of the code is copied from Google's example at\n",
        "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "\n",
        "## and some is copied from Dat Tran's example at\n",
        "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n",
        "\n",
        "## but I changed it to make it more understandable to me.\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import imutils\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Import utilites\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Name of the directory containing the object detection module we're using\n",
        "MODEL_NAME = 'inference_graph'\n",
        "VIDEO_NAME = 'rasen.mov'\n",
        "\n",
        "# Grab path to current working directory\n",
        "CWD_PATH = os.getcwd()\n",
        "\n",
        "print(CWD_PATH)\n",
        "\n",
        "# Path to frozen detection graph .pb file, which contains the model that is used\n",
        "# for object detection.\n",
        "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\n",
        "\n",
        "# Path to label map file\n",
        "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','label_map.pbtxt')\n",
        "\n",
        "# Path to video\n",
        "PATH_TO_VIDEO = os.path.join(CWD_PATH,VIDEO_NAME)\n",
        "\n",
        "# Number of classes the object detector can identify\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Load the label map.\n",
        "# Label maps map indices to category names, so that when our convolution\n",
        "# network predicts `5`, we know that this corresponds to `king`.\n",
        "# Here we use internal utility functions, but anything that returns a\n",
        "# dictionary mapping integers to appropriate string labels would be fine\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Load the Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    sess = tf.Session(graph=detection_graph)\n",
        "\n",
        "# Define input and output tensors (i.e. data) for the object detection classifier\n",
        "\n",
        "# Input tensor is the image\n",
        "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "# Output tensors are the detection boxes, scores, and classes\n",
        "# Each box represents a part of the image where a particular object was detected\n",
        "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "# Each score represents level of confidence for each of the objects.\n",
        "# The score is shown on the result image, together with the class label.\n",
        "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "\n",
        "# Number of objects detected\n",
        "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "# Open video file\n",
        "video = cv2.VideoCapture(PATH_TO_VIDEO)\n",
        "print(\"ok\")\n",
        "i = 0\n",
        "while(video.isOpened()):\n",
        "\n",
        "    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n",
        "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
        "    ret, frame = video.read()\n",
        "    if ret==True:\n",
        "        frame = cv2.imread(\"/gdrive/My Drive/colabfiles/lektion20/DSC01019.JPG\")\n",
        "        frame_expanded = np.expand_dims(frame, axis=0)\n",
        "\n",
        "        # Perform the actual detection by running the model with the image as input\n",
        "        (boxes, scores, classes, num) = sess.run(\n",
        "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "            feed_dict={image_tensor: frame_expanded})\n",
        "\n",
        "        # Draw the results of the detection (aka 'visulaize the results')\n",
        "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "            frame,\n",
        "            np.squeeze(boxes),\n",
        "            np.squeeze(classes).astype(np.int32),\n",
        "            np.squeeze(scores),\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            line_thickness=8,\n",
        "            min_score_thresh=0.70)\n",
        "\n",
        "        # All the results have been drawn on the frame, so it's time to display it.\n",
        "        \n",
        "        frame = imutils.resize(frame, 800)\n",
        "        cv2_imshow(frame)\n",
        "        #print(boxes)\n",
        "        time.sleep(1)\n",
        "        clear_output()\n",
        "        \n",
        "\n",
        "        # Press 'q' to quit\n",
        "        #print(i)\n",
        "        #i = i + 1\n",
        "        #if cv2.waitKey(1) == ord('q'):\n",
        "        #    break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Clean up\n",
        "print(\"end1\")\n",
        "#video.release()\n",
        "#cv2.destroyAllWindows()\n",
        "print(\"end2\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4e4fd5c87157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;31m#print(boxes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, check)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     ImageFile._save(im, _idat(fp, chunk),\n\u001b[0;32m--> 797\u001b[0;31m                     [(\"zip\", (0, 0)+im.size, 0, rawmode)])\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYdH-jDqafF5",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}